{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "from afqinsight import AFQDataset\n",
    "from afqinsight.nn.utils import prep_pytorch_data\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.normal import Normal\n",
    "from sklearn.decomposition import PCA\n",
    "import afqinsight.augmentation as aug\n",
    "from afqinsight.nn.pt_models import Conv1DAutoencoder\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Adjust path as needed\n",
    "# sys.path.insert(1, '/mmfs1/gscratch/nrdg/samchou/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils')\n",
    "sys.path.insert(1, '/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils')\n",
    "# Import necessary functions, including the new one\n",
    "from utils import select_device, kl_divergence_loss,prep_fa_flattned_data, prep_fa_flattened_remapped_data, train_vae_age_site_staged\n",
    "from models import Conv1DVariationalAutoencoder_fa, AgePredictorCNN, SitePredictorCNN, CombinedVAE_Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "Using MPS backend on macOS. (Detailed memory info may not be available.)\n"
     ]
    }
   ],
   "source": [
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/samchou/.cache/afq-insight/hbn/subjects.tsv exists.\n",
      "File /Users/samchou/.cache/afq-insight/hbn/nodes.csv exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samchou/src/nrdg/AFQ-Insight/afqinsight/transform.py:144: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  features = interpolated.stack([\"subjectID\", \"tractID\", \"metric\"]).unstack(\n"
     ]
    }
   ],
   "source": [
    "dataset = AFQDataset.from_study('hbn')\n",
    "torch_dataset, train_loader, test_loader, val_loader = prep_pytorch_data(dataset,batch_size=128)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_idx = dataset.target_cols.index('scan_site_id')\n",
    "age_idx = dataset.target_cols.index('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset, all_tracts_train_loader, all_tracts_test_loader, all_tracts_val_loader = prep_fa_flattned_data(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing initial PyTorch data loaders...\n",
      "Remapping prep: Using age index 0, site index 2 from ['age', 'sex', 'scan_site_id']\n",
      "Using site map: {0.0: 0.0, 1.0: 1.0, 3.0: 2.0, 4.0: 3.0}\n",
      "Creating remapped datasets...\n",
      "Creating final DataLoaders...\n",
      "prep_fa_flattened_remapped_data complete.\n",
      "Initial data loaders prepared.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing initial PyTorch data loaders...\")\n",
    "try:\n",
    "    # Assuming prep_pytorch_data returns torch_dataset, train_loader, test_loader, val_loader\n",
    "    # If it returns datasets, create loaders here.\n",
    "    # Adapt this call based on the actual signature and return values of your prep_pytorch_data\n",
    "    prep_output = prep_fa_flattened_remapped_data(dataset, batch_size=128)\n",
    "    if len(prep_output) == 4:\n",
    "        _, train_loader_raw, test_loader_raw, val_loader_raw = prep_output\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 4 return values from prep_pytorch_data, got {len(prep_output)}\")\n",
    "\n",
    "    print(\"Initial data loaders prepared.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error calling prep_pytorch_data: {e}\")\n",
    "     print(\"Ensure the function exists and returns DataLoaders or required components.\")\n",
    "     sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train_data = []\n",
    "\n",
    "for x, labels in train_data:\n",
    "    tract_data = x.to(device, non_blocking=True)\n",
    "    age_labels = labels[:, 0].float().unsqueeze(1)\n",
    "    x_hat, _, _ = vae_model(tract_data)\n",
    "    age_train_data.append((x_hat.cpu(), age_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 448\n",
      "tensor([[ 8.6692],\n",
      "        [13.6279],\n",
      "        [10.1421],\n",
      "        [10.6547],\n",
      "        [ 9.1620],\n",
      "        [ 8.4230],\n",
      "        [ 7.3139],\n",
      "        [14.2714],\n",
      "        [10.8841],\n",
      "        [12.5246],\n",
      "        [ 9.6472],\n",
      "        [ 6.3864],\n",
      "        [ 7.2729],\n",
      "        [10.9285],\n",
      "        [ 6.6513],\n",
      "        [11.1278],\n",
      "        [ 7.7849],\n",
      "        [ 9.6192],\n",
      "        [11.4350],\n",
      "        [15.2242],\n",
      "        [ 9.9593],\n",
      "        [ 9.6275],\n",
      "        [ 9.4633],\n",
      "        [ 9.1023],\n",
      "        [11.3413],\n",
      "        [ 8.3680],\n",
      "        [13.1269],\n",
      "        [ 8.5794],\n",
      "        [16.0837],\n",
      "        [12.8065],\n",
      "        [12.4454],\n",
      "        [13.0196],\n",
      "        [11.8808],\n",
      "        [ 7.5110],\n",
      "        [10.2271],\n",
      "        [14.0441],\n",
      "        [ 7.3331],\n",
      "        [ 8.6692],\n",
      "        [ 9.7074],\n",
      "        [ 8.3353],\n",
      "        [16.4342],\n",
      "        [ 6.5857],\n",
      "        [ 7.0483],\n",
      "        [ 8.8253],\n",
      "        [ 8.4065],\n",
      "        [17.4221],\n",
      "        [ 5.0716],\n",
      "        [ 7.6946],\n",
      "        [10.7418],\n",
      "        [15.9546],\n",
      "        [11.7877],\n",
      "        [10.8300],\n",
      "        [ 7.3775],\n",
      "        [17.4467],\n",
      "        [ 6.7553],\n",
      "        [ 7.7328],\n",
      "        [13.6279],\n",
      "        [ 8.6912],\n",
      "        [ 7.0626],\n",
      "        [15.0840],\n",
      "        [15.1585],\n",
      "        [ 9.5513],\n",
      "        [ 9.5157],\n",
      "        [13.0421],\n",
      "        [15.6513],\n",
      "        [15.7246],\n",
      "        [ 9.0227],\n",
      "        [10.3557],\n",
      "        [ 8.8312],\n",
      "        [10.8984],\n",
      "        [12.0751],\n",
      "        [15.9031],\n",
      "        [11.9333],\n",
      "        [ 6.1394],\n",
      "        [ 5.2966],\n",
      "        [ 9.6493],\n",
      "        [ 8.0919],\n",
      "        [13.4609],\n",
      "        [10.0989],\n",
      "        [ 9.0333],\n",
      "        [ 8.8087],\n",
      "        [17.2039],\n",
      "        [10.1969],\n",
      "        [11.0845],\n",
      "        [ 8.2809],\n",
      "        [12.6063],\n",
      "        [10.7939],\n",
      "        [13.4363],\n",
      "        [ 9.5157],\n",
      "        [17.7396],\n",
      "        [13.4363],\n",
      "        [ 7.2186],\n",
      "        [15.1420],\n",
      "        [ 7.8535],\n",
      "        [ 9.1022],\n",
      "        [11.5301],\n",
      "        [ 9.3373],\n",
      "        [14.1154],\n",
      "        [ 6.0222],\n",
      "        [10.4383],\n",
      "        [ 5.8107],\n",
      "        [ 7.6207],\n",
      "        [13.8437],\n",
      "        [12.9901],\n",
      "        [ 5.7757],\n",
      "        [ 6.9662],\n",
      "        [16.0400],\n",
      "        [ 8.2151],\n",
      "        [ 8.3822],\n",
      "        [10.3038],\n",
      "        [ 9.9178],\n",
      "        [ 6.6295],\n",
      "        [ 9.1866],\n",
      "        [11.4324],\n",
      "        [11.0210],\n",
      "        [ 6.5013],\n",
      "        [ 7.6513],\n",
      "        [ 9.6466],\n",
      "        [10.0438],\n",
      "        [ 5.8107],\n",
      "        [11.1632],\n",
      "        [ 8.7869],\n",
      "        [10.9170],\n",
      "        [10.4953],\n",
      "        [ 6.5829],\n",
      "        [ 8.2667],\n",
      "        [16.6450],\n",
      "        [14.3693]], device='mps:0')\n",
      "tensor([2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0,\n",
      "        0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 3, 2, 3, 0, 2, 2,\n",
      "        0, 0, 2, 3, 2, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 3, 3, 0, 0, 0, 2, 2, 3,\n",
      "        0, 2, 2, 3, 1, 0, 0, 2, 0, 3, 2, 0, 0, 0, 2, 0, 0, 2, 0, 3, 0, 2, 3, 0,\n",
      "        0, 0, 3, 3, 0, 2, 0, 3, 2, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0,\n",
      "        2, 0, 2, 3, 0, 3, 2, 1], device='mps:0')\n",
      "Batch 2 of 448\n",
      "tensor([[ 8.3712],\n",
      "        [ 7.0626],\n",
      "        [11.6128],\n",
      "        [11.8867],\n",
      "        [ 7.8236],\n",
      "        [10.1809],\n",
      "        [ 9.8985],\n",
      "        [16.6725],\n",
      "        [14.8765],\n",
      "        [14.5972],\n",
      "        [10.5338],\n",
      "        [16.3658],\n",
      "        [19.6567],\n",
      "        [ 5.4638],\n",
      "        [10.4795],\n",
      "        [16.1386],\n",
      "        [21.8990],\n",
      "        [ 9.5513],\n",
      "        [10.7718],\n",
      "        [ 7.4071],\n",
      "        [ 6.4001],\n",
      "        [ 9.4721],\n",
      "        [12.6259],\n",
      "        [14.7992],\n",
      "        [11.4324],\n",
      "        [11.6206],\n",
      "        [ 7.7849],\n",
      "        [15.1388],\n",
      "        [ 8.2340],\n",
      "        [10.2271],\n",
      "        [10.1043],\n",
      "        [ 5.7731],\n",
      "        [ 6.7198],\n",
      "        [13.1790],\n",
      "        [ 8.1599],\n",
      "        [11.9989],\n",
      "        [ 8.3353],\n",
      "        [ 5.9504],\n",
      "        [14.8354],\n",
      "        [ 7.5800],\n",
      "        [ 9.5538],\n",
      "        [ 9.3871],\n",
      "        [ 5.2195],\n",
      "        [ 8.4419],\n",
      "        [ 9.5070],\n",
      "        [ 8.8476],\n",
      "        [ 9.9593],\n",
      "        [10.7258],\n",
      "        [ 9.3921],\n",
      "        [ 9.4721],\n",
      "        [18.3968],\n",
      "        [ 9.0086],\n",
      "        [20.9982],\n",
      "        [10.0825],\n",
      "        [17.0716],\n",
      "        [12.5926],\n",
      "        [13.1270],\n",
      "        [12.4035],\n",
      "        [13.4198],\n",
      "        [ 7.4375],\n",
      "        [ 8.4454],\n",
      "        [13.8300],\n",
      "        [16.3658],\n",
      "        [10.6190],\n",
      "        [17.7073],\n",
      "        [20.1248],\n",
      "        [ 6.5890],\n",
      "        [12.5926],\n",
      "        [16.9512],\n",
      "        [ 8.6473],\n",
      "        [ 7.9929],\n",
      "        [ 6.6984],\n",
      "        [ 6.9033],\n",
      "        [17.3022],\n",
      "        [13.1182],\n",
      "        [20.9101],\n",
      "        [12.4147],\n",
      "        [ 9.5809],\n",
      "        [17.6032],\n",
      "        [19.7826],\n",
      "        [ 5.7923],\n",
      "        [10.8984],\n",
      "        [ 6.2600],\n",
      "        [ 9.3016],\n",
      "        [ 7.7850],\n",
      "        [10.7718],\n",
      "        [ 9.3182],\n",
      "        [ 7.5110],\n",
      "        [ 8.7463],\n",
      "        [17.5698],\n",
      "        [21.2167],\n",
      "        [10.1454],\n",
      "        [ 9.5538],\n",
      "        [ 8.4446],\n",
      "        [13.6636],\n",
      "        [10.0438],\n",
      "        [ 5.6165],\n",
      "        [ 6.3288],\n",
      "        [ 5.7507],\n",
      "        [16.1249],\n",
      "        [ 6.8381],\n",
      "        [15.1388],\n",
      "        [ 8.5159],\n",
      "        [12.5926],\n",
      "        [10.5583],\n",
      "        [ 9.6275],\n",
      "        [13.0421],\n",
      "        [ 8.3872],\n",
      "        [10.6897],\n",
      "        [ 9.5672],\n",
      "        [ 7.0214],\n",
      "        [ 6.3256],\n",
      "        [ 6.9033],\n",
      "        [11.6128],\n",
      "        [16.1249],\n",
      "        [ 6.5890],\n",
      "        [ 9.1620],\n",
      "        [10.2275],\n",
      "        [ 8.8827],\n",
      "        [ 9.9341],\n",
      "        [21.4195],\n",
      "        [14.3693],\n",
      "        [ 7.4590],\n",
      "        [11.9141],\n",
      "        [12.0341],\n",
      "        [11.7520],\n",
      "        [ 8.0532],\n",
      "        [11.3413]], device='mps:0')\n",
      "tensor([2, 0, 2, 0, 0, 0, 0, 0, 2, 1, 2, 2, 3, 2, 2, 2, 0, 0, 2, 2, 0, 3, 2, 2,\n",
      "        0, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0,\n",
      "        2, 3, 3, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 0, 2, 2, 3, 0, 2, 2, 0, 0, 3, 2,\n",
      "        1, 3, 2, 3, 2, 3, 2, 0, 0, 2, 2, 2, 3, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0,\n",
      "        2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 1,\n",
      "        0, 1, 0, 3, 2, 2, 2, 2], device='mps:0')\n",
      "Batch 3 of 448\n",
      "tensor([[ 8.6747],\n",
      "        [11.5000],\n",
      "        [ 6.2600],\n",
      "        [13.9423],\n",
      "        [ 9.2690],\n",
      "        [16.4063],\n",
      "        [ 5.2036],\n",
      "        [ 8.8476],\n",
      "        [ 5.8662],\n",
      "        [ 6.9662],\n",
      "        [ 8.3900],\n",
      "        [ 5.2036],\n",
      "        [ 6.8677],\n",
      "        [ 8.4454],\n",
      "        [15.0840],\n",
      "        [12.2728],\n",
      "        [12.5378],\n",
      "        [ 7.9409],\n",
      "        [ 6.9717],\n",
      "        [ 9.1899],\n",
      "        [ 5.1729],\n",
      "        [12.1190],\n",
      "        [ 9.5864],\n",
      "        [10.9170],\n",
      "        [12.4147],\n",
      "        [ 9.8469],\n",
      "        [ 8.5110],\n",
      "        [ 7.9875],\n",
      "        [13.8277],\n",
      "        [ 8.6806],\n",
      "        [15.8889],\n",
      "        [10.5338],\n",
      "        [ 9.0667],\n",
      "        [ 7.9956],\n",
      "        [ 5.6251],\n",
      "        [ 8.8587],\n",
      "        [ 9.6006],\n",
      "        [ 6.0272],\n",
      "        [ 6.2927],\n",
      "        [10.4378],\n",
      "        [12.5520],\n",
      "        [ 6.0934],\n",
      "        [ 9.4774],\n",
      "        [11.8808],\n",
      "        [ 8.2036],\n",
      "        [ 6.1913],\n",
      "        [ 8.4452],\n",
      "        [ 6.5089],\n",
      "        [ 8.4419],\n",
      "        [ 5.4691],\n",
      "        [ 6.7885],\n",
      "        [12.8065],\n",
      "        [14.7992],\n",
      "        [ 7.7685],\n",
      "        [10.4986],\n",
      "        [ 7.0922],\n",
      "        [ 7.0324],\n",
      "        [ 5.8465],\n",
      "        [16.0449],\n",
      "        [13.6356],\n",
      "        [ 7.4071],\n",
      "        [ 9.5538],\n",
      "        [10.7418],\n",
      "        [11.0210],\n",
      "        [ 8.2535],\n",
      "        [ 9.7348],\n",
      "        [ 8.7623],\n",
      "        [11.7526],\n",
      "        [13.6197],\n",
      "        [12.0127],\n",
      "        [ 6.5829],\n",
      "        [10.1535],\n",
      "        [ 8.5302],\n",
      "        [ 5.3705],\n",
      "        [17.1018],\n",
      "        [13.0196],\n",
      "        [ 9.6493],\n",
      "        [ 8.6473],\n",
      "        [15.5467],\n",
      "        [11.3413],\n",
      "        [ 9.6034],\n",
      "        [18.0222],\n",
      "        [ 8.5602],\n",
      "        [ 7.2101],\n",
      "        [14.5424],\n",
      "        [15.2242],\n",
      "        [ 5.7616],\n",
      "        [ 5.8107],\n",
      "        [ 6.2927],\n",
      "        [ 9.9619],\n",
      "        [13.0885],\n",
      "        [11.2568],\n",
      "        [ 9.6055],\n",
      "        [17.7534],\n",
      "        [13.0196],\n",
      "        [16.1249],\n",
      "        [10.0825],\n",
      "        [ 5.6411],\n",
      "        [ 8.5110],\n",
      "        [11.8341],\n",
      "        [ 7.0380],\n",
      "        [13.6636],\n",
      "        [15.1825],\n",
      "        [15.6513],\n",
      "        [ 6.8024],\n",
      "        [10.8300],\n",
      "        [ 8.6943],\n",
      "        [ 5.4965],\n",
      "        [ 9.5731],\n",
      "        [ 6.2298],\n",
      "        [10.9170],\n",
      "        [15.0792],\n",
      "        [ 6.2050],\n",
      "        [ 6.4110],\n",
      "        [ 5.0552],\n",
      "        [ 9.7593],\n",
      "        [12.2311],\n",
      "        [ 6.5753],\n",
      "        [13.1270],\n",
      "        [10.9034],\n",
      "        [ 5.7757],\n",
      "        [ 6.6272],\n",
      "        [ 7.4398],\n",
      "        [10.0084],\n",
      "        [11.1804],\n",
      "        [16.6725],\n",
      "        [18.2029],\n",
      "        [ 6.0874]], device='mps:0')\n",
      "tensor([2, 2, 2, 0, 1, 2, 2, 0, 0, 0, 2, 2, 0, 3, 2, 2, 2, 0, 1, 1, 0, 0, 0, 2,\n",
      "        2, 2, 0, 3, 0, 0, 0, 2, 3, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 1, 2, 0, 0,\n",
      "        0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0, 1, 2, 2, 3, 0, 1,\n",
      "        2, 0, 0, 2, 3, 0, 3, 0, 2, 3, 2, 1, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2,\n",
      "        2, 3, 0, 0, 0, 2, 3, 3, 2, 3, 2, 0, 2, 2, 2, 0, 1, 0, 0, 2, 3, 2, 2, 2,\n",
      "        2, 0, 0, 2, 2, 0, 2, 1], device='mps:0')\n",
      "Batch 4 of 448\n",
      "tensor([[ 5.8848],\n",
      "        [ 7.5171],\n",
      "        [ 9.9400],\n",
      "        [13.6521],\n",
      "        [ 6.2298],\n",
      "        [ 9.2523],\n",
      "        [12.4229],\n",
      "        [10.8079],\n",
      "        [ 7.4652],\n",
      "        [ 8.0888],\n",
      "        [14.3613],\n",
      "        [ 8.9052],\n",
      "        [13.9368],\n",
      "        [ 7.1200],\n",
      "        [10.2713],\n",
      "        [ 7.5116],\n",
      "        [11.8182],\n",
      "        [11.0214],\n",
      "        [ 8.4610],\n",
      "        [ 7.4564],\n",
      "        [ 6.3612],\n",
      "        [19.7932],\n",
      "        [ 6.4685],\n",
      "        [ 8.5734],\n",
      "        [ 6.2576],\n",
      "        [12.6259],\n",
      "        [ 6.2570],\n",
      "        [ 9.1126],\n",
      "        [ 7.6457],\n",
      "        [12.9977],\n",
      "        [ 6.7553],\n",
      "        [12.4807],\n",
      "        [14.2133],\n",
      "        [11.3413],\n",
      "        [ 7.1939],\n",
      "        [11.1632],\n",
      "        [ 7.7498],\n",
      "        [14.4679],\n",
      "        [ 5.2036],\n",
      "        [15.9847],\n",
      "        [ 8.6747],\n",
      "        [15.0681],\n",
      "        [10.1454],\n",
      "        [ 9.1756],\n",
      "        [ 6.0272],\n",
      "        [ 9.3921],\n",
      "        [11.2291],\n",
      "        [13.0585],\n",
      "        [12.0395],\n",
      "        [11.3665],\n",
      "        [ 8.4529],\n",
      "        [ 5.8107],\n",
      "        [ 8.5026],\n",
      "        [16.9512],\n",
      "        [11.0214],\n",
      "        [12.1221],\n",
      "        [ 5.4446],\n",
      "        [11.8808],\n",
      "        [17.3243],\n",
      "        [12.5213],\n",
      "        [ 7.5631],\n",
      "        [ 8.0702],\n",
      "        [17.4467],\n",
      "        [ 6.1394],\n",
      "        [11.8259],\n",
      "        [11.3008],\n",
      "        [ 9.0826],\n",
      "        [ 9.4636],\n",
      "        [ 7.5171],\n",
      "        [ 6.1394],\n",
      "        [11.2568],\n",
      "        [ 5.4198],\n",
      "        [17.3022],\n",
      "        [ 6.5556],\n",
      "        [10.0026],\n",
      "        [ 7.7965],\n",
      "        [11.9438],\n",
      "        [12.2563],\n",
      "        [ 6.5447],\n",
      "        [12.4450],\n",
      "        [12.9895],\n",
      "        [11.5827],\n",
      "        [14.3536],\n",
      "        [14.4679],\n",
      "        [20.9271],\n",
      "        [ 6.1208],\n",
      "        [ 9.5728],\n",
      "        [ 8.5302],\n",
      "        [ 8.2120],\n",
      "        [18.6460],\n",
      "        [12.4808],\n",
      "        [14.2960],\n",
      "        [11.3413],\n",
      "        [13.0224],\n",
      "        [ 8.2809],\n",
      "        [12.1221],\n",
      "        [ 9.9398],\n",
      "        [ 9.1729],\n",
      "        [11.6128],\n",
      "        [15.4678],\n",
      "        [10.6514],\n",
      "        [12.0975],\n",
      "        [14.5144],\n",
      "        [14.5260],\n",
      "        [ 7.3331],\n",
      "        [11.2810],\n",
      "        [17.1018],\n",
      "        [ 5.5946],\n",
      "        [15.9031],\n",
      "        [10.4986],\n",
      "        [ 6.2215],\n",
      "        [17.3482],\n",
      "        [ 8.8745],\n",
      "        [10.0086],\n",
      "        [ 9.3103],\n",
      "        [ 5.6219],\n",
      "        [10.9641],\n",
      "        [ 9.5044],\n",
      "        [ 7.3994],\n",
      "        [ 9.6656],\n",
      "        [ 7.6780],\n",
      "        [ 7.6207],\n",
      "        [11.1775],\n",
      "        [ 9.2718],\n",
      "        [10.2736],\n",
      "        [ 6.0222],\n",
      "        [ 7.3830],\n",
      "        [ 6.0874]], device='mps:0')\n",
      "tensor([0, 0, 2, 2, 2, 3, 2, 1, 3, 3, 2, 0, 2, 0, 2, 2, 3, 0, 1, 2, 2, 0, 0, 2,\n",
      "        2, 2, 0, 0, 2, 0, 0, 3, 0, 0, 2, 2, 0, 0, 2, 0, 2, 3, 2, 0, 0, 2, 2, 0,\n",
      "        3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 3, 2, 0, 2, 3, 2, 0, 2, 0, 2,\n",
      "        3, 3, 3, 2, 2, 0, 0, 0, 1, 0, 3, 0, 3, 0, 2, 2, 0, 2, 3, 3, 0, 0, 0, 0,\n",
      "        0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 3, 0, 2, 0, 0, 0, 0, 0, 0, 3, 3, 0,\n",
      "        0, 2, 2, 0, 2, 3, 0, 1], device='mps:0')\n",
      "Batch 5 of 448\n",
      "tensor([[10.3698],\n",
      "        [ 5.8929],\n",
      "        [11.2867],\n",
      "        [11.1880],\n",
      "        [10.1887],\n",
      "        [ 7.7935],\n",
      "        [ 9.0826],\n",
      "        [ 9.6034],\n",
      "        [ 7.8866],\n",
      "        [16.4967],\n",
      "        [ 7.4590],\n",
      "        [ 6.0222],\n",
      "        [11.6650],\n",
      "        [12.5762],\n",
      "        [ 5.4522],\n",
      "        [ 9.1427],\n",
      "        [ 9.5097],\n",
      "        [ 8.5327],\n",
      "        [14.5424],\n",
      "        [ 7.5603],\n",
      "        [ 8.5327],\n",
      "        [ 8.2206],\n",
      "        [ 9.9702],\n",
      "        [20.8418],\n",
      "        [11.3747],\n",
      "        [18.1290],\n",
      "        [12.9430],\n",
      "        [13.5152],\n",
      "        [ 7.3441],\n",
      "        [ 8.3900],\n",
      "        [ 6.4296],\n",
      "        [13.5951],\n",
      "        [ 9.5864],\n",
      "        [ 6.3201],\n",
      "        [13.1182],\n",
      "        [ 5.8662],\n",
      "        [ 6.4904],\n",
      "        [11.3413],\n",
      "        [ 7.1743],\n",
      "        [ 9.5562],\n",
      "        [ 8.7075],\n",
      "        [13.3708],\n",
      "        [10.2275],\n",
      "        [ 7.5800],\n",
      "        [15.7246],\n",
      "        [19.6567],\n",
      "        [10.7939],\n",
      "        [14.8711],\n",
      "        [ 8.7869],\n",
      "        [14.3207],\n",
      "        [ 8.8389],\n",
      "        [ 8.6254],\n",
      "        [11.5274],\n",
      "        [15.7252],\n",
      "        [10.9749],\n",
      "        [14.3613],\n",
      "        [ 6.2494],\n",
      "        [ 7.4926],\n",
      "        [ 7.2186],\n",
      "        [ 9.0333],\n",
      "        [ 8.8827],\n",
      "        [11.3386],\n",
      "        [13.6581],\n",
      "        [ 8.7623],\n",
      "        [11.1360],\n",
      "        [17.3454],\n",
      "        [ 8.5110],\n",
      "        [ 7.8040],\n",
      "        [14.0250],\n",
      "        [12.4147],\n",
      "        [13.0990],\n",
      "        [12.2393],\n",
      "        [17.4687],\n",
      "        [11.3413],\n",
      "        [ 5.6548],\n",
      "        [16.0284],\n",
      "        [10.0743],\n",
      "        [15.1585],\n",
      "        [10.9884],\n",
      "        [ 5.4577],\n",
      "        [16.4452],\n",
      "        [16.3658],\n",
      "        [ 8.7294],\n",
      "        [ 9.1022],\n",
      "        [16.1523],\n",
      "        [ 7.1032],\n",
      "        [ 5.7757],\n",
      "        [16.7574],\n",
      "        [ 9.9346],\n",
      "        [17.5698],\n",
      "        [16.0400],\n",
      "        [13.8437],\n",
      "        [14.7417],\n",
      "        [ 8.8281],\n",
      "        [ 9.1866],\n",
      "        [13.3127],\n",
      "        [15.9546],\n",
      "        [11.9989],\n",
      "        [13.6197],\n",
      "        [21.1761],\n",
      "        [ 7.8889],\n",
      "        [ 8.7463],\n",
      "        [ 8.9708],\n",
      "        [12.3219],\n",
      "        [ 6.5529],\n",
      "        [13.9099],\n",
      "        [ 5.6439],\n",
      "        [ 8.5650],\n",
      "        [19.3499],\n",
      "        [ 9.5815],\n",
      "        [10.4433],\n",
      "        [ 9.2690],\n",
      "        [12.5926],\n",
      "        [15.2682],\n",
      "        [10.1809],\n",
      "        [14.2057],\n",
      "        [20.2748],\n",
      "        [ 9.5097],\n",
      "        [ 5.7430],\n",
      "        [15.0792],\n",
      "        [14.5419],\n",
      "        [10.7361],\n",
      "        [ 7.7547],\n",
      "        [14.1154],\n",
      "        [ 8.8281],\n",
      "        [ 7.1524],\n",
      "        [ 8.5570],\n",
      "        [10.0545]], device='mps:0')\n",
      "tensor([2, 0, 2, 0, 2, 0, 3, 2, 0, 0, 0, 3, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2,\n",
      "        2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 3, 2, 2, 3, 3, 2, 3,\n",
      "        0, 3, 0, 0, 0, 2, 2, 2, 0, 2, 3, 0, 0, 3, 0, 1, 0, 0, 0, 3, 0, 2, 0, 0,\n",
      "        0, 0, 0, 3, 0, 0, 2, 2, 3, 2, 0, 3, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0,\n",
      "        0, 0, 2, 0, 3, 2, 2, 0, 2, 1, 0, 1, 3, 2, 3, 1, 2, 3, 0, 0, 2, 0, 2, 0,\n",
      "        2, 0, 2, 0, 2, 2, 2, 2], device='mps:0')\n",
      "Batch 6 of 448\n",
      "tensor([[19.6567],\n",
      "        [10.1318],\n",
      "        [12.8993],\n",
      "        [13.4418],\n",
      "        [10.1535],\n",
      "        [ 5.1894],\n",
      "        [14.0250],\n",
      "        [ 7.6946],\n",
      "        [10.1783],\n",
      "        [19.2072],\n",
      "        [10.0989],\n",
      "        [ 9.9287],\n",
      "        [11.5000],\n",
      "        [ 8.3680],\n",
      "        [13.9368],\n",
      "        [ 6.5090],\n",
      "        [ 7.0736],\n",
      "        [ 5.7123],\n",
      "        [13.4363],\n",
      "        [ 9.3921],\n",
      "        [11.8565],\n",
      "        [ 8.8859],\n",
      "        [ 9.4636],\n",
      "        [15.3250],\n",
      "        [ 8.0345],\n",
      "        [ 7.1743],\n",
      "        [ 9.9593],\n",
      "        [15.1420],\n",
      "        [11.7964],\n",
      "        [ 8.3680],\n",
      "        [ 7.0704],\n",
      "        [14.1674],\n",
      "        [ 7.4926],\n",
      "        [ 6.8677],\n",
      "        [ 8.7463],\n",
      "        [ 9.4002],\n",
      "        [ 5.1735],\n",
      "        [12.8993],\n",
      "        [ 5.5787],\n",
      "        [ 9.3921],\n",
      "        [ 5.6362],\n",
      "        [13.4362],\n",
      "        [ 9.5672],\n",
      "        [ 5.5240],\n",
      "        [ 8.3353],\n",
      "        [10.4492],\n",
      "        [ 6.7664],\n",
      "        [10.5780],\n",
      "        [ 6.5556],\n",
      "        [ 9.9038],\n",
      "        [21.8990],\n",
      "        [15.8889],\n",
      "        [11.0210],\n",
      "        [ 6.2303],\n",
      "        [15.7246],\n",
      "        [10.6514],\n",
      "        [10.5617],\n",
      "        [ 6.3256],\n",
      "        [ 8.5650],\n",
      "        [10.1421],\n",
      "        [11.7055],\n",
      "        [ 8.1304],\n",
      "        [18.8814],\n",
      "        [ 6.4214],\n",
      "        [13.8958],\n",
      "        [ 5.6411],\n",
      "        [11.1775],\n",
      "        [11.6891],\n",
      "        [ 7.2186],\n",
      "        [14.1154],\n",
      "        [10.1450],\n",
      "        [14.1449],\n",
      "        [ 5.9504],\n",
      "        [ 8.4454],\n",
      "        [13.3127],\n",
      "        [ 7.0324],\n",
      "        [14.1120],\n",
      "        [ 6.9033],\n",
      "        [11.8862],\n",
      "        [12.4857],\n",
      "        [15.4537],\n",
      "        [12.0341],\n",
      "        [10.4686],\n",
      "        [14.1449],\n",
      "        [ 6.6355],\n",
      "        [19.7826],\n",
      "        [ 8.8696],\n",
      "        [ 5.7979],\n",
      "        [10.1893],\n",
      "        [12.2481],\n",
      "        [10.8300],\n",
      "        [ 9.4002],\n",
      "        [ 9.6192],\n",
      "        [ 6.7446],\n",
      "        [ 7.1826],\n",
      "        [13.1270],\n",
      "        [17.4467],\n",
      "        [12.8663],\n",
      "        [15.1886],\n",
      "        [ 8.8746],\n",
      "        [11.2291],\n",
      "        [ 5.7757],\n",
      "        [16.4447],\n",
      "        [17.9401],\n",
      "        [ 7.9442],\n",
      "        [ 6.8485],\n",
      "        [10.4433],\n",
      "        [11.5905],\n",
      "        [ 5.5727],\n",
      "        [14.1120],\n",
      "        [11.6206],\n",
      "        [12.1190],\n",
      "        [ 6.5529],\n",
      "        [ 8.5986],\n",
      "        [ 6.4981],\n",
      "        [ 8.3900],\n",
      "        [10.0961],\n",
      "        [19.9847],\n",
      "        [ 7.8236],\n",
      "        [12.8663],\n",
      "        [11.4377],\n",
      "        [ 8.4644],\n",
      "        [ 5.1735],\n",
      "        [ 9.7561],\n",
      "        [13.9099],\n",
      "        [ 7.5253],\n",
      "        [ 9.1346],\n",
      "        [ 9.4414]], device='mps:0')\n",
      "tensor([3, 0, 2, 0, 1, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 3, 2, 3,\n",
      "        2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 3, 2,\n",
      "        3, 0, 0, 0, 1, 1, 3, 2, 3, 2, 1, 0, 2, 2, 0, 2, 2, 3, 2, 2, 3, 0, 2, 2,\n",
      "        0, 3, 0, 0, 0, 1, 0, 0, 2, 2, 3, 2, 2, 0, 0, 0, 0, 0, 3, 2, 2, 2, 2, 2,\n",
      "        3, 0, 0, 3, 2, 2, 0, 3, 2, 0, 3, 2, 2, 0, 0, 0, 2, 0, 2, 2, 2, 3, 0, 0,\n",
      "        0, 0, 2, 2, 1, 0, 2, 1], device='mps:0')\n",
      "Batch 7 of 448\n",
      "tensor([[16.1413],\n",
      "        [11.3063],\n",
      "        [ 9.0497],\n",
      "        [12.4229],\n",
      "        [11.0216],\n",
      "        [13.6439],\n",
      "        [ 9.1346],\n",
      "        [13.4309],\n",
      "        [ 7.0100],\n",
      "        [12.0975],\n",
      "        [ 7.7985],\n",
      "        [19.7932],\n",
      "        [12.2837],\n",
      "        [16.1380],\n",
      "        [ 6.4898],\n",
      "        [13.3127],\n",
      "        [10.1893],\n",
      "        [ 8.6912],\n",
      "        [12.4999],\n",
      "        [ 7.4400],\n",
      "        [ 9.5731],\n",
      "        [ 6.0031],\n",
      "        [ 8.4009],\n",
      "        [ 8.0341],\n",
      "        [ 7.8593],\n",
      "        [ 7.1939],\n",
      "        [14.8573],\n",
      "        [ 9.7753],\n",
      "        [ 9.5731],\n",
      "        [ 6.7280],\n",
      "        [17.1927],\n",
      "        [ 5.8218],\n",
      "        [ 7.4125],\n",
      "        [12.5378],\n",
      "        [ 8.7136],\n",
      "        [ 8.7376],\n",
      "        [ 5.8328],\n",
      "        [ 9.7431],\n",
      "        [11.5000],\n",
      "        [17.7069],\n",
      "        [17.3454],\n",
      "        [15.7794],\n",
      "        [ 7.6562],\n",
      "        [11.0873],\n",
      "        [19.7826],\n",
      "        [ 6.4110],\n",
      "        [15.4678],\n",
      "        [10.0136],\n",
      "        [10.2900],\n",
      "        [ 8.8253],\n",
      "        [ 8.5302],\n",
      "        [ 8.5650],\n",
      "        [11.6128],\n",
      "        [11.9086],\n",
      "        [ 6.2570],\n",
      "        [20.2722],\n",
      "        [13.7068],\n",
      "        [ 7.2101],\n",
      "        [ 8.6747],\n",
      "        [13.9449],\n",
      "        [12.2536],\n",
      "        [16.3658],\n",
      "        [13.0224],\n",
      "        [ 8.5650],\n",
      "        [13.6581],\n",
      "        [ 6.9662],\n",
      "        [12.1632],\n",
      "        [15.0185],\n",
      "        [ 6.8485],\n",
      "        [11.2867],\n",
      "        [ 9.9039],\n",
      "        [ 5.1894],\n",
      "        [14.5424],\n",
      "        [ 7.8535],\n",
      "        [ 7.4398],\n",
      "        [ 8.5465],\n",
      "        [14.9613],\n",
      "        [13.7068],\n",
      "        [ 9.9038],\n",
      "        [15.6157],\n",
      "        [ 7.1311],\n",
      "        [ 9.9287],\n",
      "        [ 7.0324],\n",
      "        [ 8.4446],\n",
      "        [10.0218],\n",
      "        [12.8531],\n",
      "        [ 5.5787],\n",
      "        [11.5301],\n",
      "        [13.9423],\n",
      "        [11.6650],\n",
      "        [17.6747],\n",
      "        [17.9287],\n",
      "        [ 9.5896],\n",
      "        [15.1388],\n",
      "        [10.4713],\n",
      "        [17.6636],\n",
      "        [11.1632],\n",
      "        [16.1249],\n",
      "        [13.8277],\n",
      "        [ 9.1899],\n",
      "        [16.6094],\n",
      "        [ 7.1364],\n",
      "        [14.4625],\n",
      "        [ 8.3822],\n",
      "        [ 7.6562],\n",
      "        [ 9.9867],\n",
      "        [13.1182],\n",
      "        [ 5.5727],\n",
      "        [ 8.1599],\n",
      "        [ 9.5731],\n",
      "        [ 7.1826],\n",
      "        [ 7.6650],\n",
      "        [11.8752],\n",
      "        [20.2748],\n",
      "        [ 8.8281],\n",
      "        [ 7.0380],\n",
      "        [ 7.7985],\n",
      "        [ 6.6930],\n",
      "        [11.5000],\n",
      "        [ 9.4905],\n",
      "        [ 5.6219],\n",
      "        [10.8841],\n",
      "        [ 6.2570],\n",
      "        [13.1269],\n",
      "        [12.2728],\n",
      "        [17.9893],\n",
      "        [ 5.5562],\n",
      "        [ 6.1913]], device='mps:0')\n",
      "tensor([3, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 1, 0, 0, 0, 2, 2, 2, 3, 2, 3,\n",
      "        2, 2, 0, 0, 2, 2, 0, 1, 2, 2, 0, 3, 2, 3, 2, 2, 0, 2, 3, 0, 0, 0, 0, 2,\n",
      "        0, 2, 2, 3, 2, 0, 0, 0, 3, 1, 2, 0, 0, 2, 0, 3, 0, 0, 0, 1, 0, 2, 2, 2,\n",
      "        0, 2, 0, 2, 0, 3, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0,\n",
      "        2, 2, 0, 1, 0, 0, 0, 0, 3, 0, 2, 2, 2, 2, 2, 3, 3, 2, 2, 0, 2, 0, 2, 2,\n",
      "        0, 2, 0, 0, 2, 2, 2, 2], device='mps:0')\n",
      "Batch 8 of 448\n",
      "tensor([[13.0421],\n",
      "        [ 8.8012],\n",
      "        [ 6.1284],\n",
      "        [13.4198],\n",
      "        [12.2728],\n",
      "        [ 8.8281],\n",
      "        [ 7.3392],\n",
      "        [ 8.8033],\n",
      "        [12.4857],\n",
      "        [11.3747],\n",
      "        [ 6.4898],\n",
      "        [ 8.4454],\n",
      "        [10.3749],\n",
      "        [17.6747],\n",
      "        [10.2709],\n",
      "        [ 9.4002],\n",
      "        [10.9034],\n",
      "        [11.0873],\n",
      "        [ 7.9827],\n",
      "        [ 7.8866],\n",
      "        [ 8.5817],\n",
      "        [ 8.4230],\n",
      "        [ 5.2195],\n",
      "        [ 5.7369],\n",
      "        [11.4324],\n",
      "        [13.6636],\n",
      "        [ 7.9792],\n",
      "        [10.8076],\n",
      "        [ 7.9134],\n",
      "        [ 9.0749],\n",
      "        [14.7992],\n",
      "        [20.8418],\n",
      "        [10.1723],\n",
      "        [15.2242],\n",
      "        [ 7.1524],\n",
      "        [ 6.3864],\n",
      "        [11.9333],\n",
      "        [16.3658],\n",
      "        [13.7725],\n",
      "        [10.4547],\n",
      "        [ 6.5529],\n",
      "        [10.0086],\n",
      "        [11.7877],\n",
      "        [ 6.2303],\n",
      "        [ 6.1208],\n",
      "        [ 8.5570],\n",
      "        [ 7.8177],\n",
      "        [ 7.9164],\n",
      "        [19.3358],\n",
      "        [16.9212],\n",
      "        [10.1477],\n",
      "        [ 9.4363],\n",
      "        [10.0743],\n",
      "        [ 6.6513],\n",
      "        [ 8.7294],\n",
      "        [ 8.5350],\n",
      "        [ 7.0483],\n",
      "        [ 7.9251],\n",
      "        [ 6.2570],\n",
      "        [ 7.0922],\n",
      "        [11.7802],\n",
      "        [ 7.8784],\n",
      "        [16.8614],\n",
      "        [11.5822],\n",
      "        [12.1882],\n",
      "        [ 8.6395],\n",
      "        [15.5828],\n",
      "        [13.5951],\n",
      "        [ 7.8565],\n",
      "        [ 7.6151],\n",
      "        [ 7.0214],\n",
      "        [11.2050],\n",
      "        [12.0695],\n",
      "        [10.9285],\n",
      "        [12.9895],\n",
      "        [10.2112],\n",
      "        [ 7.7772],\n",
      "        [ 9.3349],\n",
      "        [14.8819],\n",
      "        [ 8.2120],\n",
      "        [ 9.1729],\n",
      "        [ 9.1428],\n",
      "        [ 5.3705],\n",
      "        [ 7.6946],\n",
      "        [ 5.6741],\n",
      "        [ 5.5485],\n",
      "        [10.2878],\n",
      "        [13.6526],\n",
      "        [10.1454],\n",
      "        [15.5302],\n",
      "        [ 7.5171],\n",
      "        [14.4104],\n",
      "        [15.3199],\n",
      "        [ 9.8901],\n",
      "        [ 5.7781],\n",
      "        [13.8601],\n",
      "        [ 7.3775],\n",
      "        [ 7.1200],\n",
      "        [ 7.5906],\n",
      "        [12.6013],\n",
      "        [11.5827],\n",
      "        [ 7.4125],\n",
      "        [ 7.9134],\n",
      "        [10.5780],\n",
      "        [ 8.4419],\n",
      "        [12.4063],\n",
      "        [12.9895],\n",
      "        [ 7.6780],\n",
      "        [11.7520],\n",
      "        [10.9120],\n",
      "        [11.3989],\n",
      "        [14.4685],\n",
      "        [12.7458],\n",
      "        [ 9.9400],\n",
      "        [ 6.2029],\n",
      "        [ 9.9178],\n",
      "        [11.3879],\n",
      "        [ 8.2120],\n",
      "        [14.5287],\n",
      "        [12.1190],\n",
      "        [11.9710],\n",
      "        [16.6719],\n",
      "        [ 6.5829],\n",
      "        [10.3038],\n",
      "        [10.3749],\n",
      "        [12.9430],\n",
      "        [15.1886],\n",
      "        [16.8614]], device='mps:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2,\n",
      "        0, 2, 3, 2, 1, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 1, 0, 2, 0, 0,\n",
      "        3, 0, 2, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 3, 0, 3, 1, 2, 0, 0, 3, 2, 0,\n",
      "        0, 3, 1, 3, 2, 2, 2, 0, 2, 1, 0, 2, 2, 2, 2, 0, 2, 3, 0, 0, 0, 0, 2, 0,\n",
      "        2, 0, 2, 0, 0, 2, 1, 2, 0, 2, 1, 0, 2, 0, 2, 3, 3, 2, 2, 2, 0, 0, 0, 0,\n",
      "        2, 2, 0, 0, 0, 2, 0, 3], device='mps:0')\n",
      "Batch 9 of 448\n",
      "tensor([[ 9.8711],\n",
      "        [ 7.3994],\n",
      "        [13.8300],\n",
      "        [11.2050],\n",
      "        [12.5926],\n",
      "        [12.4450],\n",
      "        [12.4857],\n",
      "        [ 5.1735],\n",
      "        [11.3419],\n",
      "        [16.6450],\n",
      "        [ 6.4541],\n",
      "        [21.8990],\n",
      "        [ 7.4400],\n",
      "        [ 7.9798],\n",
      "        [15.4212],\n",
      "        [10.7718],\n",
      "        [ 9.4721],\n",
      "        [10.1969],\n",
      "        [15.2682],\n",
      "        [13.3264],\n",
      "        [11.0873],\n",
      "        [ 5.6439],\n",
      "        [19.7826],\n",
      "        [ 6.9805],\n",
      "        [14.3613],\n",
      "        [ 8.2064],\n",
      "        [12.4150],\n",
      "        [11.0976],\n",
      "        [ 5.1894],\n",
      "        [16.4233],\n",
      "        [11.5274],\n",
      "        [ 7.9086],\n",
      "        [ 7.7526],\n",
      "        [12.2311],\n",
      "        [ 5.5562],\n",
      "        [18.4822],\n",
      "        [17.7073],\n",
      "        [ 8.8312],\n",
      "        [ 7.3824],\n",
      "        [11.9333],\n",
      "        [ 9.8711],\n",
      "        [ 8.6725],\n",
      "        [13.6279],\n",
      "        [ 9.5562],\n",
      "        [13.3127],\n",
      "        [ 9.4414],\n",
      "        [ 6.8677],\n",
      "        [ 8.4452],\n",
      "        [14.8765],\n",
      "        [13.1046],\n",
      "        [16.4967],\n",
      "        [17.2611],\n",
      "        [ 5.3620],\n",
      "        [ 7.9251],\n",
      "        [ 6.6191],\n",
      "        [14.1509],\n",
      "        [ 5.6251],\n",
      "        [12.2728],\n",
      "        [14.0250],\n",
      "        [ 7.9792],\n",
      "        [ 9.2940],\n",
      "        [15.7471],\n",
      "        [ 8.7846],\n",
      "        [ 9.1570],\n",
      "        [16.3461],\n",
      "        [11.9141],\n",
      "        [12.8362],\n",
      "        [11.9989],\n",
      "        [ 7.4071],\n",
      "        [ 9.4414],\n",
      "        [13.8799],\n",
      "        [ 8.8012],\n",
      "        [11.8341],\n",
      "        [ 5.8306],\n",
      "        [19.7932],\n",
      "        [14.1449],\n",
      "        [ 9.6712],\n",
      "        [14.3536],\n",
      "        [10.9887],\n",
      "        [ 6.9805],\n",
      "        [14.5424],\n",
      "        [ 9.4414],\n",
      "        [14.2960],\n",
      "        [ 9.4414],\n",
      "        [10.7553],\n",
      "        [ 9.6472],\n",
      "        [12.9107],\n",
      "        [ 8.5650],\n",
      "        [ 9.9593],\n",
      "        [ 8.4667],\n",
      "        [10.0518],\n",
      "        [13.0196],\n",
      "        [15.0298],\n",
      "        [ 8.5327],\n",
      "        [11.5279],\n",
      "        [11.1749],\n",
      "        [14.1887],\n",
      "        [ 7.5110],\n",
      "        [ 8.9762],\n",
      "        [10.4433],\n",
      "        [10.5035],\n",
      "        [ 8.2099],\n",
      "        [13.8437],\n",
      "        [ 7.4016],\n",
      "        [13.6356],\n",
      "        [ 6.4001],\n",
      "        [10.2271],\n",
      "        [ 8.8587],\n",
      "        [15.8889],\n",
      "        [ 6.2215],\n",
      "        [ 7.9442],\n",
      "        [ 6.3809],\n",
      "        [ 7.7685],\n",
      "        [ 7.4398],\n",
      "        [10.0136],\n",
      "        [10.0218],\n",
      "        [ 6.1421],\n",
      "        [ 6.7885],\n",
      "        [ 8.1599],\n",
      "        [13.6279],\n",
      "        [ 5.8328],\n",
      "        [ 6.4001],\n",
      "        [ 8.6664],\n",
      "        [13.1675],\n",
      "        [ 8.6912],\n",
      "        [ 9.6656],\n",
      "        [10.0218],\n",
      "        [15.7307]], device='mps:0')\n",
      "tensor([3, 3, 0, 0, 2, 0, 0, 2, 0, 2, 1, 0, 2, 2, 2, 2, 3, 2, 3, 3, 0, 0, 0, 0,\n",
      "        2, 0, 3, 2, 2, 0, 0, 0, 0, 3, 2, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0,\n",
      "        2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 3, 2, 2, 2, 1, 2, 3, 0, 0, 2, 1, 0, 2,\n",
      "        0, 2, 0, 2, 3, 3, 0, 0, 0, 2, 3, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 0, 2,\n",
      "        0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 3, 0, 0, 2, 0, 3, 0, 2, 0,\n",
      "        2, 0, 0, 0, 0, 0, 0, 2], device='mps:0')\n",
      "Batch 10 of 448\n",
      "tensor([[ 9.2446],\n",
      "        [16.1380],\n",
      "        [11.3879],\n",
      "        [ 7.0704],\n",
      "        [11.9715],\n",
      "        [ 8.0181],\n",
      "        [18.6460],\n",
      "        [12.9430],\n",
      "        [12.5926],\n",
      "        [ 7.8593],\n",
      "        [11.3665],\n",
      "        [ 8.8745],\n",
      "        [ 8.3768],\n",
      "        [ 5.3377],\n",
      "        [ 8.4419],\n",
      "        [10.3776],\n",
      "        [ 9.3487],\n",
      "        [15.1585],\n",
      "        [10.3776],\n",
      "        [ 6.4898],\n",
      "        [ 8.6725],\n",
      "        [14.5424],\n",
      "        [12.9298],\n",
      "        [11.6891],\n",
      "        [11.6891],\n",
      "        [ 9.1428],\n",
      "        [ 9.7675],\n",
      "        [18.8954],\n",
      "        [16.4063],\n",
      "        [ 7.9958],\n",
      "        [12.1632],\n",
      "        [12.7677],\n",
      "        [ 8.2099],\n",
      "        [16.2097],\n",
      "        [ 6.5447],\n",
      "        [11.1420],\n",
      "        [ 7.5576],\n",
      "        [ 6.9033],\n",
      "        [11.7877],\n",
      "        [ 9.0640],\n",
      "        [ 8.4256],\n",
      "        [16.9271],\n",
      "        [ 8.5467],\n",
      "        [10.4215],\n",
      "        [ 5.6741],\n",
      "        [ 9.3373],\n",
      "        [17.7396],\n",
      "        [ 7.3824],\n",
      "        [ 9.0497],\n",
      "        [ 6.5397],\n",
      "        [ 6.0222],\n",
      "        [ 9.1761],\n",
      "        [ 6.0114],\n",
      "        [19.2077],\n",
      "        [11.9601],\n",
      "        [12.9046],\n",
      "        [ 6.1284],\n",
      "        [17.4221],\n",
      "        [ 8.4065],\n",
      "        [ 9.9867],\n",
      "        [18.3968],\n",
      "        [ 6.4685],\n",
      "        [11.1420],\n",
      "        [18.7364],\n",
      "        [ 7.9956],\n",
      "        [13.0934],\n",
      "        [ 7.7526],\n",
      "        [ 9.4277],\n",
      "        [12.0127],\n",
      "        [10.9170],\n",
      "        [ 8.3872],\n",
      "        [14.6404],\n",
      "        [15.7246],\n",
      "        [10.4433],\n",
      "        [11.3063],\n",
      "        [11.0873],\n",
      "        [ 8.1599],\n",
      "        [ 5.2195],\n",
      "        [ 8.7627],\n",
      "        [ 8.0805],\n",
      "        [ 7.4268],\n",
      "        [ 7.3331],\n",
      "        [16.2860],\n",
      "        [ 7.9792],\n",
      "        [ 8.5986],\n",
      "        [15.3250],\n",
      "        [ 8.6039],\n",
      "        [ 7.8319],\n",
      "        [ 9.1023],\n",
      "        [13.5212],\n",
      "        [ 5.9504],\n",
      "        [20.2748],\n",
      "        [ 6.8381],\n",
      "        [12.4857],\n",
      "        [ 8.7819],\n",
      "        [20.2722],\n",
      "        [15.1388],\n",
      "        [ 6.2600],\n",
      "        [17.7074],\n",
      "        [14.3693],\n",
      "        [ 9.5538],\n",
      "        [12.4857],\n",
      "        [11.0210],\n",
      "        [ 9.1346],\n",
      "        [13.4362],\n",
      "        [10.9887],\n",
      "        [ 9.0825],\n",
      "        [10.5338],\n",
      "        [13.6279],\n",
      "        [10.3698],\n",
      "        [17.3022],\n",
      "        [ 7.9251],\n",
      "        [ 7.5282],\n",
      "        [17.3104],\n",
      "        [ 7.0324],\n",
      "        [15.2653],\n",
      "        [ 5.7616],\n",
      "        [10.4492],\n",
      "        [ 6.3940],\n",
      "        [ 8.1304],\n",
      "        [14.6656],\n",
      "        [ 5.2966],\n",
      "        [11.8862],\n",
      "        [ 7.3171],\n",
      "        [ 7.5282],\n",
      "        [11.0927],\n",
      "        [ 7.6946],\n",
      "        [ 6.7363]], device='mps:0')\n",
      "tensor([2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 1, 0, 0, 0, 2,\n",
      "        2, 1, 3, 0, 2, 0, 0, 2, 2, 0, 0, 2, 3, 1, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0,\n",
      "        2, 0, 3, 2, 3, 2, 2, 0, 2, 0, 3, 0, 3, 0, 2, 3, 2, 2, 0, 2, 3, 2, 0, 2,\n",
      "        3, 3, 2, 0, 2, 2, 1, 2, 0, 2, 2, 3, 0, 3, 1, 2, 0, 0, 0, 2, 2, 0, 2, 0,\n",
      "        0, 2, 3, 1, 2, 2, 1, 2, 0, 0, 0, 2, 0, 2, 3, 0, 3, 2, 0, 3, 0, 0, 2, 2,\n",
      "        2, 2, 0, 0, 3, 2, 2, 2], device='mps:0')\n",
      "Batch 11 of 448\n",
      "tensor([[13.1790],\n",
      "        [13.0196],\n",
      "        [ 9.1899],\n",
      "        [11.6891],\n",
      "        [ 7.2729],\n",
      "        [ 8.8281],\n",
      "        [ 7.4926],\n",
      "        [10.5560],\n",
      "        [ 7.8040],\n",
      "        [ 8.2563],\n",
      "        [ 9.6526],\n",
      "        [12.4147],\n",
      "        [15.3939],\n",
      "        [11.7526],\n",
      "        [12.7677],\n",
      "        [15.8889],\n",
      "        [ 9.6034],\n",
      "        [16.9212],\n",
      "        [10.3557],\n",
      "        [ 8.7928],\n",
      "        [17.7534],\n",
      "        [ 8.5461],\n",
      "        [ 6.5890],\n",
      "        [12.1221],\n",
      "        [ 7.7855],\n",
      "        [ 6.4219],\n",
      "        [ 7.3141],\n",
      "        [11.8259],\n",
      "        [ 7.3331],\n",
      "        [10.7939],\n",
      "        [ 6.1394],\n",
      "        [10.4795],\n",
      "        [ 7.4541],\n",
      "        [ 7.6562],\n",
      "        [10.9887],\n",
      "        [ 5.5485],\n",
      "        [12.4147],\n",
      "        [16.9271],\n",
      "        [17.1376],\n",
      "        [13.6521],\n",
      "        [ 6.7446],\n",
      "        [ 7.0133],\n",
      "        [10.1809],\n",
      "        [ 8.8281],\n",
      "        [11.1880],\n",
      "        [ 6.4541],\n",
      "        [17.6439],\n",
      "        [ 9.1598],\n",
      "        [16.6725],\n",
      "        [ 7.6650],\n",
      "        [ 9.0935],\n",
      "        [ 7.7526],\n",
      "        [ 9.0667],\n",
      "        [ 6.1531],\n",
      "        [ 7.4400],\n",
      "        [11.1749],\n",
      "        [ 6.3528],\n",
      "        [ 7.8866],\n",
      "        [ 7.9442],\n",
      "        [ 6.2215],\n",
      "        [ 7.8236],\n",
      "        [ 8.5159],\n",
      "        [10.4547],\n",
      "        [ 7.4926],\n",
      "        [ 7.7389],\n",
      "        [ 5.5787],\n",
      "        [16.0756],\n",
      "        [13.8300],\n",
      "        [ 6.3809],\n",
      "        [10.2713],\n",
      "        [17.4221],\n",
      "        [ 6.1531],\n",
      "        [18.9141],\n",
      "        [ 9.7593],\n",
      "        [11.2810],\n",
      "        [ 5.2036],\n",
      "        [ 7.1743],\n",
      "        [10.1043],\n",
      "        [ 9.6417],\n",
      "        [14.0441],\n",
      "        [ 6.2105],\n",
      "        [12.4808],\n",
      "        [ 7.3141],\n",
      "        [ 5.4522],\n",
      "        [ 6.4597],\n",
      "        [ 9.1899],\n",
      "        [14.1072],\n",
      "        [ 7.7985],\n",
      "        [10.9749],\n",
      "        [ 7.4268],\n",
      "        [14.8711],\n",
      "        [ 5.7369],\n",
      "        [10.0438],\n",
      "        [13.8799],\n",
      "        [13.8277],\n",
      "        [14.4077],\n",
      "        [11.0538],\n",
      "        [14.4055],\n",
      "        [ 8.5794],\n",
      "        [ 7.1032],\n",
      "        [11.7055],\n",
      "        [ 5.6362],\n",
      "        [ 7.7470],\n",
      "        [ 8.1304],\n",
      "        [ 7.7935],\n",
      "        [ 7.4541],\n",
      "        [10.9120],\n",
      "        [ 7.0100],\n",
      "        [ 9.7675],\n",
      "        [ 8.5026],\n",
      "        [10.5885],\n",
      "        [ 8.2036],\n",
      "        [10.3038],\n",
      "        [ 8.2284],\n",
      "        [ 5.1894],\n",
      "        [13.9449],\n",
      "        [16.4342],\n",
      "        [18.0222],\n",
      "        [ 6.2927],\n",
      "        [19.2077],\n",
      "        [ 7.4926],\n",
      "        [ 7.4268],\n",
      "        [19.7826],\n",
      "        [ 7.2428],\n",
      "        [ 9.3647],\n",
      "        [ 7.7985],\n",
      "        [ 5.7979],\n",
      "        [10.7418]], device='mps:0')\n",
      "tensor([0, 2, 1, 2, 0, 2, 2, 3, 3, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0,\n",
      "        2, 3, 3, 0, 2, 2, 2, 2, 0, 3, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 1, 2, 0,\n",
      "        0, 3, 0, 0, 3, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 3, 2, 0, 0,\n",
      "        3, 2, 0, 2, 0, 2, 3, 0, 2, 3, 3, 2, 0, 1, 2, 2, 2, 0, 3, 2, 0, 0, 0, 2,\n",
      "        2, 2, 0, 2, 2, 0, 1, 2, 0, 0, 0, 0, 3, 0, 2, 1, 0, 3, 2, 0, 2, 3, 2, 2,\n",
      "        0, 0, 0, 2, 0, 2, 0, 0], device='mps:0')\n",
      "Batch 12 of 448\n",
      "tensor([[10.9749],\n",
      "        [ 5.4358],\n",
      "        [ 9.6466],\n",
      "        [ 7.7109],\n",
      "        [16.1386],\n",
      "        [ 5.7979],\n",
      "        [ 7.5576],\n",
      "        [14.0250],\n",
      "        [ 6.9662],\n",
      "        [ 7.4400],\n",
      "        [13.0585],\n",
      "        [ 7.4564],\n",
      "        [ 8.4447],\n",
      "        [ 8.7846],\n",
      "        [ 9.6493],\n",
      "        [ 7.3392],\n",
      "        [10.1477],\n",
      "        [ 6.8024],\n",
      "        [ 9.5809],\n",
      "        [ 8.7075],\n",
      "        [15.0185],\n",
      "        [ 6.1421],\n",
      "        [ 8.7404],\n",
      "        [13.4362],\n",
      "        [ 7.8753],\n",
      "        [ 8.6912],\n",
      "        [11.0214],\n",
      "        [12.4857],\n",
      "        [ 8.5350],\n",
      "        [ 9.1620],\n",
      "        [ 8.1599],\n",
      "        [ 7.3141],\n",
      "        [14.2133],\n",
      "        [ 7.4541],\n",
      "        [ 9.3921],\n",
      "        [11.1420],\n",
      "        [ 6.3612],\n",
      "        [ 8.4610],\n",
      "        [17.6032],\n",
      "        [ 6.1284],\n",
      "        [14.5643],\n",
      "        [16.9517],\n",
      "        [15.0840],\n",
      "        [16.4452],\n",
      "        [10.7939],\n",
      "        [11.7964],\n",
      "        [ 9.1570],\n",
      "        [15.4212],\n",
      "        [ 6.4382],\n",
      "        [ 6.8677],\n",
      "        [14.4679],\n",
      "        [11.8182],\n",
      "        [13.3127],\n",
      "        [ 6.4904],\n",
      "        [ 7.4926],\n",
      "        [10.3065],\n",
      "        [17.1018],\n",
      "        [ 6.6295],\n",
      "        [15.1886],\n",
      "        [12.5246],\n",
      "        [ 9.5864],\n",
      "        [14.1887],\n",
      "        [ 8.2262],\n",
      "        [ 5.8005],\n",
      "        [18.6600],\n",
      "        [ 7.9409],\n",
      "        [ 7.4016],\n",
      "        [ 9.0935],\n",
      "        [10.3749],\n",
      "        [15.7252],\n",
      "        [10.0825],\n",
      "        [ 9.2523],\n",
      "        [ 6.0326],\n",
      "        [12.2311],\n",
      "        [ 9.3373],\n",
      "        [10.1893],\n",
      "        [16.1413],\n",
      "        [ 8.5302],\n",
      "        [ 9.4363],\n",
      "        [ 6.5857],\n",
      "        [ 6.1284],\n",
      "        [12.4754],\n",
      "        [ 7.7363],\n",
      "        [14.4520],\n",
      "        [10.4383],\n",
      "        [17.6439],\n",
      "        [13.6521],\n",
      "        [10.4795],\n",
      "        [ 5.8389],\n",
      "        [ 5.5240],\n",
      "        [ 6.3393],\n",
      "        [10.8079],\n",
      "        [10.7882],\n",
      "        [ 6.3612],\n",
      "        [ 9.7697],\n",
      "        [13.6356],\n",
      "        [12.4200],\n",
      "        [ 5.9559],\n",
      "        [ 5.0716],\n",
      "        [12.1190],\n",
      "        [ 8.0970],\n",
      "        [16.5465],\n",
      "        [ 9.1209],\n",
      "        [12.1632],\n",
      "        [ 5.1729],\n",
      "        [ 5.7841],\n",
      "        [ 5.4638],\n",
      "        [10.4713],\n",
      "        [ 6.4898],\n",
      "        [ 8.8476],\n",
      "        [15.2653],\n",
      "        [ 7.7985],\n",
      "        [ 6.5013],\n",
      "        [10.6897],\n",
      "        [ 9.4002],\n",
      "        [11.0927],\n",
      "        [ 6.0934],\n",
      "        [14.5972],\n",
      "        [ 5.6251],\n",
      "        [ 9.4363],\n",
      "        [ 6.3201],\n",
      "        [ 9.5731],\n",
      "        [10.0743],\n",
      "        [11.1278],\n",
      "        [ 9.6330],\n",
      "        [13.1182],\n",
      "        [ 9.7675],\n",
      "        [12.6013]], device='mps:0')\n",
      "tensor([2, 2, 2, 2, 2, 0, 3, 2, 0, 2, 0, 2, 2, 2, 3, 2, 2, 2, 3, 2, 1, 3, 3, 0,\n",
      "        3, 0, 0, 0, 0, 2, 2, 3, 0, 0, 2, 2, 2, 1, 2, 2, 0, 3, 2, 3, 2, 2, 1, 2,\n",
      "        0, 0, 0, 2, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 3,\n",
      "        0, 3, 0, 0, 3, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 0, 0, 2, 1, 0, 2, 2, 0,\n",
      "        2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 1, 2, 3, 2, 0, 2, 2, 2, 2, 1, 2, 0,\n",
      "        2, 2, 0, 0, 2, 2, 3, 0], device='mps:0')\n",
      "Batch 13 of 448\n",
      "tensor([[ 7.7547],\n",
      "        [11.0210],\n",
      "        [ 9.1620],\n",
      "        [ 8.7980],\n",
      "        [ 8.8033],\n",
      "        [11.5822],\n",
      "        [ 9.7316],\n",
      "        [ 8.5465],\n",
      "        [ 9.2523],\n",
      "        [ 9.7675],\n",
      "        [ 7.4071],\n",
      "        [18.9141],\n",
      "        [ 7.9929],\n",
      "        [ 7.8236],\n",
      "        [ 9.2447],\n",
      "        [ 9.2688],\n",
      "        [ 8.2064],\n",
      "        [ 9.1626],\n",
      "        [11.7802],\n",
      "        [ 8.0888],\n",
      "        [ 8.6725],\n",
      "        [10.7308],\n",
      "        [12.9046],\n",
      "        [15.1744],\n",
      "        [10.2879],\n",
      "        [16.9654],\n",
      "        [ 5.7616],\n",
      "        [10.0113],\n",
      "        [17.8551],\n",
      "        [10.1202],\n",
      "        [ 9.4633],\n",
      "        [12.9298],\n",
      "        [19.2072],\n",
      "        [ 6.4904],\n",
      "        [ 8.2284],\n",
      "        [ 8.6395],\n",
      "        [10.4986],\n",
      "        [13.0500],\n",
      "        [ 7.9792],\n",
      "        [ 9.9038],\n",
      "        [13.8437],\n",
      "        [ 9.5864],\n",
      "        [ 5.9559],\n",
      "        [ 8.9127],\n",
      "        [ 7.3171],\n",
      "        [ 9.3349],\n",
      "        [ 9.7074],\n",
      "        [13.6439],\n",
      "        [11.7802],\n",
      "        [11.1775],\n",
      "        [ 7.1743],\n",
      "        [16.9401],\n",
      "        [ 9.8629],\n",
      "        [ 5.4198],\n",
      "        [ 9.5044],\n",
      "        [11.9608],\n",
      "        [ 8.8778],\n",
      "        [ 7.7328],\n",
      "        [ 8.8696],\n",
      "        [11.0927],\n",
      "        [13.6279],\n",
      "        [ 8.9127],\n",
      "        [ 8.7846],\n",
      "        [ 8.6664],\n",
      "        [ 8.4556],\n",
      "        [12.5213],\n",
      "        [11.5274],\n",
      "        [20.9271],\n",
      "        [10.7939],\n",
      "        [ 9.6417],\n",
      "        [12.5602],\n",
      "        [ 7.7219],\n",
      "        [ 8.5465],\n",
      "        [ 7.4564],\n",
      "        [ 8.6747],\n",
      "        [17.5698],\n",
      "        [17.7534],\n",
      "        [17.5179],\n",
      "        [12.4035],\n",
      "        [14.1072],\n",
      "        [13.3264],\n",
      "        [19.2049],\n",
      "        [ 9.1183],\n",
      "        [ 9.1756],\n",
      "        [10.7992],\n",
      "        [ 8.9708],\n",
      "        [ 9.0826],\n",
      "        [14.8711],\n",
      "        [15.7471],\n",
      "        [12.4857],\n",
      "        [ 6.7553],\n",
      "        [13.4418],\n",
      "        [ 6.0874],\n",
      "        [16.7574],\n",
      "        [ 7.1059],\n",
      "        [ 5.9504],\n",
      "        [ 8.0477],\n",
      "        [ 9.5157],\n",
      "        [ 8.8745],\n",
      "        [ 9.1427],\n",
      "        [ 6.9033],\n",
      "        [11.1804],\n",
      "        [ 6.4597],\n",
      "        [ 9.0086],\n",
      "        [ 7.1059],\n",
      "        [13.0934],\n",
      "        [12.6063],\n",
      "        [10.9749],\n",
      "        [12.0395],\n",
      "        [ 7.0100],\n",
      "        [20.8203],\n",
      "        [ 7.7935],\n",
      "        [19.7328],\n",
      "        [10.9859],\n",
      "        [14.7992],\n",
      "        [ 7.1826],\n",
      "        [ 6.2600],\n",
      "        [14.4520],\n",
      "        [12.7458],\n",
      "        [13.6279],\n",
      "        [ 7.8866],\n",
      "        [12.4147],\n",
      "        [12.1221],\n",
      "        [ 8.0039],\n",
      "        [ 9.1839],\n",
      "        [18.3968],\n",
      "        [12.4063],\n",
      "        [16.0756]], device='mps:0')\n",
      "tensor([2, 1, 2, 0, 2, 0, 2, 2, 3, 3, 2, 3, 3, 0, 2, 1, 0, 0, 0, 3, 0, 2, 0, 0,\n",
      "        2, 3, 0, 0, 0, 2, 2, 0, 2, 2, 3, 1, 0, 1, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "        0, 2, 0, 2, 0, 2, 3, 3, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 3, 2, 3, 0, 0,\n",
      "        2, 2, 2, 2, 0, 0, 2, 2, 3, 2, 3, 0, 3, 2, 3, 3, 2, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 2, 1, 2, 0, 0, 0, 2, 0, 2, 3, 0, 3, 0, 0, 2, 2, 2, 2, 3, 3, 0,\n",
      "        0, 2, 0, 2, 2, 3, 2, 2], device='mps:0')\n",
      "Batch 14 of 448\n",
      "tensor([[17.3104],\n",
      "        [ 6.7363],\n",
      "        [14.0441],\n",
      "        [18.6600],\n",
      "        [15.0325],\n",
      "        [ 9.1018],\n",
      "        [ 7.0405],\n",
      "        [ 5.1894],\n",
      "        [ 6.5008],\n",
      "        [12.0695],\n",
      "        [ 8.4419],\n",
      "        [20.2748],\n",
      "        [12.4807],\n",
      "        [13.6356],\n",
      "        [ 8.6806],\n",
      "        [13.0500],\n",
      "        [ 8.2262],\n",
      "        [ 7.7855],\n",
      "        [ 7.4564],\n",
      "        [ 8.1599],\n",
      "        [ 9.1018],\n",
      "        [ 8.6747],\n",
      "        [ 7.0405],\n",
      "        [ 8.4644],\n",
      "        [ 8.3872],\n",
      "        [20.8203],\n",
      "        [ 6.2570],\n",
      "        [ 6.3864],\n",
      "        [ 6.5008],\n",
      "        [12.7677],\n",
      "        [11.2016],\n",
      "        [ 8.4995],\n",
      "        [16.0449],\n",
      "        [10.7939],\n",
      "        [10.3147],\n",
      "        [ 7.3775],\n",
      "        [ 7.0405],\n",
      "        [11.2867],\n",
      "        [10.1202],\n",
      "        [11.7602],\n",
      "        [ 8.5980],\n",
      "        [16.1386],\n",
      "        [10.5780],\n",
      "        [15.0840],\n",
      "        [ 5.3705],\n",
      "        [ 9.1209],\n",
      "        [10.1043],\n",
      "        [ 7.6946],\n",
      "        [12.2837],\n",
      "        [ 6.0763],\n",
      "        [ 5.4638],\n",
      "        [10.0084],\n",
      "        [11.7877],\n",
      "        [12.1190],\n",
      "        [17.3104],\n",
      "        [10.0989],\n",
      "        [ 8.0919],\n",
      "        [11.2489],\n",
      "        [ 7.4373],\n",
      "        [ 8.8312],\n",
      "        [13.9368],\n",
      "        [ 9.5157],\n",
      "        [15.7301],\n",
      "        [ 7.8866],\n",
      "        [ 5.6439],\n",
      "        [14.0250],\n",
      "        [13.3264],\n",
      "        [11.8236],\n",
      "        [ 9.9178],\n",
      "        [ 5.7123],\n",
      "        [ 8.3680],\n",
      "        [10.6514],\n",
      "        [21.4823],\n",
      "        [ 7.4564],\n",
      "        [ 9.1756],\n",
      "        [ 7.1939],\n",
      "        [ 9.1839],\n",
      "        [16.0367],\n",
      "        [19.6321],\n",
      "        [11.9333],\n",
      "        [12.0751],\n",
      "        [ 9.5562],\n",
      "        [18.9805],\n",
      "        [ 7.5110],\n",
      "        [11.1804],\n",
      "        [ 7.4069],\n",
      "        [10.1508],\n",
      "        [12.4481],\n",
      "        [18.7364],\n",
      "        [13.6740],\n",
      "        [10.2879],\n",
      "        [10.2271],\n",
      "        [ 9.7348],\n",
      "        [ 8.7623],\n",
      "        [ 5.6362],\n",
      "        [14.3207],\n",
      "        [13.7068],\n",
      "        [ 7.7849],\n",
      "        [14.1674],\n",
      "        [15.7246],\n",
      "        [ 7.1364],\n",
      "        [ 7.1524],\n",
      "        [ 9.3016],\n",
      "        [11.9438],\n",
      "        [20.1248],\n",
      "        [ 9.1022],\n",
      "        [ 6.4685],\n",
      "        [11.5494],\n",
      "        [13.9449],\n",
      "        [12.2536],\n",
      "        [10.6897],\n",
      "        [17.1242],\n",
      "        [ 8.6039],\n",
      "        [10.2736],\n",
      "        [15.1798],\n",
      "        [ 7.8784],\n",
      "        [ 7.1311],\n",
      "        [ 5.5727],\n",
      "        [ 6.9033],\n",
      "        [ 8.8281],\n",
      "        [ 9.3349],\n",
      "        [14.6405],\n",
      "        [ 6.0763],\n",
      "        [ 6.2298],\n",
      "        [ 9.5097],\n",
      "        [ 6.2494],\n",
      "        [ 7.9360],\n",
      "        [ 9.7999]], device='mps:0')\n",
      "tensor([2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 3, 0, 0, 1, 2, 2, 2, 2, 0, 2, 2, 0,\n",
      "        0, 3, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 2, 3, 0, 2, 2, 0, 2,\n",
      "        2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 3, 0, 0, 3, 2, 2, 2, 0, 1, 0, 3,\n",
      "        3, 2, 0, 3, 0, 2, 0, 2, 0, 3, 0, 2, 0, 0, 2, 2, 1, 2, 3, 2, 0, 2, 1, 2,\n",
      "        2, 0, 2, 2, 0, 0, 2, 2], device='mps:0')\n",
      "Batch 15 of 448\n",
      "tensor([[ 7.4564],\n",
      "        [ 7.5906],\n",
      "        [10.3557],\n",
      "        [ 5.7369],\n",
      "        [15.7575],\n",
      "        [ 7.5576],\n",
      "        [ 7.5171],\n",
      "        [ 8.5817],\n",
      "        [ 9.8901],\n",
      "        [11.1632],\n",
      "        [ 6.6930],\n",
      "        [11.5905],\n",
      "        [ 8.3851],\n",
      "        [13.4362],\n",
      "        [11.3906],\n",
      "        [ 7.3331],\n",
      "        [11.9141],\n",
      "        [19.7932],\n",
      "        [ 7.0380],\n",
      "        [14.3207],\n",
      "        [ 6.1394],\n",
      "        [10.1508],\n",
      "        [ 8.7627],\n",
      "        [13.4362],\n",
      "        [ 9.4363],\n",
      "        [10.5035],\n",
      "        [ 8.8033],\n",
      "        [ 6.9750],\n",
      "        [10.6897],\n",
      "        [12.4481],\n",
      "        [ 9.9178],\n",
      "        [ 7.9792],\n",
      "        [ 8.5327],\n",
      "        [10.1508],\n",
      "        [17.5179],\n",
      "        [14.6405],\n",
      "        [11.7964],\n",
      "        [17.1018],\n",
      "        [16.0395],\n",
      "        [ 8.7294],\n",
      "        [ 6.1531],\n",
      "        [11.5279],\n",
      "        [10.4678],\n",
      "        [ 6.4981],\n",
      "        [12.4147],\n",
      "        [16.8362],\n",
      "        [15.4212],\n",
      "        [ 8.0345],\n",
      "        [ 7.6207],\n",
      "        [16.6725],\n",
      "        [12.3844],\n",
      "        [10.2878],\n",
      "        [ 8.4447],\n",
      "        [11.2016],\n",
      "        [ 5.8218],\n",
      "        [ 8.4009],\n",
      "        [ 9.2688],\n",
      "        [ 8.7376],\n",
      "        [10.8984],\n",
      "        [14.1887],\n",
      "        [ 5.8107],\n",
      "        [14.5643],\n",
      "        [10.5035],\n",
      "        [10.1893],\n",
      "        [10.4547],\n",
      "        [13.6526],\n",
      "        [ 6.2927],\n",
      "        [ 9.1427],\n",
      "        [ 8.0533],\n",
      "        [12.4200],\n",
      "        [14.1509],\n",
      "        [ 9.8985],\n",
      "        [13.8661],\n",
      "        [ 8.0805],\n",
      "        [ 5.0716],\n",
      "        [ 9.1018],\n",
      "        [16.6719],\n",
      "        [13.4309],\n",
      "        [15.0298],\n",
      "        [11.8236],\n",
      "        [ 9.6275],\n",
      "        [13.7068],\n",
      "        [ 7.9875],\n",
      "        [16.9401],\n",
      "        [ 5.4638],\n",
      "        [11.1360],\n",
      "        [ 9.0362],\n",
      "        [ 5.8306],\n",
      "        [10.4986],\n",
      "        [13.9368],\n",
      "        [ 8.2151],\n",
      "        [ 9.2718],\n",
      "        [14.5117],\n",
      "        [ 6.6513],\n",
      "        [19.2049],\n",
      "        [14.1072],\n",
      "        [ 6.5008],\n",
      "        [15.1420],\n",
      "        [11.3441],\n",
      "        [ 6.4219],\n",
      "        [ 5.7757],\n",
      "        [ 9.9894],\n",
      "        [14.4679],\n",
      "        [20.9982],\n",
      "        [ 9.7753],\n",
      "        [ 8.8746],\n",
      "        [14.2714],\n",
      "        [14.1509],\n",
      "        [10.2112],\n",
      "        [12.0395],\n",
      "        [13.5212],\n",
      "        [10.9170],\n",
      "        [ 9.5809],\n",
      "        [ 8.5570],\n",
      "        [ 9.4686],\n",
      "        [14.4625],\n",
      "        [13.3264],\n",
      "        [14.5117],\n",
      "        [ 6.0988],\n",
      "        [11.3386],\n",
      "        [ 7.9360],\n",
      "        [10.0218],\n",
      "        [19.3499],\n",
      "        [12.6013],\n",
      "        [10.1235],\n",
      "        [10.1887],\n",
      "        [ 8.5602],\n",
      "        [17.7431]], device='mps:0')\n",
      "tensor([2, 2, 0, 2, 3, 3, 0, 0, 0, 2, 0, 2, 2, 0, 3, 2, 3, 0, 0, 3, 2, 0, 1, 0,\n",
      "        0, 0, 2, 0, 2, 0, 2, 3, 2, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "        2, 0, 0, 2, 2, 0, 1, 2, 1, 3, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0,\n",
      "        0, 2, 2, 0, 2, 2, 2, 0, 0, 3, 3, 2, 2, 0, 0, 2, 0, 2, 1, 0, 2, 0, 2, 2,\n",
      "        2, 0, 1, 3, 2, 0, 0, 2, 0, 3, 0, 2, 3, 3, 0, 2, 3, 2, 0, 0, 3, 2, 2, 3,\n",
      "        2, 0, 3, 0, 3, 2, 2, 3], device='mps:0')\n",
      "Batch 16 of 448\n",
      "tensor([[14.6405],\n",
      "        [11.2568],\n",
      "        [10.0989],\n",
      "        [ 7.1004],\n",
      "        [ 7.7303],\n",
      "        [ 8.6725],\n",
      "        [ 7.4926],\n",
      "        [ 7.8236],\n",
      "        [ 9.6330],\n",
      "        [ 6.0272],\n",
      "        [11.6891],\n",
      "        [ 7.8703],\n",
      "        [ 9.2688],\n",
      "        [13.9099],\n",
      "        [10.3749],\n",
      "        [ 6.7067],\n",
      "        [ 6.5890],\n",
      "        [10.6897],\n",
      "        [ 8.7738],\n",
      "        [12.5246],\n",
      "        [13.1182],\n",
      "        [ 6.2189],\n",
      "        [ 7.9360],\n",
      "        [10.8841],\n",
      "        [10.5617],\n",
      "        [ 8.5602],\n",
      "        [ 7.4268],\n",
      "        [14.5643],\n",
      "        [16.7574],\n",
      "        [10.5617],\n",
      "        [12.4035],\n",
      "        [17.3243],\n",
      "        [11.5494],\n",
      "        [10.1043],\n",
      "        [ 6.9033],\n",
      "        [ 7.4069],\n",
      "        [11.9710],\n",
      "        [ 8.5465],\n",
      "        [14.2057],\n",
      "        [15.7794],\n",
      "        [ 9.4878],\n",
      "        [ 7.5631],\n",
      "        [ 9.9341],\n",
      "        [11.0976],\n",
      "        [ 6.7664],\n",
      "        [11.2810],\n",
      "        [ 5.6219],\n",
      "        [ 6.4904],\n",
      "        [ 6.7884],\n",
      "        [ 8.9127],\n",
      "        [ 6.2927],\n",
      "        [17.4687],\n",
      "        [15.8889],\n",
      "        [ 9.6712],\n",
      "        [10.8765],\n",
      "        [ 9.8985],\n",
      "        [ 5.5240],\n",
      "        [ 6.3809],\n",
      "        [15.5828],\n",
      "        [ 7.8151],\n",
      "        [ 7.1936],\n",
      "        [ 7.8236],\n",
      "        [ 8.8012],\n",
      "        [ 5.4358],\n",
      "        [10.0113],\n",
      "        [ 9.9867],\n",
      "        [ 6.2494],\n",
      "        [19.7328],\n",
      "        [17.4473],\n",
      "        [ 8.4447],\n",
      "        [ 8.4452],\n",
      "        [ 9.0362],\n",
      "        [ 9.8223],\n",
      "        [ 6.3256],\n",
      "        [10.7367],\n",
      "        [ 6.4597],\n",
      "        [ 6.3065],\n",
      "        [ 6.2050],\n",
      "        [ 5.7923],\n",
      "        [ 9.9894],\n",
      "        [ 6.4382],\n",
      "        [10.0113],\n",
      "        [ 9.3871],\n",
      "        [11.9601],\n",
      "        [ 7.5110],\n",
      "        [11.6206],\n",
      "        [15.6513],\n",
      "        [13.4280],\n",
      "        [13.5951],\n",
      "        [ 5.2475],\n",
      "        [10.7642],\n",
      "        [12.9977],\n",
      "        [11.5822],\n",
      "        [ 7.6513],\n",
      "        [ 7.7772],\n",
      "        [13.1675],\n",
      "        [17.6636],\n",
      "        [ 8.9347],\n",
      "        [ 7.2428],\n",
      "        [13.1980],\n",
      "        [15.7301],\n",
      "        [ 8.5461],\n",
      "        [15.4317],\n",
      "        [ 9.5538],\n",
      "        [12.4857],\n",
      "        [10.1645],\n",
      "        [ 7.4373],\n",
      "        [ 8.0919],\n",
      "        [14.1096],\n",
      "        [13.0196],\n",
      "        [ 5.4522],\n",
      "        [ 5.7731],\n",
      "        [ 7.5253],\n",
      "        [10.4678],\n",
      "        [12.5246],\n",
      "        [14.6656],\n",
      "        [10.3698],\n",
      "        [ 6.8381],\n",
      "        [ 6.1284],\n",
      "        [12.1882],\n",
      "        [13.8300],\n",
      "        [14.3693],\n",
      "        [ 5.8107],\n",
      "        [13.0421],\n",
      "        [ 9.9479],\n",
      "        [15.7575],\n",
      "        [10.4215],\n",
      "        [11.3665]], device='mps:0')\n",
      "tensor([0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 2, 0, 1, 1, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2,\n",
      "        3, 2, 0, 0, 0, 3, 2, 3, 2, 2, 1, 3, 2, 2, 0, 2, 0, 0, 1, 2, 3, 0, 0, 2,\n",
      "        2, 0, 2, 0, 0, 3, 3, 0, 0, 3, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0,\n",
      "        2, 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 2, 0,\n",
      "        0, 1, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 3,\n",
      "        0, 1, 0, 2, 3, 3, 0, 0], device='mps:0')\n",
      "Batch 17 of 448\n",
      "tensor([[15.2345],\n",
      "        [ 5.8929],\n",
      "        [11.0873],\n",
      "        [15.4678],\n",
      "        [13.0885],\n",
      "        [ 9.0825],\n",
      "        [16.1413],\n",
      "        [ 8.4230],\n",
      "        [ 6.5145],\n",
      "        [ 9.9287],\n",
      "        [ 8.2064],\n",
      "        [15.7246],\n",
      "        [ 9.6656],\n",
      "        [11.7389],\n",
      "        [ 7.0100],\n",
      "        [ 9.2825],\n",
      "        [14.8458],\n",
      "        [14.5419],\n",
      "        [ 5.8107],\n",
      "        [12.0784],\n",
      "        [17.7069],\n",
      "        [ 9.4363],\n",
      "        [ 8.0345],\n",
      "        [ 9.6034],\n",
      "        [11.1749],\n",
      "        [ 9.1626],\n",
      "        [12.8993],\n",
      "        [10.8025],\n",
      "        [11.3413],\n",
      "        [15.5828],\n",
      "        [ 7.7547],\n",
      "        [ 5.1735],\n",
      "        [ 7.3331],\n",
      "        [10.1783],\n",
      "        [17.6636],\n",
      "        [10.4686],\n",
      "        [14.3536],\n",
      "        [10.8841],\n",
      "        [ 7.1939],\n",
      "        [10.5035],\n",
      "        [ 6.0272],\n",
      "        [ 6.2050],\n",
      "        [ 8.4610],\n",
      "        [10.9859],\n",
      "        [10.8076],\n",
      "        [17.3104],\n",
      "        [10.8765],\n",
      "        [ 6.3835],\n",
      "        [ 6.7664],\n",
      "        [ 9.6712],\n",
      "        [ 9.3373],\n",
      "        [ 6.1421],\n",
      "        [ 7.3823],\n",
      "        [17.6747],\n",
      "        [15.0185],\n",
      "        [ 6.3528],\n",
      "        [14.9908],\n",
      "        [21.4195],\n",
      "        [ 6.4522],\n",
      "        [ 8.5569],\n",
      "        [13.6439],\n",
      "        [11.1775],\n",
      "        [11.3989],\n",
      "        [11.3989],\n",
      "        [ 7.6452],\n",
      "        [ 7.3823],\n",
      "        [13.6356],\n",
      "        [16.6450],\n",
      "        [11.3413],\n",
      "        [11.4324],\n",
      "        [11.3413],\n",
      "        [20.9271],\n",
      "        [ 9.0749],\n",
      "        [ 8.5817],\n",
      "        [ 5.6548],\n",
      "        [12.3844],\n",
      "        [ 7.8236],\n",
      "        [20.2748],\n",
      "        [ 7.6207],\n",
      "        [ 8.1599],\n",
      "        [ 9.0333],\n",
      "        [10.0084],\n",
      "        [ 5.9371],\n",
      "        [12.2837],\n",
      "        [15.0845],\n",
      "        [12.4454],\n",
      "        [10.2709],\n",
      "        [ 7.8319],\n",
      "        [ 7.0704],\n",
      "        [ 6.2105],\n",
      "        [17.2039],\n",
      "        [ 5.7757],\n",
      "        [12.4857],\n",
      "        [11.0079],\n",
      "        [12.4229],\n",
      "        [ 7.5110],\n",
      "        [12.5213],\n",
      "        [10.2271],\n",
      "        [ 8.5302],\n",
      "        [ 6.4904],\n",
      "        [21.8196],\n",
      "        [10.1645],\n",
      "        [ 8.8389],\n",
      "        [14.1887],\n",
      "        [12.8993],\n",
      "        [ 7.2428],\n",
      "        [ 8.0805],\n",
      "        [17.6636],\n",
      "        [11.8808],\n",
      "        [ 9.9346],\n",
      "        [ 9.2690],\n",
      "        [10.1969],\n",
      "        [ 6.5008],\n",
      "        [10.7361],\n",
      "        [17.9287],\n",
      "        [10.1723],\n",
      "        [11.4756],\n",
      "        [ 9.7675],\n",
      "        [11.2351],\n",
      "        [ 5.8929],\n",
      "        [ 8.5461],\n",
      "        [ 9.8469],\n",
      "        [10.2900],\n",
      "        [ 7.0704],\n",
      "        [11.4377],\n",
      "        [12.5411],\n",
      "        [10.4953],\n",
      "        [ 7.3714]], device='mps:0')\n",
      "tensor([0, 0, 0, 0, 2, 0, 1, 2, 2, 2, 0, 3, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2,\n",
      "        2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 0, 3, 3, 2, 2, 0, 0, 1, 1, 2, 2, 2, 3, 3,\n",
      "        3, 3, 0, 3, 1, 0, 1, 2, 3, 0, 0, 0, 0, 2, 2, 2, 0, 1, 0, 2, 0, 0, 0, 3,\n",
      "        0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 3, 2, 2, 3, 0, 2, 2, 2, 3, 2, 2, 2, 2, 0,\n",
      "        2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 0, 2, 2, 0, 3, 3, 0,\n",
      "        0, 2, 0, 2, 0, 0, 3, 0], device='mps:0')\n",
      "Batch 18 of 448\n",
      "tensor([[ 8.7463],\n",
      "        [14.4870],\n",
      "        [15.7246],\n",
      "        [ 9.1729],\n",
      "        [ 5.3620],\n",
      "        [ 6.5089],\n",
      "        [ 8.8012],\n",
      "        [ 8.4644],\n",
      "        [ 9.3487],\n",
      "        [14.8354],\n",
      "        [ 6.6984],\n",
      "        [ 9.1126],\n",
      "        [13.0934],\n",
      "        [10.8025],\n",
      "        [13.7068],\n",
      "        [ 9.2718],\n",
      "        [13.4309],\n",
      "        [11.6426],\n",
      "        [11.6206],\n",
      "        [ 6.7772],\n",
      "        [10.7231],\n",
      "        [ 8.0915],\n",
      "        [ 7.5282],\n",
      "        [11.2867],\n",
      "        [ 5.1729],\n",
      "        [ 8.8476],\n",
      "        [ 7.3830],\n",
      "        [11.0079],\n",
      "        [ 9.9400],\n",
      "        [10.0438],\n",
      "        [12.8065],\n",
      "        [17.7534],\n",
      "        [ 6.0874],\n",
      "        [ 5.8389],\n",
      "        [11.0079],\n",
      "        [12.5926],\n",
      "        [ 8.6473],\n",
      "        [ 7.8236],\n",
      "        [ 8.8312],\n",
      "        [ 7.3823],\n",
      "        [10.0086],\n",
      "        [15.3939],\n",
      "        [17.7074],\n",
      "        [12.7820],\n",
      "        [13.0416],\n",
      "        [ 7.3775],\n",
      "        [13.8661],\n",
      "        [ 7.0868],\n",
      "        [15.0845],\n",
      "        [ 7.1524],\n",
      "        [ 7.3139],\n",
      "        [10.4547],\n",
      "        [ 9.2940],\n",
      "        [ 6.8677],\n",
      "        [ 9.6936],\n",
      "        [ 8.5650],\n",
      "        [ 9.2688],\n",
      "        [10.0438],\n",
      "        [16.1523],\n",
      "        [ 9.1570],\n",
      "        [17.5179],\n",
      "        [ 7.8177],\n",
      "        [ 7.6151],\n",
      "        [11.5822],\n",
      "        [11.9989],\n",
      "        [10.5338],\n",
      "        [13.8958],\n",
      "        [18.7364],\n",
      "        [12.5650],\n",
      "        [10.1809],\n",
      "        [12.9046],\n",
      "        [ 5.6741],\n",
      "        [11.6891],\n",
      "        [16.6227],\n",
      "        [10.7553],\n",
      "        [14.4685],\n",
      "        [ 6.2303],\n",
      "        [ 6.2215],\n",
      "        [ 9.0826],\n",
      "        [13.4280],\n",
      "        [15.7301],\n",
      "        [ 9.6794],\n",
      "        [ 6.2193],\n",
      "        [11.9608],\n",
      "        [21.4195],\n",
      "        [ 8.4452],\n",
      "        [ 7.3714],\n",
      "        [15.9546],\n",
      "        [12.1221],\n",
      "        [11.4756],\n",
      "        [10.1043],\n",
      "        [17.1927],\n",
      "        [15.9875],\n",
      "        [14.1674],\n",
      "        [ 6.4904],\n",
      "        [ 8.5570],\n",
      "        [ 6.5972],\n",
      "        [16.0400],\n",
      "        [11.5494],\n",
      "        [15.4131],\n",
      "        [11.9141],\n",
      "        [ 6.7363],\n",
      "        [ 9.6055],\n",
      "        [ 8.8696],\n",
      "        [ 7.0100],\n",
      "        [ 7.9442],\n",
      "        [11.8565],\n",
      "        [ 5.7430],\n",
      "        [ 6.4296],\n",
      "        [ 7.8236],\n",
      "        [ 7.3171],\n",
      "        [ 6.1284],\n",
      "        [ 9.3760],\n",
      "        [17.6439],\n",
      "        [18.6460],\n",
      "        [ 9.1866],\n",
      "        [ 5.5787],\n",
      "        [ 7.8507],\n",
      "        [16.5465],\n",
      "        [10.2879],\n",
      "        [ 8.2206],\n",
      "        [ 8.4454],\n",
      "        [14.9662],\n",
      "        [17.6747],\n",
      "        [ 5.7757],\n",
      "        [13.4418],\n",
      "        [ 7.6780],\n",
      "        [ 6.7884]], device='mps:0')\n",
      "tensor([2, 0, 3, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 3, 0, 2, 0, 0, 2, 0, 3, 3, 2,\n",
      "        0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 2, 3, 3, 0, 2, 0, 0,\n",
      "        2, 2, 0, 2, 2, 0, 2, 3, 1, 0, 0, 1, 0, 0, 2, 0, 0, 2, 2, 3, 0, 0, 0, 2,\n",
      "        2, 0, 2, 3, 1, 2, 3, 0, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2,\n",
      "        2, 2, 2, 0, 3, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 3, 2, 2, 0, 2, 2, 0, 2,\n",
      "        0, 3, 2, 0, 2, 0, 0, 2], device='mps:0')\n",
      "Batch 19 of 448\n",
      "tensor([[ 6.6272],\n",
      "        [10.1783],\n",
      "        [ 5.5727],\n",
      "        [ 9.7348],\n",
      "        [ 9.4636],\n",
      "        [ 9.6493],\n",
      "        [14.5260],\n",
      "        [ 7.8889],\n",
      "        [11.3906],\n",
      "        [15.9546],\n",
      "        [ 9.4686],\n",
      "        [ 7.5576],\n",
      "        [ 7.7855],\n",
      "        [ 9.3016],\n",
      "        [15.1553],\n",
      "        [13.5152],\n",
      "        [ 9.1598],\n",
      "        [14.4685],\n",
      "        [17.9287],\n",
      "        [ 6.2215],\n",
      "        [ 9.1516],\n",
      "        [14.4685],\n",
      "        [ 6.5501],\n",
      "        [17.3243],\n",
      "        [19.9847],\n",
      "        [10.5035],\n",
      "        [ 5.8218],\n",
      "        [13.3264],\n",
      "        [ 8.3353],\n",
      "        [ 7.7219],\n",
      "        [17.6032],\n",
      "        [14.2057],\n",
      "        [17.6636],\n",
      "        [ 8.0039],\n",
      "        [ 7.1939],\n",
      "        [ 6.2600],\n",
      "        [ 6.4378],\n",
      "        [ 6.4898],\n",
      "        [10.1809],\n",
      "        [20.6643],\n",
      "        [ 6.2029],\n",
      "        [ 6.4439],\n",
      "        [ 6.2570],\n",
      "        [ 9.3816],\n",
      "        [ 8.4610],\n",
      "        [12.4754],\n",
      "        [ 9.2825],\n",
      "        [ 8.4147],\n",
      "        [17.5727],\n",
      "        [13.4309],\n",
      "        [ 6.3256],\n",
      "        [ 8.0915],\n",
      "        [16.1380],\n",
      "        [ 9.4636],\n",
      "        [15.1585],\n",
      "        [19.6321],\n",
      "        [ 8.7075],\n",
      "        [ 8.7623],\n",
      "        [ 9.4905],\n",
      "        [ 9.5070],\n",
      "        [11.0216],\n",
      "        [ 6.5501],\n",
      "        [ 8.2563],\n",
      "        [10.0218],\n",
      "        [11.6426],\n",
      "        [12.2393],\n",
      "        [ 8.8859],\n",
      "        [ 8.9127],\n",
      "        [21.2228],\n",
      "        [ 8.9324],\n",
      "        [11.9601],\n",
      "        [14.1096],\n",
      "        [ 8.4529],\n",
      "        [ 7.9442],\n",
      "        [16.0395],\n",
      "        [18.3640],\n",
      "        [ 5.7369],\n",
      "        [15.0325],\n",
      "        [ 8.2809],\n",
      "        [ 7.7985],\n",
      "        [ 6.6191],\n",
      "        [10.6190],\n",
      "        [14.9065],\n",
      "        [ 7.2538],\n",
      "        [ 7.7383],\n",
      "        [13.3542],\n",
      "        [ 7.4069],\n",
      "        [14.2057],\n",
      "        [ 9.7697],\n",
      "        [ 6.3288],\n",
      "        [10.2879],\n",
      "        [ 8.4807],\n",
      "        [10.8079],\n",
      "        [ 7.6513],\n",
      "        [ 8.3851],\n",
      "        [19.6567],\n",
      "        [ 8.6473],\n",
      "        [11.2351],\n",
      "        [11.9086],\n",
      "        [ 5.8662],\n",
      "        [10.4547],\n",
      "        [ 6.2193],\n",
      "        [ 9.1072],\n",
      "        [14.5117],\n",
      "        [13.6636],\n",
      "        [ 7.3139],\n",
      "        [10.1450],\n",
      "        [ 8.0532],\n",
      "        [10.4215],\n",
      "        [12.5297],\n",
      "        [14.4077],\n",
      "        [ 7.5282],\n",
      "        [ 6.7280],\n",
      "        [ 8.8253],\n",
      "        [14.9065],\n",
      "        [ 9.9341],\n",
      "        [10.2112],\n",
      "        [ 6.4382],\n",
      "        [ 6.7553],\n",
      "        [ 9.8711],\n",
      "        [10.5583],\n",
      "        [ 6.9750],\n",
      "        [17.7074],\n",
      "        [17.4473],\n",
      "        [ 9.9479],\n",
      "        [20.2748],\n",
      "        [ 6.5884],\n",
      "        [14.5419]], device='mps:0')\n",
      "tensor([0, 0, 2, 0, 2, 3, 0, 3, 3, 0, 0, 3, 2, 0, 3, 0, 0, 3, 2, 2, 2, 3, 2, 3,\n",
      "        3, 0, 1, 3, 0, 0, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 1, 2, 2, 2,\n",
      "        2, 2, 2, 3, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 3, 0, 2, 2, 2, 2,\n",
      "        2, 2, 3, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 3, 0, 2, 0, 2, 0, 1, 0, 2, 3,\n",
      "        0, 3, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 3, 2, 2, 2, 1, 3, 0, 0, 3,\n",
      "        2, 0, 3, 2, 3, 2, 0, 2], device='mps:0')\n",
      "Batch 20 of 448\n",
      "tensor([[12.5520],\n",
      "        [ 7.7739],\n",
      "        [ 9.1022],\n",
      "        [ 9.2523],\n",
      "        [ 8.3851],\n",
      "        [10.4789],\n",
      "        [ 7.3141],\n",
      "        [13.5152],\n",
      "        [16.8614],\n",
      "        [12.3630],\n",
      "        [11.1775],\n",
      "        [ 8.5734],\n",
      "        [14.6656],\n",
      "        [11.6896],\n",
      "        [14.4685],\n",
      "        [ 7.6207],\n",
      "        [ 6.3940],\n",
      "        [ 9.6275],\n",
      "        [12.4857],\n",
      "        [ 9.6466],\n",
      "        [ 9.7753],\n",
      "        [16.1413],\n",
      "        [ 9.8223],\n",
      "        [ 9.6417],\n",
      "        [ 6.0326],\n",
      "        [12.0975],\n",
      "        [ 8.4256],\n",
      "        [ 7.9360],\n",
      "        [13.4609],\n",
      "        [ 8.5650],\n",
      "        [11.3419],\n",
      "        [ 6.9695],\n",
      "        [16.0400],\n",
      "        [13.9423],\n",
      "        [17.7074],\n",
      "        [ 7.8593],\n",
      "        [ 8.6664],\n",
      "        [ 8.2036],\n",
      "        [16.4452],\n",
      "        [17.2611],\n",
      "        [10.5506],\n",
      "        [13.9423],\n",
      "        [11.6426],\n",
      "        [12.0127],\n",
      "        [ 8.7075],\n",
      "        [15.1798],\n",
      "        [11.4756],\n",
      "        [ 8.8087],\n",
      "        [ 9.4277],\n",
      "        [ 8.7738],\n",
      "        [12.5762],\n",
      "        [16.1380],\n",
      "        [ 5.5946],\n",
      "        [ 7.3141],\n",
      "        [12.0127],\n",
      "        [ 6.0031],\n",
      "        [14.8573],\n",
      "        [18.1290],\n",
      "        [ 7.4016],\n",
      "        [10.3147],\n",
      "        [ 8.2667],\n",
      "        [ 8.9762],\n",
      "        [17.5179],\n",
      "        [15.0626],\n",
      "        [16.1413],\n",
      "        [20.1248],\n",
      "        [ 8.8696],\n",
      "        [ 6.2215],\n",
      "        [ 8.7376],\n",
      "        [ 5.6525],\n",
      "        [ 7.3714],\n",
      "        [ 9.7999],\n",
      "        [ 7.7109],\n",
      "        [15.2345],\n",
      "        [10.8079],\n",
      "        [ 8.6912],\n",
      "        [16.0449],\n",
      "        [ 6.1394],\n",
      "        [ 9.6493],\n",
      "        [14.6656],\n",
      "        [ 6.5008],\n",
      "        [11.9710],\n",
      "        [10.9120],\n",
      "        [11.2291],\n",
      "        [ 7.8889],\n",
      "        [16.8614],\n",
      "        [ 6.8024],\n",
      "        [15.9847],\n",
      "        [ 8.6943],\n",
      "        [ 6.6191],\n",
      "        [12.4200],\n",
      "        [11.0976],\n",
      "        [ 8.5350],\n",
      "        [ 8.2611],\n",
      "        [ 9.8469],\n",
      "        [ 9.0611],\n",
      "        [18.7364],\n",
      "        [16.6450],\n",
      "        [ 8.0969],\n",
      "        [15.0295],\n",
      "        [ 7.3823],\n",
      "        [ 6.5890],\n",
      "        [10.2713],\n",
      "        [ 8.7463],\n",
      "        [10.1535],\n",
      "        [ 8.0970],\n",
      "        [14.5972],\n",
      "        [11.7389],\n",
      "        [ 6.0934],\n",
      "        [ 9.1839],\n",
      "        [ 9.6493],\n",
      "        [10.4986],\n",
      "        [12.4450],\n",
      "        [ 6.3179],\n",
      "        [13.8661],\n",
      "        [ 7.7109],\n",
      "        [11.1030],\n",
      "        [14.0250],\n",
      "        [11.3441],\n",
      "        [13.8470],\n",
      "        [14.3613],\n",
      "        [ 7.3141],\n",
      "        [12.9977],\n",
      "        [16.4233],\n",
      "        [16.1413],\n",
      "        [ 5.4638],\n",
      "        [ 7.8565],\n",
      "        [10.3147]], device='mps:0')\n",
      "tensor([2, 0, 3, 3, 2, 3, 3, 0, 3, 2, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 3, 2, 3,\n",
      "        0, 2, 2, 2, 0, 3, 0, 0, 2, 2, 3, 2, 0, 1, 3, 2, 0, 0, 0, 3, 2, 3, 0, 0,\n",
      "        2, 0, 1, 2, 2, 3, 3, 3, 0, 0, 0, 2, 3, 0, 0, 3, 3, 0, 0, 2, 3, 2, 0, 2,\n",
      "        2, 0, 1, 0, 0, 2, 3, 2, 2, 2, 0, 2, 3, 3, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2,\n",
      "        3, 2, 3, 0, 1, 2, 2, 2, 1, 0, 1, 2, 2, 2, 3, 0, 0, 2, 0, 2, 2, 2, 1, 2,\n",
      "        2, 3, 0, 0, 3, 2, 0, 2], device='mps:0')\n",
      "Batch 21 of 448\n",
      "tensor([[10.7882],\n",
      "        [ 7.4070],\n",
      "        [11.5000],\n",
      "        [14.0250],\n",
      "        [13.3127],\n",
      "        [16.5465],\n",
      "        [16.1413],\n",
      "        [10.1202],\n",
      "        [ 8.5794],\n",
      "        [15.3579],\n",
      "        [10.4953],\n",
      "        [11.5279],\n",
      "        [15.4678],\n",
      "        [ 5.4446],\n",
      "        [16.5465],\n",
      "        [12.8415],\n",
      "        [10.9285],\n",
      "        [11.7055],\n",
      "        [ 6.7446],\n",
      "        [ 8.6582],\n",
      "        [15.1798],\n",
      "        [16.4063],\n",
      "        [ 8.3712],\n",
      "        [11.8182],\n",
      "        [12.2536],\n",
      "        [16.0367],\n",
      "        [12.8362],\n",
      "        [13.6581],\n",
      "        [14.8819],\n",
      "        [ 5.4522],\n",
      "        [11.2291],\n",
      "        [ 8.2151],\n",
      "        [ 9.1756],\n",
      "        [ 6.7772],\n",
      "        [ 7.4268],\n",
      "        [11.6891],\n",
      "        [12.8090],\n",
      "        [ 7.5171],\n",
      "        [ 7.0736],\n",
      "        [ 7.7935],\n",
      "        [ 5.7430],\n",
      "        [ 6.9750],\n",
      "        [ 6.5972],\n",
      "        [ 8.5734],\n",
      "        [11.7276],\n",
      "        [12.9430],\n",
      "        [ 8.2151],\n",
      "        [ 6.5447],\n",
      "        [10.4713],\n",
      "        [11.1632],\n",
      "        [ 8.4644],\n",
      "        [12.4450],\n",
      "        [ 9.3016],\n",
      "        [ 7.4070],\n",
      "        [13.3264],\n",
      "        [ 8.2099],\n",
      "        [ 9.9894],\n",
      "        [ 9.3871],\n",
      "        [11.6128],\n",
      "        [12.2728],\n",
      "        [10.7258],\n",
      "        [ 6.5529],\n",
      "        [ 7.3823],\n",
      "        [16.1380],\n",
      "        [ 7.5603],\n",
      "        [11.9333],\n",
      "        [18.6600],\n",
      "        [16.9517],\n",
      "        [ 7.7328],\n",
      "        [17.6636],\n",
      "        [10.2736],\n",
      "        [10.9034],\n",
      "        [ 9.5815],\n",
      "        [ 7.4926],\n",
      "        [ 7.7383],\n",
      "        [ 8.6806],\n",
      "        [ 8.0805],\n",
      "        [12.0751],\n",
      "        [11.7877],\n",
      "        [ 6.3528],\n",
      "        [ 9.1023],\n",
      "        [12.4450],\n",
      "        [12.4147],\n",
      "        [13.1269],\n",
      "        [10.2879],\n",
      "        [ 8.5327],\n",
      "        [13.8437],\n",
      "        [ 8.0919],\n",
      "        [ 9.3103],\n",
      "        [ 8.8033],\n",
      "        [11.9141],\n",
      "        [13.3022],\n",
      "        [13.0224],\n",
      "        [ 7.7985],\n",
      "        [12.4147],\n",
      "        [18.0222],\n",
      "        [ 8.6123],\n",
      "        [ 6.7446],\n",
      "        [ 9.2688],\n",
      "        [ 6.7446],\n",
      "        [21.2228],\n",
      "        [17.1376],\n",
      "        [10.0189],\n",
      "        [ 6.4378],\n",
      "        [15.4131],\n",
      "        [ 7.2538],\n",
      "        [ 7.3994],\n",
      "        [10.0026],\n",
      "        [10.5994],\n",
      "        [11.6206],\n",
      "        [17.1018],\n",
      "        [15.6513],\n",
      "        [ 7.9798],\n",
      "        [14.8573],\n",
      "        [11.8259],\n",
      "        [15.2899],\n",
      "        [ 9.5044],\n",
      "        [18.8326],\n",
      "        [ 6.5884],\n",
      "        [ 5.4691],\n",
      "        [19.7932],\n",
      "        [10.6190],\n",
      "        [15.0295],\n",
      "        [ 8.6692],\n",
      "        [ 5.8218],\n",
      "        [ 8.0702],\n",
      "        [14.9908],\n",
      "        [15.0185]], device='mps:0')\n",
      "tensor([0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 3, 0, 0, 0, 0, 0, 3, 2, 2, 0, 3, 2, 2, 2,\n",
      "        0, 2, 0, 0, 2, 2, 2, 1, 0, 2, 0, 2, 3, 0, 2, 0, 2, 0, 2, 2, 3, 2, 1, 0,\n",
      "        2, 2, 0, 0, 0, 0, 3, 2, 0, 0, 2, 2, 0, 2, 1, 2, 2, 0, 0, 3, 0, 0, 2, 2,\n",
      "        2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 1, 0, 2, 3, 0, 0, 2, 2, 3,\n",
      "        2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 3, 3, 2, 0, 0, 3, 2, 0, 0, 2, 3, 2, 0, 0,\n",
      "        0, 2, 0, 2, 1, 0, 3, 1], device='mps:0')\n",
      "Batch 22 of 448\n",
      "tensor([[ 7.0872],\n",
      "        [10.2879],\n",
      "        [12.8065],\n",
      "        [ 6.2900],\n",
      "        [ 7.1311],\n",
      "        [ 7.1743],\n",
      "        [ 7.4590],\n",
      "        [15.7252],\n",
      "        [11.9333],\n",
      "        [ 7.3141],\n",
      "        [ 7.6457],\n",
      "        [14.3174],\n",
      "        [ 7.1939],\n",
      "        [ 7.7903],\n",
      "        [ 7.4590],\n",
      "        [ 5.4638],\n",
      "        [15.9657],\n",
      "        [13.5951],\n",
      "        [14.3174],\n",
      "        [15.7252],\n",
      "        [ 9.8985],\n",
      "        [15.0626],\n",
      "        [ 7.7470],\n",
      "        [ 6.4685],\n",
      "        [ 8.8859],\n",
      "        [19.6567],\n",
      "        [11.5905],\n",
      "        [ 7.5576],\n",
      "        [ 8.2151],\n",
      "        [15.7575],\n",
      "        [12.4807],\n",
      "        [15.0900],\n",
      "        [11.3989],\n",
      "        [ 7.3141],\n",
      "        [10.0989],\n",
      "        [ 7.0100],\n",
      "        [ 6.7446],\n",
      "        [ 8.2372],\n",
      "        [11.1030],\n",
      "        [13.0500],\n",
      "        [ 6.6272],\n",
      "        [16.6227],\n",
      "        [ 8.9762],\n",
      "        [ 8.2036],\n",
      "        [ 6.5008],\n",
      "        [ 8.9868],\n",
      "        [12.5926],\n",
      "        [14.1674],\n",
      "        [15.0681],\n",
      "        [12.4229],\n",
      "        [20.1248],\n",
      "        [ 5.6741],\n",
      "        [14.7992],\n",
      "        [15.3199],\n",
      "        [14.6656],\n",
      "        [ 8.9708],\n",
      "        [16.9517],\n",
      "        [11.9086],\n",
      "        [11.4350],\n",
      "        [15.6513],\n",
      "        [ 8.2206],\n",
      "        [ 8.4610],\n",
      "        [16.0837],\n",
      "        [15.3579],\n",
      "        [ 5.4358],\n",
      "        [13.7725],\n",
      "        [ 5.2036],\n",
      "        [12.8362],\n",
      "        [17.5179],\n",
      "        [ 8.8087],\n",
      "        [ 9.6055],\n",
      "        [ 7.0868],\n",
      "        [14.9065],\n",
      "        [ 9.7431],\n",
      "        [ 9.1839],\n",
      "        [ 6.4597],\n",
      "        [ 7.9086],\n",
      "        [21.1761],\n",
      "        [14.9256],\n",
      "        [16.6719],\n",
      "        [ 9.8469],\n",
      "        [12.2837],\n",
      "        [ 7.7547],\n",
      "        [ 7.3331],\n",
      "        [10.6547],\n",
      "        [ 6.4981],\n",
      "        [ 9.2197],\n",
      "        [14.3693],\n",
      "        [ 9.2718],\n",
      "        [ 7.8507],\n",
      "        [ 9.1598],\n",
      "        [ 8.2340],\n",
      "        [ 7.4900],\n",
      "        [ 9.1516],\n",
      "        [ 8.7376],\n",
      "        [12.6259],\n",
      "        [ 5.6219],\n",
      "        [10.7258],\n",
      "        [ 9.6330],\n",
      "        [11.5822],\n",
      "        [ 5.4549],\n",
      "        [ 5.3620],\n",
      "        [ 5.4198],\n",
      "        [ 7.7685],\n",
      "        [ 9.1620],\n",
      "        [10.1421],\n",
      "        [ 8.2064],\n",
      "        [ 8.5986],\n",
      "        [ 9.4686],\n",
      "        [ 6.2687],\n",
      "        [ 8.4667],\n",
      "        [16.7158],\n",
      "        [17.3454],\n",
      "        [12.6013],\n",
      "        [11.5827],\n",
      "        [17.7073],\n",
      "        [12.8090],\n",
      "        [20.8203],\n",
      "        [16.4342],\n",
      "        [ 9.5809],\n",
      "        [15.4212],\n",
      "        [ 8.2667],\n",
      "        [ 6.0272],\n",
      "        [19.7826],\n",
      "        [11.9438],\n",
      "        [11.9141],\n",
      "        [ 6.6513],\n",
      "        [ 8.4452]], device='mps:0')\n",
      "tensor([2, 2, 0, 2, 0, 0, 0, 2, 0, 3, 2, 2, 2, 2, 0, 2, 3, 0, 2, 2, 0, 3, 1, 0,\n",
      "        3, 3, 2, 3, 1, 3, 3, 0, 2, 3, 0, 0, 2, 0, 2, 1, 0, 0, 0, 1, 2, 0, 2, 0,\n",
      "        3, 2, 0, 2, 2, 0, 2, 2, 3, 0, 0, 3, 0, 1, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0,\n",
      "        2, 3, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 3, 1, 0, 2, 0, 2, 3, 2, 3, 2,\n",
      "        0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 3, 3, 2, 3,\n",
      "        2, 3, 0, 0, 2, 3, 0, 0], device='mps:0')\n",
      "Batch 23 of 448\n",
      "tensor([[16.1380],\n",
      "        [ 6.9033],\n",
      "        [10.0545],\n",
      "        [17.4473],\n",
      "        [ 6.6930],\n",
      "        [20.9271],\n",
      "        [14.1072],\n",
      "        [16.4447],\n",
      "        [ 8.4481],\n",
      "        [14.0441],\n",
      "        [ 8.7404],\n",
      "        [10.4378],\n",
      "        [ 9.6275],\n",
      "        [11.4673],\n",
      "        [16.7158],\n",
      "        [ 6.7553],\n",
      "        [18.8954],\n",
      "        [ 8.7623],\n",
      "        [ 7.2101],\n",
      "        [18.8954],\n",
      "        [ 5.7923],\n",
      "        [ 8.5110],\n",
      "        [ 7.0626],\n",
      "        [ 8.5650],\n",
      "        [ 7.9442],\n",
      "        [10.1450],\n",
      "        [ 7.0736],\n",
      "        [11.9086],\n",
      "        [ 6.5829],\n",
      "        [ 9.2003],\n",
      "        [ 7.9086],\n",
      "        [ 9.5075],\n",
      "        [12.0751],\n",
      "        [ 8.4610],\n",
      "        [10.4713],\n",
      "        [ 9.5896],\n",
      "        [ 9.4774],\n",
      "        [ 8.6395],\n",
      "        [16.0395],\n",
      "        [20.9271],\n",
      "        [20.2748],\n",
      "        [ 8.0039],\n",
      "        [ 9.5070],\n",
      "        [12.0127],\n",
      "        [10.2900],\n",
      "        [12.5520],\n",
      "        [12.2563],\n",
      "        [14.9613],\n",
      "        [ 6.9695],\n",
      "        [ 7.4069],\n",
      "        [ 6.8540],\n",
      "        [ 6.2029],\n",
      "        [18.7364],\n",
      "        [18.7364],\n",
      "        [12.4807],\n",
      "        [10.1893],\n",
      "        [10.1092],\n",
      "        [10.7363],\n",
      "        [15.9031],\n",
      "        [10.9887],\n",
      "        [10.2709],\n",
      "        [12.5650],\n",
      "        [ 9.6656],\n",
      "        [ 5.4549],\n",
      "        [ 9.8985],\n",
      "        [ 8.0919],\n",
      "        [ 9.3871],\n",
      "        [12.8362],\n",
      "        [ 6.2215],\n",
      "        [ 9.7753],\n",
      "        [ 7.0922],\n",
      "        [ 8.5794],\n",
      "        [ 8.8587],\n",
      "        [ 7.3171],\n",
      "        [ 9.2936],\n",
      "        [ 9.4721],\n",
      "        [11.6206],\n",
      "        [11.3063],\n",
      "        [ 5.8005],\n",
      "        [11.4756],\n",
      "        [ 8.2064],\n",
      "        [ 5.8465],\n",
      "        [13.6439],\n",
      "        [15.9086],\n",
      "        [ 5.4522],\n",
      "        [15.9086],\n",
      "        [ 5.7430],\n",
      "        [15.3579],\n",
      "        [ 6.4214],\n",
      "        [ 7.9442],\n",
      "        [ 6.6513],\n",
      "        [11.1632],\n",
      "        [ 9.8223],\n",
      "        [ 6.4214],\n",
      "        [11.3063],\n",
      "        [14.4870],\n",
      "        [10.1043],\n",
      "        [18.2029],\n",
      "        [17.5179],\n",
      "        [ 7.6452],\n",
      "        [11.1278],\n",
      "        [11.2400],\n",
      "        [ 9.7073],\n",
      "        [14.8819],\n",
      "        [ 6.5008],\n",
      "        [16.9512],\n",
      "        [ 6.7280],\n",
      "        [ 9.4774],\n",
      "        [ 6.6272],\n",
      "        [10.7718],\n",
      "        [10.8841],\n",
      "        [ 9.7316],\n",
      "        [17.5645],\n",
      "        [ 8.9324],\n",
      "        [12.2837],\n",
      "        [ 8.4995],\n",
      "        [ 5.8328],\n",
      "        [ 6.8677],\n",
      "        [ 9.6466],\n",
      "        [10.9641],\n",
      "        [11.0896],\n",
      "        [ 8.7376],\n",
      "        [ 7.4069],\n",
      "        [11.0927],\n",
      "        [ 9.1570],\n",
      "        [13.1270],\n",
      "        [ 8.4446],\n",
      "        [ 7.6457]], device='mps:0')\n",
      "tensor([2, 1, 2, 2, 0, 3, 2, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        2, 2, 2, 0, 0, 2, 0, 0, 2, 1, 2, 2, 0, 1, 3, 3, 2, 2, 2, 3, 0, 2, 0, 0,\n",
      "        0, 3, 2, 2, 3, 3, 3, 0, 1, 0, 3, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0,\n",
      "        0, 0, 3, 3, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0,\n",
      "        2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0,\n",
      "        0, 3, 3, 2, 1, 2, 0, 2], device='mps:0')\n",
      "Batch 24 of 448\n",
      "tensor([[ 5.6411],\n",
      "        [ 6.7884],\n",
      "        [ 7.5991],\n",
      "        [ 9.3760],\n",
      "        [ 6.8677],\n",
      "        [12.5000],\n",
      "        [21.1761],\n",
      "        [ 8.9762],\n",
      "        [ 7.3139],\n",
      "        [ 5.5562],\n",
      "        [ 9.3871],\n",
      "        [10.1235],\n",
      "        [ 9.3871],\n",
      "        [ 7.7383],\n",
      "        [17.4221],\n",
      "        [ 9.1571],\n",
      "        [ 7.3830],\n",
      "        [ 8.8859],\n",
      "        [11.2016],\n",
      "        [10.8841],\n",
      "        [12.5000],\n",
      "        [ 9.4414],\n",
      "        [11.9608],\n",
      "        [ 9.6794],\n",
      "        [ 8.3353],\n",
      "        [15.0681],\n",
      "        [ 9.7999],\n",
      "        [ 8.5650],\n",
      "        [21.2228],\n",
      "        [17.6747],\n",
      "        [12.1190],\n",
      "        [10.9285],\n",
      "        [ 7.8565],\n",
      "        [ 9.4363],\n",
      "        [15.9657],\n",
      "        [ 5.1729],\n",
      "        [20.8203],\n",
      "        [ 6.6191],\n",
      "        [11.3063],\n",
      "        [11.7276],\n",
      "        [13.0885],\n",
      "        [15.7252],\n",
      "        [11.1804],\n",
      "        [ 5.8848],\n",
      "        [ 8.3680],\n",
      "        [11.1775],\n",
      "        [15.6157],\n",
      "        [10.8300],\n",
      "        [ 9.7999],\n",
      "        [ 9.6192],\n",
      "        [ 6.2215],\n",
      "        [ 7.0133],\n",
      "        [13.6197],\n",
      "        [ 7.3775],\n",
      "        [ 8.5159],\n",
      "        [16.5959],\n",
      "        [18.3640],\n",
      "        [ 5.9290],\n",
      "        [ 7.1524],\n",
      "        [15.9875],\n",
      "        [ 7.6951],\n",
      "        [13.4309],\n",
      "        [16.4342],\n",
      "        [10.3640],\n",
      "        [10.8025],\n",
      "        [19.6567],\n",
      "        [ 7.7985],\n",
      "        [ 7.4070],\n",
      "        [16.4233],\n",
      "        [ 7.4900],\n",
      "        [ 8.5570],\n",
      "        [11.9086],\n",
      "        [ 9.4003],\n",
      "        [ 6.3065],\n",
      "        [20.2722],\n",
      "        [ 6.6355],\n",
      "        [ 7.4926],\n",
      "        [14.3207],\n",
      "        [15.0295],\n",
      "        [ 9.0749],\n",
      "        [ 6.5753],\n",
      "        [14.8573],\n",
      "        [17.6439],\n",
      "        [16.0395],\n",
      "        [ 9.0825],\n",
      "        [13.3127],\n",
      "        [ 9.1866],\n",
      "        [10.5994],\n",
      "        [ 7.4926],\n",
      "        [17.4687],\n",
      "        [ 8.4256],\n",
      "        [11.7602],\n",
      "        [ 8.6582],\n",
      "        [13.9449],\n",
      "        [11.9608],\n",
      "        [ 6.3393],\n",
      "        [11.7877],\n",
      "        [ 7.5171],\n",
      "        [13.1980],\n",
      "        [ 7.4564],\n",
      "        [ 7.1936],\n",
      "        [ 6.7280],\n",
      "        [15.0298],\n",
      "        [20.8203],\n",
      "        [ 6.7772],\n",
      "        [ 9.5097],\n",
      "        [11.1749],\n",
      "        [ 8.1850],\n",
      "        [17.2611],\n",
      "        [10.2900],\n",
      "        [13.4309],\n",
      "        [12.5926],\n",
      "        [ 9.6526],\n",
      "        [ 9.0935],\n",
      "        [ 7.0922],\n",
      "        [ 8.4995],\n",
      "        [ 9.6034],\n",
      "        [15.8889],\n",
      "        [ 7.7965],\n",
      "        [17.6636],\n",
      "        [10.2112],\n",
      "        [ 6.9695],\n",
      "        [16.8362],\n",
      "        [ 9.0333],\n",
      "        [ 8.0532],\n",
      "        [11.1278],\n",
      "        [10.1235],\n",
      "        [ 7.1032]], device='mps:0')\n",
      "tensor([3, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 2, 0, 3, 0, 2, 0, 1, 3, 3,\n",
      "        0, 3, 2, 3, 2, 0, 0, 3, 0, 2, 3, 0, 3, 0, 2, 3, 2, 2, 2, 0, 0, 2, 0, 3,\n",
      "        2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 0, 2, 2, 3, 0, 3, 2, 0, 0, 3, 2, 0,\n",
      "        2, 0, 0, 2, 2, 3, 0, 0, 2, 0, 2, 3, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 3, 2,\n",
      "        2, 0, 0, 2, 0, 2, 2, 3, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0,\n",
      "        3, 0, 2, 2, 2, 0, 3, 2], device='mps:0')\n",
      "Batch 25 of 448\n",
      "tensor([[ 9.3487],\n",
      "        [ 7.6951],\n",
      "        [ 5.8306],\n",
      "        [ 9.5672],\n",
      "        [13.6521],\n",
      "        [10.2740],\n",
      "        [ 9.9400],\n",
      "        [10.7718],\n",
      "        [ 8.8389],\n",
      "        [ 8.4912],\n",
      "        [ 7.2101],\n",
      "        [ 7.7849],\n",
      "        [ 5.5869],\n",
      "        [13.7725],\n",
      "        [18.2029],\n",
      "        [10.5560],\n",
      "        [ 7.7985],\n",
      "        [10.1723],\n",
      "        [ 5.1735],\n",
      "        [ 9.2825],\n",
      "        [ 8.6582],\n",
      "        [ 5.6548],\n",
      "        [ 8.7136],\n",
      "        [ 6.4001],\n",
      "        [ 6.5397],\n",
      "        [10.9859],\n",
      "        [ 9.4686],\n",
      "        [ 7.1059],\n",
      "        [14.1509],\n",
      "        [ 9.9702],\n",
      "        [ 5.5240],\n",
      "        [ 9.1427],\n",
      "        [ 9.9178],\n",
      "        [16.1386],\n",
      "        [ 9.9039],\n",
      "        [15.9546],\n",
      "        [14.3613],\n",
      "        [13.0990],\n",
      "        [12.2311],\n",
      "        [ 9.8766],\n",
      "        [ 6.5145],\n",
      "        [16.9271],\n",
      "        [10.0825],\n",
      "        [10.4678],\n",
      "        [14.4104],\n",
      "        [11.1420],\n",
      "        [ 6.5890],\n",
      "        [14.0441],\n",
      "        [ 9.1346],\n",
      "        [15.4678],\n",
      "        [ 8.5980],\n",
      "        [15.5467],\n",
      "        [ 6.7363],\n",
      "        [11.5274],\n",
      "        [13.0934],\n",
      "        [ 8.8745],\n",
      "        [ 6.6492],\n",
      "        [ 8.5350],\n",
      "        [ 7.8866],\n",
      "        [ 7.5800],\n",
      "        [ 8.4065],\n",
      "        [ 9.8469],\n",
      "        [10.2736],\n",
      "        [20.1578],\n",
      "        [10.6190],\n",
      "        [10.2900],\n",
      "        [15.3939],\n",
      "        [16.1413],\n",
      "        [ 7.7850],\n",
      "        [ 6.2298],\n",
      "        [ 9.2718],\n",
      "        [ 8.6395],\n",
      "        [ 5.8465],\n",
      "        [15.4537],\n",
      "        [ 8.4256],\n",
      "        [ 8.7294],\n",
      "        [20.8203],\n",
      "        [18.8326],\n",
      "        [ 6.5829],\n",
      "        [14.8819],\n",
      "        [ 6.2050],\n",
      "        [ 6.5972],\n",
      "        [17.5645],\n",
      "        [ 7.9409],\n",
      "        [ 6.3612],\n",
      "        [ 6.5008],\n",
      "        [ 8.7463],\n",
      "        [ 8.0969],\n",
      "        [10.7115],\n",
      "        [16.0837],\n",
      "        [19.3358],\n",
      "        [11.9608],\n",
      "        [15.0626],\n",
      "        [ 9.3016],\n",
      "        [ 7.4185],\n",
      "        [ 7.5282],\n",
      "        [10.3749],\n",
      "        [15.0295],\n",
      "        [12.4454],\n",
      "        [ 7.9409],\n",
      "        [11.4350],\n",
      "        [ 6.7772],\n",
      "        [19.3358],\n",
      "        [ 8.6747],\n",
      "        [ 7.6562],\n",
      "        [ 9.8162],\n",
      "        [13.8470],\n",
      "        [11.2867],\n",
      "        [10.1477],\n",
      "        [ 8.6395],\n",
      "        [17.4687],\n",
      "        [11.1775],\n",
      "        [ 8.0039],\n",
      "        [ 8.9791],\n",
      "        [ 8.7376],\n",
      "        [15.1388],\n",
      "        [15.0845],\n",
      "        [14.4685],\n",
      "        [10.4492],\n",
      "        [ 8.2611],\n",
      "        [14.2714],\n",
      "        [ 8.8778],\n",
      "        [ 9.3182],\n",
      "        [ 9.4878],\n",
      "        [ 9.4277],\n",
      "        [ 7.3141],\n",
      "        [ 8.6664],\n",
      "        [ 5.6525]], device='mps:0')\n",
      "tensor([0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 1, 2, 0, 2, 2, 3, 0, 2, 2, 2, 0, 0, 0, 0,\n",
      "        0, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 3, 3, 2, 2, 2, 0, 0, 2, 2, 0,\n",
      "        2, 0, 2, 3, 2, 0, 2, 0, 3, 2, 0, 2, 3, 2, 2, 2, 2, 0, 2, 3, 3, 2, 0, 1,\n",
      "        0, 2, 2, 0, 3, 2, 0, 2, 1, 2, 0, 0, 2, 2, 2, 3, 2, 0, 3, 3, 3, 2, 0, 3,\n",
      "        2, 0, 3, 0, 0, 2, 3, 2, 3, 0, 0, 2, 2, 1, 0, 2, 2, 0, 3, 0, 2, 3, 0, 0,\n",
      "        0, 0, 0, 0, 2, 3, 0, 2], device='mps:0')\n",
      "Batch 26 of 448\n",
      "tensor([[ 8.7136],\n",
      "        [11.9715],\n",
      "        [10.0961],\n",
      "        [14.4685],\n",
      "        [10.7363],\n",
      "        [ 8.4452],\n",
      "        [10.7308],\n",
      "        [15.3250],\n",
      "        [13.0885],\n",
      "        [13.3264],\n",
      "        [ 6.3065],\n",
      "        [ 6.0272],\n",
      "        [11.0210],\n",
      "        [ 6.3612],\n",
      "        [ 8.0702],\n",
      "        [11.8862],\n",
      "        [13.7068],\n",
      "        [ 6.6513],\n",
      "        [ 7.7219],\n",
      "        [ 5.8306],\n",
      "        [11.4377],\n",
      "        [11.3413],\n",
      "        [ 6.1421],\n",
      "        [ 7.4069],\n",
      "        [ 6.3201],\n",
      "        [11.9608],\n",
      "        [17.7073],\n",
      "        [ 9.0749],\n",
      "        [ 6.2215],\n",
      "        [10.4383],\n",
      "        [ 6.5447],\n",
      "        [15.9031],\n",
      "        [15.2242],\n",
      "        [14.4104],\n",
      "        [ 8.8389],\n",
      "        [ 6.7446],\n",
      "        [ 6.7198],\n",
      "        [ 6.2927],\n",
      "        [10.7418],\n",
      "        [12.1632],\n",
      "        [21.4195],\n",
      "        [17.5727],\n",
      "        [ 8.2563],\n",
      "        [19.7932],\n",
      "        [16.3658],\n",
      "        [ 9.1428],\n",
      "        [ 5.6219],\n",
      "        [ 6.5884],\n",
      "        [ 6.6984],\n",
      "        [ 9.5538],\n",
      "        [ 5.8389],\n",
      "        [11.2291],\n",
      "        [10.6547],\n",
      "        [15.2242],\n",
      "        [12.5602],\n",
      "        [16.2097],\n",
      "        [ 9.5513],\n",
      "        [ 7.0736],\n",
      "        [15.7301],\n",
      "        [ 6.5013],\n",
      "        [11.8862],\n",
      "        [13.1269],\n",
      "        [12.4200],\n",
      "        [12.8090],\n",
      "        [ 9.0935],\n",
      "        [ 5.7731],\n",
      "        [20.1248],\n",
      "        [10.7231],\n",
      "        [ 9.0362],\n",
      "        [ 9.0333],\n",
      "        [12.2311],\n",
      "        [13.5951],\n",
      "        [ 6.2215],\n",
      "        [11.5905],\n",
      "        [16.3461],\n",
      "        [ 7.2538],\n",
      "        [13.6521],\n",
      "        [ 8.4419],\n",
      "        [10.3038],\n",
      "        [10.1537],\n",
      "        [ 6.6272],\n",
      "        [ 6.3393],\n",
      "        [12.4754],\n",
      "        [ 9.5815],\n",
      "        [ 6.4219],\n",
      "        [ 7.9875],\n",
      "        [10.6547],\n",
      "        [ 5.4198],\n",
      "        [ 8.3900],\n",
      "        [12.1221],\n",
      "        [16.2860],\n",
      "        [ 8.8746],\n",
      "        [18.6460],\n",
      "        [ 7.8507],\n",
      "        [ 6.6984],\n",
      "        [ 9.3647],\n",
      "        [ 6.1531],\n",
      "        [13.1182],\n",
      "        [13.9423],\n",
      "        [ 6.4214],\n",
      "        [ 5.8005],\n",
      "        [10.1723],\n",
      "        [10.1477],\n",
      "        [ 9.1729],\n",
      "        [20.9271],\n",
      "        [ 6.4904],\n",
      "        [15.7246],\n",
      "        [ 7.0214],\n",
      "        [ 7.6513],\n",
      "        [ 7.5906],\n",
      "        [11.0979],\n",
      "        [ 8.5026],\n",
      "        [ 7.1743],\n",
      "        [17.3022],\n",
      "        [11.5494],\n",
      "        [13.0771],\n",
      "        [ 9.9039],\n",
      "        [ 6.0799],\n",
      "        [13.7725],\n",
      "        [ 7.6151],\n",
      "        [ 9.1570],\n",
      "        [ 6.5008],\n",
      "        [ 7.5631],\n",
      "        [ 6.6355],\n",
      "        [20.9271],\n",
      "        [13.5152],\n",
      "        [ 7.7850],\n",
      "        [12.4808]], device='mps:0')\n",
      "tensor([0, 2, 2, 3, 0, 0, 2, 3, 2, 3, 0, 0, 1, 2, 0, 0, 3, 0, 0, 2, 0, 0, 3, 3,\n",
      "        2, 3, 3, 0, 2, 3, 0, 3, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 1, 0, 0,\n",
      "        2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 3, 0, 2, 0, 0, 0, 0, 3, 0,\n",
      "        2, 2, 2, 0, 2, 0, 0, 3, 0, 2, 2, 2, 3, 3, 2, 2, 2, 0, 2, 3, 2, 2, 2, 0,\n",
      "        0, 2, 2, 2, 0, 2, 2, 2, 3, 2, 3, 2, 0, 2, 0, 0, 0, 3, 2, 3, 2, 3, 2, 3,\n",
      "        1, 2, 0, 2, 3, 0, 3, 3], device='mps:0')\n",
      "Batch 27 of 448\n",
      "tensor([[ 7.4590],\n",
      "        [13.9423],\n",
      "        [11.3441],\n",
      "        [10.5780],\n",
      "        [ 7.2538],\n",
      "        [10.9170],\n",
      "        [ 8.8087],\n",
      "        [ 5.8848],\n",
      "        [11.5905],\n",
      "        [ 5.7841],\n",
      "        [ 7.8703],\n",
      "        [10.1537],\n",
      "        [ 8.9052],\n",
      "        [ 8.5327],\n",
      "        [ 9.4414],\n",
      "        [11.3989],\n",
      "        [ 8.9052],\n",
      "        [10.4789],\n",
      "        [ 8.0477],\n",
      "        [ 9.0086],\n",
      "        [ 6.7446],\n",
      "        [15.0626],\n",
      "        [ 6.3612],\n",
      "        [10.4548],\n",
      "        [ 5.7979],\n",
      "        [11.4756],\n",
      "        [ 7.7303],\n",
      "        [ 8.9053],\n",
      "        [ 6.2900],\n",
      "        [ 8.5465],\n",
      "        [ 8.5350],\n",
      "        [11.0976],\n",
      "        [ 8.8253],\n",
      "        [ 9.0611],\n",
      "        [ 6.2193],\n",
      "        [11.0979],\n",
      "        [ 8.0039],\n",
      "        [ 8.9127],\n",
      "        [16.4447],\n",
      "        [ 5.3625],\n",
      "        [12.4147],\n",
      "        [13.4280],\n",
      "        [ 8.6806],\n",
      "        [ 7.1032],\n",
      "        [ 7.6946],\n",
      "        [11.2351],\n",
      "        [ 8.3872],\n",
      "        [17.3104],\n",
      "        [14.8354],\n",
      "        [ 7.9827],\n",
      "        [ 5.6525],\n",
      "        [ 7.3823],\n",
      "        [ 5.8107],\n",
      "        [10.7992],\n",
      "        [12.8663],\n",
      "        [11.6891],\n",
      "        [ 8.8281],\n",
      "        [ 5.6411],\n",
      "        [ 7.1524],\n",
      "        [ 8.4912],\n",
      "        [ 7.9956],\n",
      "        [11.9086],\n",
      "        [11.0216],\n",
      "        [ 5.0552],\n",
      "        [11.0979],\n",
      "        [ 5.2475],\n",
      "        [16.0449],\n",
      "        [ 9.5728],\n",
      "        [ 8.9490],\n",
      "        [14.5419],\n",
      "        [ 8.5461],\n",
      "        [ 6.4439],\n",
      "        [ 9.8901],\n",
      "        [15.0845],\n",
      "        [ 9.7431],\n",
      "        [15.9875],\n",
      "        [10.9884],\n",
      "        [ 6.0988],\n",
      "        [14.4685],\n",
      "        [11.7526],\n",
      "        [ 8.4667],\n",
      "        [12.4454],\n",
      "        [ 6.7885],\n",
      "        [ 9.1346],\n",
      "        [10.3038],\n",
      "        [21.4195],\n",
      "        [ 7.7849],\n",
      "        [ 5.6548],\n",
      "        [ 7.3139],\n",
      "        [18.1290],\n",
      "        [11.0080],\n",
      "        [ 7.1311],\n",
      "        [13.8601],\n",
      "        [10.0084],\n",
      "        [12.9977],\n",
      "        [12.4147],\n",
      "        [17.5698],\n",
      "        [ 5.6219],\n",
      "        [ 6.3809],\n",
      "        [ 9.8766],\n",
      "        [14.4679],\n",
      "        [21.8990],\n",
      "        [ 7.7219],\n",
      "        [ 5.4446],\n",
      "        [ 9.9619],\n",
      "        [ 9.1022],\n",
      "        [17.6032],\n",
      "        [14.3613],\n",
      "        [ 6.0272],\n",
      "        [13.8437],\n",
      "        [13.3264],\n",
      "        [16.6450],\n",
      "        [ 6.9750],\n",
      "        [ 9.6034],\n",
      "        [ 6.1421],\n",
      "        [ 8.7980],\n",
      "        [ 9.6055],\n",
      "        [ 7.3994],\n",
      "        [ 6.8485],\n",
      "        [ 8.8476],\n",
      "        [ 8.5569],\n",
      "        [ 5.2036],\n",
      "        [11.2433],\n",
      "        [10.4713],\n",
      "        [10.1092],\n",
      "        [ 6.4541],\n",
      "        [10.1809],\n",
      "        [13.4609]], device='mps:0')\n",
      "tensor([0, 2, 1, 2, 0, 2, 0, 0, 2, 0, 0, 3, 0, 2, 1, 2, 0, 3, 0, 0, 2, 3, 2, 0,\n",
      "        0, 0, 1, 3, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 2, 3, 0, 2,\n",
      "        2, 2, 2, 1, 0, 3, 0, 2, 2, 3, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2,\n",
      "        0, 2, 3, 2, 2, 2, 3, 2, 2, 3, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2,\n",
      "        2, 0, 3, 3, 0, 0, 0, 0, 2, 3, 2, 2, 0, 0, 3, 2, 0, 2, 3, 0, 2, 3, 0, 2,\n",
      "        0, 2, 2, 2, 1, 1, 0, 0], device='mps:0')\n",
      "Batch 28 of 448\n",
      "tensor([[ 5.6251],\n",
      "        [16.1249],\n",
      "        [ 8.7846],\n",
      "        [15.2682],\n",
      "        [ 8.9708],\n",
      "        [10.4986],\n",
      "        [ 6.5857],\n",
      "        [16.2860],\n",
      "        [ 9.7753],\n",
      "        [ 6.8381],\n",
      "        [ 8.5159],\n",
      "        [ 8.8312],\n",
      "        [ 8.5986],\n",
      "        [15.0840],\n",
      "        [ 6.9033],\n",
      "        [16.4452],\n",
      "        [ 8.0969],\n",
      "        [14.8354],\n",
      "        [ 7.0872],\n",
      "        [15.3987],\n",
      "        [12.6013],\n",
      "        [10.2736],\n",
      "        [ 8.4667],\n",
      "        [ 7.1281],\n",
      "        [ 8.7679],\n",
      "        [ 6.9033],\n",
      "        [13.0421],\n",
      "        [15.9086],\n",
      "        [10.7231],\n",
      "        [ 7.3714],\n",
      "        [ 7.9764],\n",
      "        [12.6063],\n",
      "        [ 8.0533],\n",
      "        [ 6.6272],\n",
      "        [ 8.4995],\n",
      "        [ 6.5145],\n",
      "        [12.1190],\n",
      "        [ 7.0736],\n",
      "        [19.6567],\n",
      "        [ 5.5727],\n",
      "        [ 6.8840],\n",
      "        [ 6.0799],\n",
      "        [12.1190],\n",
      "        [ 5.2195],\n",
      "        [11.8429],\n",
      "        [11.9141],\n",
      "        [ 9.9593],\n",
      "        [15.4537],\n",
      "        [16.4342],\n",
      "        [ 8.3872],\n",
      "        [ 7.5253],\n",
      "        [ 8.0702],\n",
      "        [10.1535],\n",
      "        [ 7.4268],\n",
      "        [ 8.5817],\n",
      "        [ 6.3393],\n",
      "        [17.9287],\n",
      "        [15.9875],\n",
      "        [ 8.3712],\n",
      "        [11.2291],\n",
      "        [14.7992],\n",
      "        [ 9.9178],\n",
      "        [12.2481],\n",
      "        [18.7364],\n",
      "        [10.7418],\n",
      "        [11.2400],\n",
      "        [11.9333],\n",
      "        [ 7.6562],\n",
      "        [11.1775],\n",
      "        [ 6.3809],\n",
      "        [10.5338],\n",
      "        [10.8025],\n",
      "        [ 7.7685],\n",
      "        [ 8.8087],\n",
      "        [21.4195],\n",
      "        [ 6.3809],\n",
      "        [ 8.5817],\n",
      "        [14.7992],\n",
      "        [14.2057],\n",
      "        [ 7.9134],\n",
      "        [16.5465],\n",
      "        [ 8.9762],\n",
      "        [10.0086],\n",
      "        [13.7068],\n",
      "        [10.1235],\n",
      "        [ 8.4610],\n",
      "        [ 5.3625],\n",
      "        [ 9.9346],\n",
      "        [ 9.6794],\n",
      "        [16.9271],\n",
      "        [13.1182],\n",
      "        [10.8025],\n",
      "        [ 8.0532],\n",
      "        [10.6190],\n",
      "        [ 7.2729],\n",
      "        [ 8.1304],\n",
      "        [17.9401],\n",
      "        [14.0027],\n",
      "        [19.7328],\n",
      "        [17.2039],\n",
      "        [ 9.1866],\n",
      "        [11.1360],\n",
      "        [ 7.0736],\n",
      "        [17.1018],\n",
      "        [ 7.1059],\n",
      "        [ 7.4016],\n",
      "        [11.7055],\n",
      "        [ 6.4597],\n",
      "        [ 9.2003],\n",
      "        [10.7418],\n",
      "        [ 7.7109],\n",
      "        [11.2351],\n",
      "        [ 6.7501],\n",
      "        [ 8.6039],\n",
      "        [ 7.4926],\n",
      "        [ 7.7219],\n",
      "        [ 7.4375],\n",
      "        [16.9517],\n",
      "        [ 5.1729],\n",
      "        [ 9.8875],\n",
      "        [12.4035],\n",
      "        [ 7.9875],\n",
      "        [ 7.8593],\n",
      "        [11.0079],\n",
      "        [ 8.4529],\n",
      "        [11.8565],\n",
      "        [ 9.1209],\n",
      "        [ 5.5869]], device='mps:0')\n",
      "tensor([2, 2, 2, 3, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 3, 3, 2, 2, 1, 0, 2, 2, 3,\n",
      "        3, 1, 2, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0, 2, 3, 2, 2, 3, 0, 2, 0, 3, 2, 2,\n",
      "        2, 0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 3, 0, 0, 0, 3, 2, 3, 2, 0,\n",
      "        0, 0, 0, 3, 0, 2, 0, 1, 0, 0, 0, 3, 3, 1, 2, 0, 3, 2, 2, 0, 2, 2, 0, 2,\n",
      "        3, 3, 0, 3, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 3, 3, 1, 2, 0, 2, 3, 0, 0,\n",
      "        2, 3, 2, 2, 2, 0, 2, 0], device='mps:0')\n",
      "Batch 29 of 448\n",
      "tensor([[12.0341],\n",
      "        [ 8.5465],\n",
      "        [11.2867],\n",
      "        [14.9256],\n",
      "        [14.8819],\n",
      "        [16.9271],\n",
      "        [ 9.8162],\n",
      "        [12.7677],\n",
      "        [ 8.5465],\n",
      "        [ 9.0611],\n",
      "        [ 8.8389],\n",
      "        [ 8.7980],\n",
      "        [ 6.6295],\n",
      "        [12.9107],\n",
      "        [ 9.9038],\n",
      "        [ 7.9827],\n",
      "        [ 7.0922],\n",
      "        [ 9.8162],\n",
      "        [16.1523],\n",
      "        [13.3022],\n",
      "        [12.8415],\n",
      "        [10.3640],\n",
      "        [12.5602],\n",
      "        [12.3630],\n",
      "        [13.9423],\n",
      "        [14.3613],\n",
      "        [11.1360],\n",
      "        [ 7.9792],\n",
      "        [ 9.4905],\n",
      "        [ 8.8312],\n",
      "        [10.5090],\n",
      "        [ 6.5884],\n",
      "        [ 6.6295],\n",
      "        [14.9908],\n",
      "        [ 7.4070],\n",
      "        [ 9.9039],\n",
      "        [10.4492],\n",
      "        [ 9.9038],\n",
      "        [ 5.1980],\n",
      "        [ 6.7198],\n",
      "        [13.1046],\n",
      "        [15.1420],\n",
      "        [ 7.0626],\n",
      "        [17.2610],\n",
      "        [13.0421],\n",
      "        [ 7.4590],\n",
      "        [ 6.5178],\n",
      "        [ 7.0736],\n",
      "        [11.0080],\n",
      "        [ 7.0324],\n",
      "        [ 9.4878],\n",
      "        [15.3199],\n",
      "        [ 7.9409],\n",
      "        [14.1674],\n",
      "        [ 6.9717],\n",
      "        [10.5506],\n",
      "        [15.5467],\n",
      "        [ 9.6526],\n",
      "        [ 9.8629],\n",
      "        [ 8.5650],\n",
      "        [12.5297],\n",
      "        [10.2709],\n",
      "        [ 5.9504],\n",
      "        [ 7.7470],\n",
      "        [10.1537],\n",
      "        [ 9.1620],\n",
      "        [14.2960],\n",
      "        [ 8.2151],\n",
      "        [10.5506],\n",
      "        [13.3708],\n",
      "        [ 8.9347],\n",
      "        [11.6891],\n",
      "        [10.0961],\n",
      "        [ 9.8223],\n",
      "        [ 9.4721],\n",
      "        [13.3264],\n",
      "        [ 6.5178],\n",
      "        [11.7056],\n",
      "        [ 9.7348],\n",
      "        [ 6.1208],\n",
      "        [ 8.4454],\n",
      "        [ 8.8778],\n",
      "        [ 8.4667],\n",
      "        [ 9.9178],\n",
      "        [11.9086],\n",
      "        [ 5.2195],\n",
      "        [11.3008],\n",
      "        [ 9.7431],\n",
      "        [11.4377],\n",
      "        [12.5520],\n",
      "        [ 7.4185],\n",
      "        [11.3747],\n",
      "        [ 7.6946],\n",
      "        [11.3008],\n",
      "        [ 9.4774],\n",
      "        [ 7.9827],\n",
      "        [14.2057],\n",
      "        [ 7.7470],\n",
      "        [17.9893],\n",
      "        [ 9.6466],\n",
      "        [ 9.5896],\n",
      "        [ 9.4414],\n",
      "        [ 9.6526],\n",
      "        [ 5.7616],\n",
      "        [11.2810],\n",
      "        [ 7.7547],\n",
      "        [12.2393],\n",
      "        [ 9.3016],\n",
      "        [19.6567],\n",
      "        [ 7.3824],\n",
      "        [16.5959],\n",
      "        [14.7992],\n",
      "        [ 6.8485],\n",
      "        [19.3499],\n",
      "        [10.3147],\n",
      "        [ 5.3625],\n",
      "        [ 6.8540],\n",
      "        [ 6.4981],\n",
      "        [10.1887],\n",
      "        [10.5090],\n",
      "        [ 7.7470],\n",
      "        [13.8518],\n",
      "        [ 6.7884],\n",
      "        [11.6426],\n",
      "        [11.4350],\n",
      "        [ 7.3824],\n",
      "        [ 7.7903],\n",
      "        [12.4035]], device='mps:0')\n",
      "tensor([2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 3, 0, 2,\n",
      "        0, 2, 0, 3, 2, 0, 0, 0, 0, 3, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 3, 2, 0, 0, 1, 3, 2, 3, 1, 0, 3, 1, 2,\n",
      "        2, 2, 3, 3, 2, 0, 0, 0, 3, 0, 2, 2, 0, 2, 2, 3, 0, 2, 0, 2, 2, 2, 0, 2,\n",
      "        0, 1, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 3, 0, 3, 2, 0, 3, 2, 2, 2, 2, 2, 0,\n",
      "        1, 2, 2, 0, 0, 0, 2, 2], device='mps:0')\n",
      "Batch 30 of 448\n",
      "tensor([[ 9.4636],\n",
      "        [11.1085],\n",
      "        [14.2960],\n",
      "        [14.5117],\n",
      "        [ 7.2729],\n",
      "        [14.1072],\n",
      "        [ 6.2105],\n",
      "        [14.5287],\n",
      "        [ 9.3921],\n",
      "        [ 8.2262],\n",
      "        [ 7.5631],\n",
      "        [ 7.1281],\n",
      "        [ 5.0716],\n",
      "        [ 6.8381],\n",
      "        [14.4679],\n",
      "        [ 8.1599],\n",
      "        [11.6891],\n",
      "        [ 8.4610],\n",
      "        [14.4870],\n",
      "        [ 7.6151],\n",
      "        [11.5905],\n",
      "        [ 8.3822],\n",
      "        [ 7.5603],\n",
      "        [ 8.5569],\n",
      "        [ 9.1516],\n",
      "        [13.6279],\n",
      "        [14.4685],\n",
      "        [19.2077],\n",
      "        [ 9.1899],\n",
      "        [ 9.6417],\n",
      "        [10.4492],\n",
      "        [ 5.8389],\n",
      "        [ 9.5728],\n",
      "        [ 9.1126],\n",
      "        [ 6.2600],\n",
      "        [11.8752],\n",
      "        [18.6460],\n",
      "        [15.6513],\n",
      "        [11.0210],\n",
      "        [ 8.9868],\n",
      "        [15.5302],\n",
      "        [17.4467],\n",
      "        [ 8.0533],\n",
      "        [ 7.7607],\n",
      "        [ 5.5240],\n",
      "        [12.2311],\n",
      "        [ 7.3141],\n",
      "        [ 8.9708],\n",
      "        [ 9.6055],\n",
      "        [14.5287],\n",
      "        [ 5.8107],\n",
      "        [ 6.5829],\n",
      "        [14.1887],\n",
      "        [10.9641],\n",
      "        [20.2748],\n",
      "        [ 7.6151],\n",
      "        [ 6.8840],\n",
      "        [10.2112],\n",
      "        [11.7526],\n",
      "        [11.9086],\n",
      "        [ 6.3288],\n",
      "        [ 9.6656],\n",
      "        [12.2393],\n",
      "        [12.8090],\n",
      "        [ 7.8535],\n",
      "        [ 6.4296],\n",
      "        [ 6.0326],\n",
      "        [10.7718],\n",
      "        [ 7.6513],\n",
      "        [11.0209],\n",
      "        [14.9662],\n",
      "        [ 6.9750],\n",
      "        [ 9.7561],\n",
      "        [10.8076],\n",
      "        [12.6063],\n",
      "        [ 8.7627],\n",
      "        [ 8.8087],\n",
      "        [ 6.1947],\n",
      "        [12.5602],\n",
      "        [ 7.4373],\n",
      "        [12.4481],\n",
      "        [11.6891],\n",
      "        [12.0395],\n",
      "        [21.4823],\n",
      "        [ 8.4481],\n",
      "        [ 9.7561],\n",
      "        [ 7.5110],\n",
      "        [10.5560],\n",
      "        [ 7.4565],\n",
      "        [10.0189],\n",
      "        [10.2112],\n",
      "        [ 9.7561],\n",
      "        [13.8470],\n",
      "        [ 8.0888],\n",
      "        [11.7964],\n",
      "        [ 9.0826],\n",
      "        [16.9517],\n",
      "        [ 5.1980],\n",
      "        [ 6.5972],\n",
      "        [ 9.8082],\n",
      "        [ 8.8745],\n",
      "        [12.5793],\n",
      "        [ 9.6656],\n",
      "        [ 5.7430],\n",
      "        [ 6.4597],\n",
      "        [ 6.4219],\n",
      "        [ 6.5972],\n",
      "        [11.9608],\n",
      "        [ 8.4912],\n",
      "        [ 6.5529],\n",
      "        [19.3358],\n",
      "        [ 6.9717],\n",
      "        [12.6013],\n",
      "        [ 8.8476],\n",
      "        [ 6.7446],\n",
      "        [13.3708],\n",
      "        [ 6.1421],\n",
      "        [11.6891],\n",
      "        [ 5.5485],\n",
      "        [17.3482],\n",
      "        [20.1578],\n",
      "        [ 6.6513],\n",
      "        [ 7.4071],\n",
      "        [ 7.1936],\n",
      "        [10.7553],\n",
      "        [ 6.1208],\n",
      "        [ 6.4214],\n",
      "        [ 5.5485]], device='mps:0')\n",
      "tensor([2, 2, 3, 2, 0, 2, 2, 0, 2, 2, 0, 3, 2, 2, 0, 2, 2, 1, 0, 3, 2, 0, 2, 0,\n",
      "        2, 0, 3, 2, 1, 3, 0, 0, 2, 0, 2, 3, 2, 3, 1, 0, 3, 3, 0, 2, 0, 3, 3, 2,\n",
      "        2, 0, 0, 0, 0, 0, 2, 3, 2, 3, 2, 0, 0, 0, 0, 3, 2, 0, 0, 2, 0, 2, 2, 0,\n",
      "        2, 2, 0, 1, 0, 2, 0, 2, 0, 2, 3, 2, 0, 2, 0, 3, 0, 0, 3, 2, 0, 3, 2, 3,\n",
      "        3, 2, 2, 3, 0, 0, 0, 2, 0, 3, 2, 3, 0, 2, 3, 1, 0, 2, 2, 3, 3, 2, 2, 0,\n",
      "        2, 0, 2, 0, 2, 0, 2, 2], device='mps:0')\n",
      "Batch 31 of 448\n",
      "tensor([[13.8470],\n",
      "        [10.1450],\n",
      "        [ 8.2399],\n",
      "        [10.3776],\n",
      "        [18.1290],\n",
      "        [ 7.9827],\n",
      "        [12.1632],\n",
      "        [11.9601],\n",
      "        [16.6450],\n",
      "        [11.0293],\n",
      "        [ 8.9127],\n",
      "        [17.7431],\n",
      "        [ 6.2029],\n",
      "        [ 7.5719],\n",
      "        [ 9.8082],\n",
      "        [13.1270],\n",
      "        [ 9.7074],\n",
      "        [ 6.3042],\n",
      "        [10.9285],\n",
      "        [11.7055],\n",
      "        [ 8.8859],\n",
      "        [20.2748],\n",
      "        [ 6.5178],\n",
      "        [ 7.3830],\n",
      "        [ 5.4549],\n",
      "        [11.2291],\n",
      "        [ 8.4556],\n",
      "        [ 5.8662],\n",
      "        [13.8470],\n",
      "        [ 8.5159],\n",
      "        [ 7.4565],\n",
      "        [19.9847],\n",
      "        [ 8.4419],\n",
      "        [ 7.0380],\n",
      "        [17.1927],\n",
      "        [ 9.0935],\n",
      "        [ 7.4016],\n",
      "        [ 7.9251],\n",
      "        [ 9.2447],\n",
      "        [ 8.8587],\n",
      "        [13.6521],\n",
      "        [20.6643],\n",
      "        [16.9654],\n",
      "        [ 7.9764],\n",
      "        [ 7.7903],\n",
      "        [ 8.0969],\n",
      "        [11.5822],\n",
      "        [12.8415],\n",
      "        [ 7.8236],\n",
      "        [ 8.5602],\n",
      "        [ 7.1939],\n",
      "        [ 8.5467],\n",
      "        [18.3640],\n",
      "        [12.4229],\n",
      "        [ 8.7047],\n",
      "        [ 9.1183],\n",
      "        [ 8.5110],\n",
      "        [13.1269],\n",
      "        [10.1645],\n",
      "        [ 9.9287],\n",
      "        [ 9.6794],\n",
      "        [ 8.3851],\n",
      "        [ 7.6951],\n",
      "        [13.6636],\n",
      "        [ 6.7067],\n",
      "        [ 7.4016],\n",
      "        [18.9141],\n",
      "        [10.5994],\n",
      "        [12.5213],\n",
      "        [ 8.4807],\n",
      "        [ 5.6165],\n",
      "        [ 8.6725],\n",
      "        [10.8076],\n",
      "        [14.3672],\n",
      "        [ 8.7075],\n",
      "        [ 7.4069],\n",
      "        [11.3413],\n",
      "        [ 7.7903],\n",
      "        [ 9.2447],\n",
      "        [12.8663],\n",
      "        [13.4609],\n",
      "        [11.2016],\n",
      "        [15.9031],\n",
      "        [ 9.2825],\n",
      "        [14.5144],\n",
      "        [15.4537],\n",
      "        [ 9.9398],\n",
      "        [ 9.9975],\n",
      "        [ 9.9894],\n",
      "        [ 8.7136],\n",
      "        [ 7.6513],\n",
      "        [ 9.6794],\n",
      "        [ 7.8040],\n",
      "        [19.6321],\n",
      "        [11.8236],\n",
      "        [11.1804],\n",
      "        [ 7.1032],\n",
      "        [12.6063],\n",
      "        [ 7.0405],\n",
      "        [ 8.8033],\n",
      "        [ 9.5097],\n",
      "        [ 8.0181],\n",
      "        [16.9516],\n",
      "        [ 9.0825],\n",
      "        [ 6.2105],\n",
      "        [13.0934],\n",
      "        [21.4195],\n",
      "        [17.8551],\n",
      "        [15.0681],\n",
      "        [ 8.7980],\n",
      "        [ 7.3331],\n",
      "        [20.2748],\n",
      "        [11.8182],\n",
      "        [15.4131],\n",
      "        [ 7.5631],\n",
      "        [15.9086],\n",
      "        [15.1585],\n",
      "        [ 7.6207],\n",
      "        [ 7.8507],\n",
      "        [11.2351],\n",
      "        [13.5951],\n",
      "        [15.8889],\n",
      "        [12.9977],\n",
      "        [12.5870],\n",
      "        [ 9.1516],\n",
      "        [ 9.2639],\n",
      "        [ 7.5906],\n",
      "        [19.7328]], device='mps:0')\n",
      "tensor([2, 2, 3, 2, 0, 2, 0, 2, 2, 2, 0, 3, 2, 2, 3, 2, 0, 0, 3, 2, 3, 2, 2, 0,\n",
      "        2, 2, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 3, 1, 2, 3, 0, 0,\n",
      "        0, 2, 2, 0, 2, 2, 0, 3, 0, 0, 2, 2, 3, 2, 0, 2, 2, 0, 3, 2, 2, 0, 2, 0,\n",
      "        2, 0, 2, 3, 2, 2, 2, 0, 0, 0, 3, 2, 0, 2, 0, 2, 0, 0, 0, 3, 3, 0, 0, 2,\n",
      "        2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 3, 0, 2, 2, 3, 0, 0, 0, 0, 2, 2, 3,\n",
      "        0, 0, 0, 2, 2, 0, 2, 0], device='mps:0')\n",
      "Batch 32 of 448\n",
      "tensor([[11.0080],\n",
      "        [17.9287],\n",
      "        [16.6725],\n",
      "        [17.3022],\n",
      "        [ 9.9894],\n",
      "        [ 5.6525],\n",
      "        [ 9.5157],\n",
      "        [ 6.4439],\n",
      "        [ 7.7965],\n",
      "        [20.6643],\n",
      "        [11.2810],\n",
      "        [ 9.3016],\n",
      "        [13.5152],\n",
      "        [10.3640],\n",
      "        [ 5.6741],\n",
      "        [ 9.5157],\n",
      "        [18.0222],\n",
      "        [ 9.5157],\n",
      "        [ 6.0272],\n",
      "        [10.2709],\n",
      "        [ 9.6275],\n",
      "        [13.6636],\n",
      "        [ 6.6984],\n",
      "        [ 9.4905],\n",
      "        [ 8.8696],\n",
      "        [10.1809],\n",
      "        [ 6.5890],\n",
      "        [ 6.7501],\n",
      "        [ 9.9894],\n",
      "        [13.5152],\n",
      "        [ 6.1208],\n",
      "        [11.1632],\n",
      "        [ 7.3392],\n",
      "        [ 7.1059],\n",
      "        [15.0325],\n",
      "        [ 8.8746],\n",
      "        [15.7794],\n",
      "        [16.4342],\n",
      "        [10.4953],\n",
      "        [ 6.4541],\n",
      "        [15.2653],\n",
      "        [ 8.2099],\n",
      "        [ 5.4638],\n",
      "        [ 9.4774],\n",
      "        [11.1278],\n",
      "        [ 5.2966],\n",
      "        [18.4822],\n",
      "        [10.4378],\n",
      "        [ 7.1826],\n",
      "        [ 7.6207],\n",
      "        [ 8.5302],\n",
      "        [11.1749],\n",
      "        [ 8.8389],\n",
      "        [ 8.0970],\n",
      "        [12.9298],\n",
      "        [13.0585],\n",
      "        [14.8819],\n",
      "        [ 8.1850],\n",
      "        [13.5951],\n",
      "        [ 9.1346],\n",
      "        [13.1182],\n",
      "        [15.5302],\n",
      "        [ 6.5884],\n",
      "        [ 9.6493],\n",
      "        [ 9.1570],\n",
      "        [10.8984],\n",
      "        [11.0216],\n",
      "        [13.1675],\n",
      "        [12.0127],\n",
      "        [ 5.4638],\n",
      "        [ 5.8328],\n",
      "        [ 9.1571],\n",
      "        [17.7534],\n",
      "        [ 9.1866],\n",
      "        [ 8.8253],\n",
      "        [ 7.8753],\n",
      "        [ 9.2718],\n",
      "        [10.3749],\n",
      "        [ 5.8005],\n",
      "        [ 5.9290],\n",
      "        [10.6514],\n",
      "        [ 8.6747],\n",
      "        [17.6636],\n",
      "        [10.0026],\n",
      "        [ 7.4125],\n",
      "        [15.9847],\n",
      "        [13.9423],\n",
      "        [ 6.5829],\n",
      "        [13.8661],\n",
      "        [ 5.1980],\n",
      "        [ 7.7985],\n",
      "        [ 7.0872],\n",
      "        [ 9.2577],\n",
      "        [ 9.1209],\n",
      "        [ 7.6946],\n",
      "        [ 8.8696],\n",
      "        [ 5.8107],\n",
      "        [11.5822],\n",
      "        [ 8.5986],\n",
      "        [ 9.4414],\n",
      "        [ 9.1209],\n",
      "        [ 7.1939],\n",
      "        [12.8090],\n",
      "        [ 8.2284],\n",
      "        [ 6.0874],\n",
      "        [ 7.7850],\n",
      "        [12.5000],\n",
      "        [21.4195],\n",
      "        [17.7534],\n",
      "        [ 9.3349],\n",
      "        [12.1882],\n",
      "        [ 9.4414],\n",
      "        [ 6.4522],\n",
      "        [14.5117],\n",
      "        [10.7553],\n",
      "        [10.1043],\n",
      "        [21.4823],\n",
      "        [ 6.5501],\n",
      "        [ 7.6151],\n",
      "        [ 9.7999],\n",
      "        [11.7389],\n",
      "        [11.6891],\n",
      "        [10.5583],\n",
      "        [12.2393],\n",
      "        [ 9.1209],\n",
      "        [ 5.7923],\n",
      "        [12.5297],\n",
      "        [11.0210]], device='mps:0')\n",
      "tensor([0, 2, 0, 3, 0, 2, 0, 2, 2, 0, 0, 0, 0, 3, 2, 0, 3, 0, 0, 0, 0, 2, 2, 2,\n",
      "        0, 0, 2, 3, 0, 0, 0, 2, 2, 0, 2, 3, 2, 2, 3, 1, 3, 2, 2, 0, 0, 2, 0, 0,\n",
      "        2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 3, 0, 3, 1, 2, 2, 0, 3, 2, 2, 2,\n",
      "        0, 0, 2, 3, 0, 0, 0, 2, 2, 2, 0, 3, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0,\n",
      "        0, 0, 0, 2, 2, 2, 3, 3, 1, 3, 0, 0, 0, 2, 3, 2, 0, 2, 2, 2, 2, 2, 3, 2,\n",
      "        2, 2, 2, 0, 2, 0, 2, 1], device='mps:0')\n",
      "Batch 33 of 448\n",
      "tensor([[ 9.8469],\n",
      "        [ 7.7855],\n",
      "        [ 6.5972],\n",
      "        [14.6404],\n",
      "        [15.0185],\n",
      "        [ 5.0552],\n",
      "        [18.3640],\n",
      "        [12.1221],\n",
      "        [16.1523],\n",
      "        [17.9401],\n",
      "        [10.2879],\n",
      "        [ 7.3830],\n",
      "        [12.8531],\n",
      "        [10.8079],\n",
      "        [16.8362],\n",
      "        [ 5.9371],\n",
      "        [15.7307],\n",
      "        [ 6.5013],\n",
      "        [10.9170],\n",
      "        [ 8.6123],\n",
      "        [15.0900],\n",
      "        [ 5.6251],\n",
      "        [ 6.6930],\n",
      "        [16.0367],\n",
      "        [15.1553],\n",
      "        [17.7069],\n",
      "        [10.0438],\n",
      "        [ 7.9409],\n",
      "        [ 5.7731],\n",
      "        [ 6.1421],\n",
      "        [ 7.7965],\n",
      "        [13.5951],\n",
      "        [10.2713],\n",
      "        [13.0990],\n",
      "        [ 5.6165],\n",
      "        [ 7.1743],\n",
      "        [ 9.6006],\n",
      "        [16.1523],\n",
      "        [ 6.5013],\n",
      "        [ 7.1281],\n",
      "        [ 9.9867],\n",
      "        [ 8.0888],\n",
      "        [ 7.1743],\n",
      "        [10.3557],\n",
      "        [17.2610],\n",
      "        [ 8.6582],\n",
      "        [ 9.5044],\n",
      "        [ 9.7753],\n",
      "        [14.0027],\n",
      "        [11.0845],\n",
      "        [ 9.7753],\n",
      "        [ 9.0640],\n",
      "        [12.8663],\n",
      "        [ 7.1743],\n",
      "        [ 9.5097],\n",
      "        [ 7.0380],\n",
      "        [ 8.0181],\n",
      "        [16.9401],\n",
      "        [ 6.0114],\n",
      "        [ 9.7561],\n",
      "        [ 5.8465],\n",
      "        [12.5870],\n",
      "        [14.3207],\n",
      "        [ 9.1018],\n",
      "        [10.7584],\n",
      "        [20.9101],\n",
      "        [ 9.1022],\n",
      "        [ 9.2718],\n",
      "        [ 5.4198],\n",
      "        [ 7.6650],\n",
      "        [10.4433],\n",
      "        [10.1809],\n",
      "        [ 7.6650],\n",
      "        [11.0979],\n",
      "        [10.1723],\n",
      "        [11.8808],\n",
      "        [18.0222],\n",
      "        [ 6.5556],\n",
      "        [14.1120],\n",
      "        [14.1120],\n",
      "        [21.1761],\n",
      "        [10.8025],\n",
      "        [17.7074],\n",
      "        [18.0222],\n",
      "        [ 8.4556],\n",
      "        [ 8.2099],\n",
      "        [11.3413],\n",
      "        [ 8.3768],\n",
      "        [14.8711],\n",
      "        [17.3454],\n",
      "        [ 8.4147],\n",
      "        [15.9546],\n",
      "        [ 8.7463],\n",
      "        [12.7820],\n",
      "        [14.1509],\n",
      "        [10.7882],\n",
      "        [12.4229],\n",
      "        [ 5.5727],\n",
      "        [10.9120],\n",
      "        [ 8.2611],\n",
      "        [ 6.4110],\n",
      "        [ 8.9127],\n",
      "        [14.5287],\n",
      "        [15.4212],\n",
      "        [ 6.6355],\n",
      "        [ 7.3141],\n",
      "        [ 6.0031],\n",
      "        [13.0500],\n",
      "        [15.1585],\n",
      "        [ 5.8848],\n",
      "        [11.0538],\n",
      "        [12.8362],\n",
      "        [ 7.7685],\n",
      "        [10.0961],\n",
      "        [11.0976],\n",
      "        [ 5.7731],\n",
      "        [11.7802],\n",
      "        [ 8.7294],\n",
      "        [ 7.4071],\n",
      "        [ 8.2340],\n",
      "        [ 6.1394],\n",
      "        [ 9.9039],\n",
      "        [15.7575],\n",
      "        [16.6094],\n",
      "        [ 7.4125],\n",
      "        [12.1882],\n",
      "        [ 5.5946],\n",
      "        [16.6450]], device='mps:0')\n",
      "tensor([2, 2, 2, 2, 1, 0, 2, 0, 0, 3, 2, 0, 1, 1, 2, 3, 2, 0, 2, 2, 0, 2, 0, 2,\n",
      "        3, 2, 0, 0, 2, 3, 2, 0, 2, 0, 2, 0, 0, 0, 0, 3, 0, 3, 0, 0, 2, 0, 3, 2,\n",
      "        3, 0, 2, 0, 0, 0, 0, 0, 0, 2, 3, 2, 0, 2, 3, 0, 2, 3, 3, 0, 2, 3, 3, 0,\n",
      "        3, 0, 2, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 2, 0, 0, 3, 0, 2, 0, 2, 3, 2, 0,\n",
      "        2, 2, 0, 0, 0, 0, 0, 2, 2, 3, 3, 1, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2,\n",
      "        2, 2, 3, 0, 2, 3, 2, 2], device='mps:0')\n",
      "Batch 34 of 448\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_stages.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_stages.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m site_true \u001b[39m=\u001b[39m labels[:, \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_stages.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_loader_raw)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_stages.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(age_true)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_stages.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(site_true)\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/_tensor.py:523\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    520\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/_tensor_str.py:708\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_python_dispatch\u001b[39m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    707\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 708\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/_tensor_str.py:625\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    623\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    624\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 625\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[1;32m    628\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/_tensor_str.py:357\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    354\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    358\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/_tensor_str.py:191\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m             \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m nonzero_finite_vals:\n\u001b[0;32m--> 191\u001b[0m                 value_str \u001b[39m=\u001b[39m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{{\u001b[39;49;00m\u001b[39m:.\u001b[39;49m\u001b[39m{\u001b[39;49;00mPRINT_OPTS\u001b[39m.\u001b[39;49mprecision\u001b[39m}\u001b[39;49;00m\u001b[39mf\u001b[39;49m\u001b[39m}}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(value)\n\u001b[1;32m    192\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m PRINT_OPTS\u001b[39m.\u001b[39msci_mode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/_tensor.py:1052\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, format_spec)\n\u001b[1;32m   1051\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_meta \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m Tensor:\n\u001b[0;32m-> 1052\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem()\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(format_spec)\n\u001b[1;32m   1053\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(\u001b[39mself\u001b[39m, format_spec)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (x, labels) in enumerate(train_loader_raw):\n",
    "    batch_size = x.size(0)\n",
    "    tract_data = x.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "\n",
    "    age_true = labels[:, 0].float().unsqueeze(1).to(device) #for some reason non_blocking=True causes nan values\n",
    "    site_true = labels[:, 1].long().to(device, non_blocking=True) \n",
    "    print(f\"Batch {i+1} of {len(train_loader_raw)}\")\n",
    "    print(age_true)\n",
    "    print(site_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not get sample batch to determine input shape.\n",
      "Using default/manual input shape: channels=1, sequence_length=50\n"
     ]
    }
   ],
   "source": [
    "if 'x_batch' in locals() and x_batch is not None:\n",
    "    input_channels = x_batch.shape[1]\n",
    "    sequence_length = x_batch.shape[2]\n",
    "    print(f\"Detected input shape: channels={input_channels}, sequence_length={sequence_length}\")\n",
    "else:\n",
    "    print(\"Warning: Could not get sample batch to determine input shape.\")\n",
    "    # Set defaults or exit if necessary\n",
    "    input_channels = 1 # Set manually if needed\n",
    "    sequence_length = 50 # Set manually if needed (MUST MATCH VAE DECODER OUTPUT)\n",
    "    print(f\"Using default/manual input shape: channels={input_channels}, sequence_length={sequence_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3210903679.py, line 205)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 205\u001b[0;36m\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "# ================================================================================\n",
    "# STAGED TRAINING EXPERIMENT\n",
    "# ================================================================================\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"RUNNING STAGED TRAINING EXPERIMENT\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Set parameters for the staged experiment\n",
    "latent_dim = 64  # Choose the larger latent dim\n",
    "dropout = 0.0  # VAE dropout\n",
    "age_dropout = 0.0\n",
    "site_dropout = 0.0\n",
    "w_recon = 1.0\n",
    "w_kl = 0.1\n",
    "w_age = 5.0  # Higher weight for age prediction\n",
    "w_site = 5.0  # Higher weight for site adversarial training\n",
    "\n",
    "# Create models\n",
    "vae = Conv1DVariationalAutoencoder_fa(latent_dims=latent_dim, dropout=dropout)\n",
    "age_predictor = AgePredictorCNN(input_channels=input_channels, \n",
    "                              sequence_length=sequence_length, \n",
    "                              dropout=age_dropout)\n",
    "site_predictor = SitePredictorCNN(num_sites=4, \n",
    "                                input_channels=input_channels, \n",
    "                                sequence_length=sequence_length, \n",
    "                                dropout=site_dropout)\n",
    "\n",
    "# Define directory for saving staged models\n",
    "staged_save_directory = \"staged_experiment_results\"\n",
    "os.makedirs(staged_save_directory, exist_ok=True)\n",
    "print(f\"Staged experiment results will be saved in: {staged_save_directory}\")\n",
    "\n",
    "\n",
    "    \n",
    "staged_results = train_vae_age_site_staged(\n",
    "    vae_model=vae,\n",
    "    age_predictor=age_predictor,\n",
    "    site_predictor=site_predictor,\n",
    "    train_data=train_loader_raw,\n",
    "    val_data=val_loader_raw,\n",
    "    epochs_stage1=500,  # For individual training\n",
    "    epochs_stage2=1000,  # For adversarial training\n",
    "    lr=0.001,\n",
    "    device=device,\n",
    "    max_grad_norm=1.0,\n",
    "    w_recon=w_recon,\n",
    "    w_kl=w_kl,\n",
    "    w_age=w_age,\n",
    "    w_site=w_site,\n",
    "    kl_annealing_start_epoch=200,\n",
    "    kl_annealing_duration=200,\n",
    "    kl_annealing_start=0.001,\n",
    "    grl_alpha_start=0.0,\n",
    "    grl_alpha_end=2.5,\n",
    "    grl_alpha_epochs=150,\n",
    "    save_dir=staged_save_directory,\n",
    "    val_metric_to_monitor=\"val_age_mae\"\n",
    ")\n",
    "\n",
    "def process_metrics(metrics_dict, keys_to_convert):\n",
    "    processed_results = {}\n",
    "    for key in keys_to_convert:\n",
    "        metric_list = metrics_dict.get(key, [])\n",
    "        new_list = []\n",
    "        if isinstance(metric_list, (list, tuple)):\n",
    "            for val in metric_list:\n",
    "                if isinstance(val, torch.Tensor):\n",
    "                    new_list.append(float(val.cpu().item()))\n",
    "                elif isinstance(val, (int, float, np.number)):\n",
    "                    new_list.append(float(val))\n",
    "                else:\n",
    "                    new_list.append(float('nan'))\n",
    "        processed_results[key] = new_list\n",
    "    return processed_results\n",
    "\n",
    "# Process and save VAE Stage 1 results\n",
    "if staged_results and \"vae\" in staged_results:\n",
    "    vae_results = staged_results[\"vae\"]\n",
    "    \n",
    "    # Keys to convert for VAE metrics\n",
    "    vae_keys = [\n",
    "        \"train_loss_epoch\", \"val_loss_epoch\",\n",
    "        \"train_recon_loss_epoch\", \"val_recon_loss_epoch\",\n",
    "        \"train_kl_loss_epoch\", \"val_kl_loss_epoch\",\n",
    "        \"current_beta_epoch\", \"current_lr_epoch\"\n",
    "    ]\n",
    "    \n",
    "    vae_processed = process_metrics(vae_results, vae_keys)\n",
    "    \n",
    "    # Create DataFrame for VAE metrics\n",
    "    vae_epochs = len(vae_processed.get(\"train_loss_epoch\", []))\n",
    "    if vae_epochs > 0:\n",
    "        vae_df_data = {\"epoch\": range(1, vae_epochs + 1)}\n",
    "        for k in vae_keys:\n",
    "            col_name = k.replace('_epoch', '')\n",
    "            vae_df_data[col_name] = vae_processed.get(k, [float('nan')] * vae_epochs)\n",
    "        \n",
    "        vae_df = pd.DataFrame(vae_df_data)\n",
    "        vae_metrics_file = os.path.join(staged_save_directory, \"vae_metrics.csv\")\n",
    "        vae_df.to_csv(vae_metrics_file, index=False)\n",
    "        print(f\"Saved VAE training metrics to {vae_metrics_file}\")\n",
    "    \n",
    "\n",
    "# Process and save Age Predictor Stage 1 results\n",
    "if staged_results and \"age_predictor\" in staged_results:\n",
    "    age_results = staged_results[\"age_predictor\"]\n",
    "    \n",
    "    # Keys to convert for Age Predictor metrics\n",
    "    age_keys = [\"train_loss_epoch\", \"val_loss_epoch\", \"current_lr_epoch\"]\n",
    "    \n",
    "    age_processed = process_metrics(age_results, age_keys)\n",
    "    \n",
    "    # Create DataFrame for Age Predictor metrics\n",
    "    age_epochs = len(age_processed.get(\"train_loss_epoch\", []))\n",
    "    if age_epochs > 0:\n",
    "        age_df_data = {\"epoch\": range(1, age_epochs + 1)}\n",
    "        for k in age_keys:\n",
    "            col_name = k.replace('_epoch', '')\n",
    "            age_df_data[col_name] = age_processed.get(k, [float('nan')] * age_epochs)\n",
    "        \n",
    "        age_df = pd.DataFrame(age_df_data)\n",
    "        age_metrics_file = os.path.join(staged_save_directory, \"age_predictor_metrics.csv\")\n",
    "        age_df.to_csv(age_metrics_file, index=False)\n",
    "        print(f\"Saved Age Predictor training metrics to {age_metrics_file}\")\n",
    "\n",
    "# Process and save Site Predictor Stage 1 results\n",
    "if staged_results and \"site_predictor\" in staged_results:\n",
    "    site_results = staged_results[\"site_predictor\"]\n",
    "    \n",
    "    # Keys to convert for Site Predictor metrics\n",
    "    site_keys = [\"train_loss_epoch\", \"val_loss_epoch\", \"train_acc_epoch\", \"val_acc_epoch\", \"current_lr_epoch\"]\n",
    "    \n",
    "    site_processed = process_metrics(site_results, site_keys)\n",
    "    \n",
    "    # Create DataFrame for Site Predictor metrics\n",
    "    site_epochs = len(site_processed.get(\"train_loss_epoch\", []))\n",
    "    if site_epochs > 0:\n",
    "        site_df_data = {\"epoch\": range(1, site_epochs + 1)}\n",
    "        for k in site_keys:\n",
    "            col_name = k.replace('_epoch', '')\n",
    "            site_df_data[col_name] = site_processed.get(k, [float('nan')] * site_epochs)\n",
    "        \n",
    "        site_df = pd.DataFrame(site_df_data)\n",
    "        site_metrics_file = os.path.join(staged_save_directory, \"site_predictor_metrics.csv\")\n",
    "        site_df.to_csv(site_metrics_file, index=False)\n",
    "        print(f\"Saved Site Predictor training metrics to {site_metrics_file}\")\n",
    "\n",
    "# Process and save combined stage results\n",
    "if staged_results and \"combined\" in staged_results:\n",
    "    combined_results = staged_results[\"combined\"]\n",
    "    \n",
    "    # Convert metrics to CPU floats\n",
    "    keys_to_convert = [\n",
    "        \"train_loss_epoch\", \"val_loss_epoch\", \n",
    "        \"train_recon_loss_epoch\", \"val_recon_loss_epoch\",\n",
    "        \"train_kl_loss_epoch\", \"val_kl_loss_epoch\", \n",
    "        \"train_age_loss_epoch\", \"val_age_loss_epoch\",\n",
    "        \"train_site_loss_epoch\", \"val_site_loss_epoch\", \n",
    "        \"train_age_mae_epoch\", \"val_age_mae_epoch\",\n",
    "        \"train_site_acc_epoch\", \"val_site_acc_epoch\", \n",
    "        \"current_beta_epoch\", \"current_grl_alpha_epoch\",\n",
    "        \"current_lr_epoch\"\n",
    "    ]\n",
    "    \n",
    "    processed_results = process_metrics(combined_results, keys_to_convert)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    num_epochs = len(processed_results.get(\"train_loss_epoch\", []))\n",
    "    if num_epochs > 0:\n",
    "        df_data = {\"epoch\": range(1, num_epochs + 1)}\n",
    "        for k in keys_to_convert:\n",
    "            col_name = k.replace('_epoch', '')\n",
    "            metric_data = processed_results.get(k, [])\n",
    "            if len(metric_data) != num_epochs:\n",
    "                metric_data = [float('nan')] * num_epochs\n",
    "            df_data[col_name] = metric_data\n",
    "        \n",
    "        df_epochs = pd.DataFrame(df_data)\n",
    "        metrics_file = os.path.join(staged_save_directory, \"staged_combined_metrics.csv\")\n",
    "        df_epochs.to_csv(metrics_file, index=False)\n",
    "        \n",
    "        # Save summary metrics\n",
    "        best_mae_key = \"best_val_age_mae\"\n",
    "        best_mae = combined_results.get(best_mae_key, float('nan'))\n",
    "        if isinstance(best_mae, torch.Tensor):\n",
    "            best_mae = float(best_mae.cpu().item())\n",
    "        \n",
    "        df_summary = pd.DataFrame([{\n",
    "            best_mae_key: best_mae,\n",
    "            \"best_epoch\": combined_results.get(\"best_epoch\", float('nan')),\n",
    "            \"model_path\": combined_results.get(\"model_path\", \"N/A\")\n",
    "        }])\n",
    "        summary_file = os.path.join(staged_save_directory, \"staged_combined_summary.csv\")\n",
    "        df_summary.to_csv(summary_file, index=False)\n",
    "        \n",
    "        print(f\"Saved staged training metrics to {metrics_file}\")\n",
    "        print(f\"Saved staged training summary to {summary_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Staged training experiment complete!\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "print(f\"\\n !!! Staged training experiment failed: {e} !!!\\n\")\n",
    "import traceback\n",
    "traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
