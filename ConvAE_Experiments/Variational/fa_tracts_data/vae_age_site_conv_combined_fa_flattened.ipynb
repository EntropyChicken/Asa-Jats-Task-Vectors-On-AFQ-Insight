{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "from afqinsight import AFQDataset\n",
    "from afqinsight.nn.utils import prep_pytorch_data\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.normal import Normal\n",
    "from sklearn.decomposition import PCA\n",
    "import afqinsight.augmentation as aug\n",
    "from afqinsight.nn.pt_models import Conv1DAutoencoder\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Adjust path as needed\n",
    "sys.path.insert(1, '/mmfs1/gscratch/nrdg/samchou/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils')\n",
    "# sys.path.insert(1, '/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils')\n",
    "# Import necessary functions, including the new one\n",
    "from utils import select_device, train_variational_autoencoder_age_site, kl_divergence_loss,prep_fa_flattned_data, GradReverse, prep_fa_flattened_remapped_data\n",
    "from models import Conv1DVariationalAutoencoder_fa, AgePredictorCNN, SitePredictorCNN, CombinedVAE_Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "Using MPS backend on macOS. (Detailed memory info may not be available.)\n"
     ]
    }
   ],
   "source": [
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/samchou/.cache/afq-insight/hbn/subjects.tsv exists.\n",
      "File /Users/samchou/.cache/afq-insight/hbn/nodes.csv exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samchou/src/nrdg/AFQ-Insight/afqinsight/transform.py:144: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  features = interpolated.stack([\"subjectID\", \"tractID\", \"metric\"]).unstack(\n"
     ]
    }
   ],
   "source": [
    "dataset = AFQDataset.from_study('hbn')\n",
    "torch_dataset, train_loader, test_loader, val_loader = prep_pytorch_data(dataset,batch_size=128)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_idx = dataset.target_cols.index('scan_site_id')\n",
    "age_idx = dataset.target_cols.index('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique site values found: [0. 1. 3. 4.]\n",
      "Created site map: {0.0: 0, 1.0: 1, 3.0: 2, 4.0: 3}\n",
      "Number of unique sites (classes): 4\n"
     ]
    }
   ],
   "source": [
    "unique_sites = np.unique(torch_dataset.y[:, site_idx])\n",
    "print(f\"Unique site values found: {unique_sites}\")\n",
    "site_map = {float(site): i for i, site in enumerate(sorted(unique_sites))}\n",
    "print(f\"Created site map: {site_map}\")\n",
    "num_sites = len(site_map)\n",
    "print(f\"Number of unique sites (classes): {num_sites}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset, all_tracts_train_loader, all_tracts_test_loader, all_tracts_val_loader = prep_fa_flattned_data(dataset, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all tracts train loader torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(\"all tracts train loader\", all_tracts_train_loader.dataset[0][1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing initial PyTorch data loaders...\n",
      "Remapping prep: Using age index 0, site index 2 from ['age', 'sex', 'scan_site_id']\n",
      "Using site map: {0.0: 0.0, 1.0: 1.0, 3.0: 2.0, 4.0: 3.0}\n",
      "Creating remapped datasets...\n",
      "Creating final DataLoaders...\n",
      "prep_fa_flattened_remapped_data complete.\n",
      "Initial data loaders prepared.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing initial PyTorch data loaders...\")\n",
    "try:\n",
    "    # Assuming prep_pytorch_data returns torch_dataset, train_loader, test_loader, val_loader\n",
    "    # If it returns datasets, create loaders here.\n",
    "    # Adapt this call based on the actual signature and return values of your prep_pytorch_data\n",
    "    prep_output = prep_fa_flattened_remapped_data(dataset, batch_size=128)\n",
    "    if len(prep_output) == 4:\n",
    "        _, train_loader_raw, test_loader_raw, val_loader_raw = prep_output\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 4 return values from prep_pytorch_data, got {len(prep_output)}\")\n",
    "\n",
    "    print(\"Initial data loaders prepared.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error calling prep_pytorch_data: {e}\")\n",
    "     print(\"Ensure the function exists and returns DataLoaders or required components.\")\n",
    "     sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "tensor(9.9398)\n",
      "all tracts train loader tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "print(train_loader_raw.dataset[0][0].shape)\n",
    "print(train_loader_raw.dataset[0][1][0])\n",
    "print(\"all tracts train loader\", train_loader_raw.dataset[11611][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 0: tensor([[ 9.2718,  0.0000],\n",
      "        [16.0756,  2.0000],\n",
      "        [15.8889,  0.0000],\n",
      "        [ 9.1022,  3.0000],\n",
      "        [10.1783,  0.0000],\n",
      "        [ 7.4541,  0.0000],\n",
      "        [ 9.1620,  2.0000],\n",
      "        [ 5.2195,  2.0000],\n",
      "        [14.3174,  2.0000],\n",
      "        [ 8.8696,  0.0000],\n",
      "        [15.2682,  3.0000],\n",
      "        [10.3065,  3.0000],\n",
      "        [ 8.0919,  1.0000],\n",
      "        [14.4870,  0.0000],\n",
      "        [10.1887,  2.0000],\n",
      "        [13.6740,  2.0000],\n",
      "        [ 6.7067,  2.0000],\n",
      "        [ 8.5817,  0.0000],\n",
      "        [14.0250,  2.0000],\n",
      "        [17.5645,  0.0000],\n",
      "        [16.7574,  0.0000],\n",
      "        [ 5.5562,  2.0000],\n",
      "        [13.1046,  2.0000],\n",
      "        [ 6.4110,  0.0000],\n",
      "        [13.8518,  2.0000],\n",
      "        [ 8.8746,  3.0000],\n",
      "        [13.0196,  2.0000],\n",
      "        [10.4678,  0.0000],\n",
      "        [10.3119,  3.0000],\n",
      "        [14.6404,  2.0000],\n",
      "        [ 9.5538,  2.0000],\n",
      "        [13.6526,  0.0000],\n",
      "        [10.2879,  2.0000],\n",
      "        [ 6.5529,  2.0000],\n",
      "        [ 8.9053,  3.0000],\n",
      "        [11.7276,  3.0000],\n",
      "        [ 6.7884,  2.0000],\n",
      "        [ 6.3939,  1.0000],\n",
      "        [ 9.3487,  0.0000],\n",
      "        [ 7.3141,  3.0000],\n",
      "        [ 7.1743,  0.0000],\n",
      "        [ 5.3377,  2.0000],\n",
      "        [20.1248,  0.0000],\n",
      "        [ 6.5857,  2.0000],\n",
      "        [16.4063,  2.0000],\n",
      "        [ 8.4481,  0.0000],\n",
      "        [19.7328,  0.0000],\n",
      "        [10.7231,  0.0000],\n",
      "        [16.4233,  0.0000],\n",
      "        [13.3708,  3.0000],\n",
      "        [10.1783,  0.0000],\n",
      "        [ 7.5603,  2.0000],\n",
      "        [ 6.6513,  0.0000],\n",
      "        [ 8.8253,  2.0000],\n",
      "        [ 7.3392,  2.0000],\n",
      "        [ 5.7123,  2.0000],\n",
      "        [ 7.9827,  2.0000],\n",
      "        [20.9982,  2.0000],\n",
      "        [ 6.6492,  3.0000],\n",
      "        [ 9.5672,  0.0000],\n",
      "        [11.6891,  2.0000],\n",
      "        [14.9256,  0.0000],\n",
      "        [19.7328,  0.0000],\n",
      "        [ 6.0326,  0.0000],\n",
      "        [ 6.2687,  0.0000],\n",
      "        [21.4823,  2.0000],\n",
      "        [10.2275,  2.0000],\n",
      "        [13.8601,  0.0000],\n",
      "        [13.4609,  0.0000],\n",
      "        [13.8518,  2.0000],\n",
      "        [ 6.3065,  0.0000],\n",
      "        [10.2379,  2.0000],\n",
      "        [ 9.9894,  0.0000],\n",
      "        [ 6.5890,  2.0000],\n",
      "        [ 5.6548,  0.0000],\n",
      "        [ 7.6951,  0.0000],\n",
      "        [ 5.6165,  2.0000],\n",
      "        [ 8.0969,  3.0000],\n",
      "        [17.2611,  2.0000],\n",
      "        [15.0845,  2.0000],\n",
      "        [14.8819,  2.0000],\n",
      "        [15.7307,  2.0000],\n",
      "        [ 8.5465,  2.0000],\n",
      "        [ 7.7389,  0.0000],\n",
      "        [ 8.0969,  3.0000],\n",
      "        [19.2049,  2.0000],\n",
      "        [ 5.0716,  2.0000],\n",
      "        [ 7.7685,  0.0000],\n",
      "        [ 9.1620,  2.0000],\n",
      "        [ 8.3872,  0.0000],\n",
      "        [16.7158,  0.0000],\n",
      "        [10.9120,  0.0000],\n",
      "        [ 5.8107,  0.0000],\n",
      "        [ 7.8151,  2.0000],\n",
      "        [10.3640,  3.0000],\n",
      "        [ 6.4541,  1.0000],\n",
      "        [ 7.7903,  2.0000],\n",
      "        [10.7882,  0.0000],\n",
      "        [ 7.5631,  0.0000],\n",
      "        [11.3441,  1.0000],\n",
      "        [ 6.3835,  3.0000],\n",
      "        [10.8841,  2.0000],\n",
      "        [ 7.1311,  0.0000],\n",
      "        [ 9.1839,  2.0000],\n",
      "        [12.9430,  2.0000],\n",
      "        [15.0185,  1.0000],\n",
      "        [13.1675,  0.0000],\n",
      "        [ 5.5869,  0.0000],\n",
      "        [18.9141,  3.0000],\n",
      "        [15.4131,  0.0000],\n",
      "        [12.7677,  2.0000],\n",
      "        [ 8.2809,  0.0000],\n",
      "        [ 9.6794,  3.0000],\n",
      "        [ 9.6794,  3.0000],\n",
      "        [ 6.1394,  2.0000],\n",
      "        [11.4324,  0.0000],\n",
      "        [11.1775,  2.0000],\n",
      "        [ 5.5562,  2.0000],\n",
      "        [ 6.5829,  0.0000],\n",
      "        [14.8765,  2.0000],\n",
      "        [13.6526,  0.0000],\n",
      "        [10.4789,  3.0000],\n",
      "        [13.4362,  0.0000],\n",
      "        [12.4808,  3.0000],\n",
      "        [11.2016,  0.0000],\n",
      "        [ 9.7675,  3.0000],\n",
      "        [ 8.5026,  0.0000],\n",
      "        [ 9.4905,  2.0000]])\n",
      "age tensor(9.2718)\n",
      "sex tensor(0.)\n",
      "No NaN found in age column\n",
      "No NaN found in sex column\n",
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 1: tensor([[ 5.8306,  2.0000],\n",
      "        [ 9.0942,  3.0000],\n",
      "        [12.6259,  2.0000],\n",
      "        [ 6.8677,  0.0000],\n",
      "        [11.1030,  2.0000],\n",
      "        [ 9.6794,  3.0000],\n",
      "        [11.6896,  2.0000],\n",
      "        [ 5.5562,  2.0000],\n",
      "        [18.3968,  3.0000],\n",
      "        [ 8.4667,  2.0000],\n",
      "        [11.9438,  2.0000],\n",
      "        [10.2878,  2.0000],\n",
      "        [ 8.5110,  0.0000],\n",
      "        [ 6.7772,  2.0000],\n",
      "        [14.5144,  0.0000],\n",
      "        [ 5.5787,  2.0000],\n",
      "        [14.8573,  0.0000],\n",
      "        [10.5994,  2.0000],\n",
      "        [ 9.7753,  0.0000],\n",
      "        [ 6.3612,  2.0000],\n",
      "        [ 9.9593,  2.0000],\n",
      "        [ 8.6039,  1.0000],\n",
      "        [ 8.7376,  3.0000],\n",
      "        [ 5.9504,  0.0000],\n",
      "        [ 8.4452,  0.0000],\n",
      "        [16.0449,  0.0000],\n",
      "        [13.5951,  0.0000],\n",
      "        [13.6356,  0.0000],\n",
      "        [ 8.4556,  0.0000],\n",
      "        [15.6157,  0.0000],\n",
      "        [ 7.9929,  3.0000],\n",
      "        [ 5.2036,  2.0000],\n",
      "        [15.0900,  0.0000],\n",
      "        [10.7992,  3.0000],\n",
      "        [10.1893,  0.0000],\n",
      "        [ 5.9504,  0.0000],\n",
      "        [11.0214,  0.0000],\n",
      "        [ 7.8703,  0.0000],\n",
      "        [ 5.8328,  2.0000],\n",
      "        [ 9.3016,  0.0000],\n",
      "        [ 7.6457,  2.0000],\n",
      "        [ 6.4898,  1.0000],\n",
      "        [ 8.8476,  0.0000],\n",
      "        [11.8182,  3.0000],\n",
      "        [ 8.8745,  0.0000],\n",
      "        [19.7826,  0.0000],\n",
      "        [ 5.8465,  0.0000],\n",
      "        [ 5.3620,  0.0000],\n",
      "        [12.6013,  0.0000],\n",
      "        [ 6.3612,  2.0000],\n",
      "        [ 6.6984,  2.0000],\n",
      "        [14.8458,  0.0000],\n",
      "        [16.9517,  3.0000],\n",
      "        [16.8614,  3.0000],\n",
      "        [18.1290,  0.0000],\n",
      "        [10.7418,  0.0000],\n",
      "        [14.5287,  0.0000],\n",
      "        [13.0771,  3.0000],\n",
      "        [ 8.2099,  2.0000],\n",
      "        [ 8.7679,  3.0000],\n",
      "        [ 7.8703,  0.0000],\n",
      "        [ 8.8745,  0.0000],\n",
      "        [14.0250,  2.0000],\n",
      "        [ 8.4454,  3.0000],\n",
      "        [13.8470,  0.0000],\n",
      "        [ 6.4296,  0.0000],\n",
      "        [13.6581,  0.0000],\n",
      "        [ 9.1018,  0.0000],\n",
      "        [11.1749,  2.0000],\n",
      "        [ 7.7739,  0.0000],\n",
      "        [12.0127,  3.0000],\n",
      "        [ 8.7376,  3.0000],\n",
      "        [14.6404,  2.0000],\n",
      "        [15.9875,  2.0000],\n",
      "        [12.2728,  2.0000],\n",
      "        [15.8889,  0.0000],\n",
      "        [11.9333,  0.0000],\n",
      "        [ 6.8485,  0.0000],\n",
      "        [ 5.5946,  2.0000],\n",
      "        [15.1798,  3.0000],\n",
      "        [ 6.9750,  0.0000],\n",
      "        [ 9.6656,  0.0000],\n",
      "        [11.1030,  2.0000],\n",
      "        [15.6513,  3.0000],\n",
      "        [ 9.5538,  2.0000],\n",
      "        [ 8.8746,  3.0000],\n",
      "        [10.0113,  0.0000],\n",
      "        [17.6636,  0.0000],\n",
      "        [13.4198,  2.0000],\n",
      "        [ 9.3349,  2.0000],\n",
      "        [14.1096,  2.0000],\n",
      "        [ 9.4636,  2.0000],\n",
      "        [ 9.6712,  3.0000],\n",
      "        [ 5.5946,  2.0000],\n",
      "        [12.5213,  2.0000],\n",
      "        [ 5.1894,  2.0000],\n",
      "        [ 6.9662,  0.0000],\n",
      "        [ 9.7561,  2.0000],\n",
      "        [ 9.8766,  3.0000],\n",
      "        [14.6656,  2.0000],\n",
      "        [11.2433,  2.0000],\n",
      "        [ 8.9791,  0.0000],\n",
      "        [ 6.0222,  3.0000],\n",
      "        [ 9.1626,  0.0000],\n",
      "        [12.0341,  2.0000],\n",
      "        [ 7.3714,  0.0000],\n",
      "        [11.0976,  2.0000],\n",
      "        [ 8.4419,  0.0000],\n",
      "        [ 8.2120,  0.0000],\n",
      "        [16.4063,  2.0000],\n",
      "        [ 5.8848,  0.0000],\n",
      "        [18.4822,  0.0000],\n",
      "        [ 7.6562,  3.0000],\n",
      "        [13.6581,  0.0000],\n",
      "        [19.2049,  2.0000],\n",
      "        [14.1154,  0.0000],\n",
      "        [10.5583,  2.0000],\n",
      "        [14.0250,  2.0000],\n",
      "        [ 7.7470,  1.0000],\n",
      "        [13.9423,  2.0000],\n",
      "        [11.1749,  2.0000],\n",
      "        [ 9.9593,  2.0000],\n",
      "        [ 7.3171,  0.0000],\n",
      "        [ 9.4003,  2.0000],\n",
      "        [ 9.0362,  0.0000],\n",
      "        [11.2433,  2.0000],\n",
      "        [ 6.2927,  2.0000],\n",
      "        [15.9031,  3.0000]])\n",
      "age tensor(5.8306)\n",
      "sex tensor(2.)\n",
      "No NaN found in age column\n",
      "No NaN found in sex column\n",
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 2: tensor([[ 9.0942,  3.0000],\n",
      "        [10.9034,  2.0000],\n",
      "        [ 8.2206,  0.0000],\n",
      "        [12.1882,  3.0000],\n",
      "        [ 7.0100,  0.0000],\n",
      "        [15.0298,  2.0000],\n",
      "        [15.5467,  3.0000],\n",
      "        [ 7.3830,  0.0000],\n",
      "        [ 8.1850,  0.0000],\n",
      "        [ 6.4214,  2.0000],\n",
      "        [11.2351,  3.0000],\n",
      "        [11.9438,  2.0000],\n",
      "        [ 6.1947,  2.0000],\n",
      "        [ 6.2927,  2.0000],\n",
      "        [ 5.3377,  2.0000],\n",
      "        [19.2077,  2.0000],\n",
      "        [11.3413,  2.0000],\n",
      "        [ 9.7753,  2.0000],\n",
      "        [ 9.1126,  0.0000],\n",
      "        [12.8531,  1.0000],\n",
      "        [ 5.7616,  0.0000],\n",
      "        [19.2077,  2.0000],\n",
      "        [ 9.2523,  3.0000],\n",
      "        [ 8.7819,  2.0000],\n",
      "        [ 9.9400,  2.0000],\n",
      "        [11.9086,  0.0000],\n",
      "        [10.8841,  2.0000],\n",
      "        [ 7.8177,  0.0000],\n",
      "        [ 8.0915,  3.0000],\n",
      "        [ 5.1729,  0.0000],\n",
      "        [10.3147,  2.0000],\n",
      "        [ 7.4375,  2.0000],\n",
      "        [13.0224,  0.0000],\n",
      "        [ 9.8629,  0.0000],\n",
      "        [ 8.9762,  0.0000],\n",
      "        [ 7.7772,  2.0000],\n",
      "        [10.4713,  2.0000],\n",
      "        [16.2860,  2.0000],\n",
      "        [11.3906,  3.0000],\n",
      "        [16.2097,  0.0000],\n",
      "        [15.1585,  0.0000],\n",
      "        [ 5.7507,  2.0000],\n",
      "        [13.6636,  2.0000],\n",
      "        [10.3749,  0.0000],\n",
      "        [13.0990,  0.0000],\n",
      "        [12.1190,  0.0000],\n",
      "        [16.0367,  2.0000],\n",
      "        [ 8.5350,  0.0000],\n",
      "        [ 6.7280,  2.0000],\n",
      "        [13.8518,  2.0000],\n",
      "        [ 9.7697,  2.0000],\n",
      "        [ 5.6165,  2.0000],\n",
      "        [12.4808,  3.0000],\n",
      "        [ 6.5008,  2.0000],\n",
      "        [10.4953,  3.0000],\n",
      "        [13.3264,  3.0000],\n",
      "        [10.7308,  2.0000],\n",
      "        [ 8.5026,  0.0000],\n",
      "        [11.9608,  3.0000],\n",
      "        [ 9.3816,  2.0000],\n",
      "        [ 6.4597,  0.0000],\n",
      "        [ 9.0362,  0.0000],\n",
      "        [12.3844,  0.0000],\n",
      "        [ 7.8565,  0.0000],\n",
      "        [ 7.6562,  3.0000],\n",
      "        [11.6426,  0.0000],\n",
      "        [ 7.8565,  0.0000],\n",
      "        [12.8362,  0.0000],\n",
      "        [12.4063,  2.0000],\n",
      "        [13.8799,  0.0000],\n",
      "        [11.6650,  2.0000],\n",
      "        [ 9.4905,  2.0000],\n",
      "        [14.9662,  2.0000],\n",
      "        [ 7.0324,  0.0000],\n",
      "        [ 8.4065,  3.0000],\n",
      "        [ 5.7430,  2.0000],\n",
      "        [ 7.8507,  2.0000],\n",
      "        [17.9538,  3.0000],\n",
      "        [ 9.7561,  2.0000],\n",
      "        [ 6.0272,  0.0000],\n",
      "        [17.3482,  0.0000],\n",
      "        [11.7526,  2.0000],\n",
      "        [ 8.6039,  1.0000],\n",
      "        [ 7.8565,  0.0000],\n",
      "        [20.1578,  2.0000],\n",
      "        [ 6.2576,  2.0000],\n",
      "        [ 7.8151,  2.0000],\n",
      "        [ 8.5570,  2.0000],\n",
      "        [15.1585,  0.0000],\n",
      "        [17.1018,  0.0000],\n",
      "        [ 7.4900,  3.0000],\n",
      "        [ 9.9619,  2.0000],\n",
      "        [ 9.3373,  0.0000],\n",
      "        [ 8.2099,  2.0000],\n",
      "        [ 9.4363,  2.0000],\n",
      "        [ 9.4003,  2.0000],\n",
      "        [15.3987,  1.0000],\n",
      "        [15.1798,  3.0000],\n",
      "        [15.7246,  3.0000],\n",
      "        [ 5.7781,  2.0000],\n",
      "        [10.4678,  0.0000],\n",
      "        [ 9.7999,  2.0000],\n",
      "        [15.4678,  0.0000],\n",
      "        [17.7073,  3.0000],\n",
      "        [ 9.6034,  2.0000],\n",
      "        [ 8.4447,  2.0000],\n",
      "        [ 9.1899,  1.0000],\n",
      "        [ 9.7183,  0.0000],\n",
      "        [ 9.1866,  0.0000],\n",
      "        [ 6.5090,  0.0000],\n",
      "        [10.1235,  3.0000],\n",
      "        [ 7.4400,  2.0000],\n",
      "        [ 6.2050,  1.0000],\n",
      "        [15.3250,  3.0000],\n",
      "        [ 8.2340,  2.0000],\n",
      "        [12.0975,  2.0000],\n",
      "        [ 8.6747,  2.0000],\n",
      "        [11.8808,  0.0000],\n",
      "        [15.1798,  3.0000],\n",
      "        [ 8.8745,  0.0000],\n",
      "        [11.4756,  0.0000],\n",
      "        [15.4212,  2.0000],\n",
      "        [ 8.4256,  2.0000],\n",
      "        [ 8.6123,  2.0000],\n",
      "        [10.0518,  0.0000],\n",
      "        [ 6.5501,  2.0000],\n",
      "        [10.0025,  2.0000],\n",
      "        [14.2714,  0.0000]])\n",
      "age tensor(9.0942)\n",
      "sex tensor(3.)\n",
      "NaN found in age column\n",
      "No NaN found in sex column\n",
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 3: tensor([[ 6.2494,  0.0000],\n",
      "        [12.0127,  3.0000],\n",
      "        [11.0896,  0.0000],\n",
      "        [ 8.4832,  2.0000],\n",
      "        [16.0400,  2.0000],\n",
      "        [10.7231,  0.0000],\n",
      "        [ 6.5501,  2.0000],\n",
      "        [ 6.2189,  0.0000],\n",
      "        [16.9212,  0.0000],\n",
      "        [ 6.3612,  2.0000],\n",
      "        [ 7.7363,  3.0000],\n",
      "        [ 7.4400,  2.0000],\n",
      "        [ 5.9617,  0.0000],\n",
      "        [ 6.8540,  2.0000],\n",
      "        [10.5338,  2.0000],\n",
      "        [11.1360,  0.0000],\n",
      "        [14.1072,  2.0000],\n",
      "        [ 8.4454,  3.0000],\n",
      "        [10.2713,  2.0000],\n",
      "        [ 9.1626,  0.0000],\n",
      "        [ 6.5972,  2.0000],\n",
      "        [ 8.7404,  3.0000],\n",
      "        [ 9.6034,  2.0000],\n",
      "        [ 8.5650,  1.0000],\n",
      "        [10.0961,  2.0000],\n",
      "        [11.1749,  2.0000],\n",
      "        [12.4857,  0.0000],\n",
      "        [ 8.2151,  1.0000],\n",
      "        [11.0079,  2.0000],\n",
      "        [11.7526,  2.0000],\n",
      "        [ 7.4565,  0.0000],\n",
      "        [ 5.1980,  2.0000],\n",
      "        [ 9.1023,  0.0000],\n",
      "        [ 8.7075,  2.0000],\n",
      "        [ 6.3256,  2.0000],\n",
      "        [ 7.4541,  0.0000],\n",
      "        [12.5297,  2.0000],\n",
      "        [16.0400,  2.0000],\n",
      "        [17.1376,  2.0000],\n",
      "        [ 9.3487,  0.0000],\n",
      "        [ 9.2718,  0.0000],\n",
      "        [ 5.4446,  0.0000],\n",
      "        [ 9.6794,  3.0000],\n",
      "        [ 9.6493,  3.0000],\n",
      "        [ 5.8328,  2.0000],\n",
      "        [16.0837,  0.0000],\n",
      "        [15.1744,  0.0000],\n",
      "        [10.1783,  0.0000],\n",
      "        [12.0695,  0.0000],\n",
      "        [10.0189,  0.0000],\n",
      "        [14.2133,  0.0000],\n",
      "        [16.8614,  3.0000],\n",
      "        [10.4986,  0.0000],\n",
      "        [10.3749,  0.0000],\n",
      "        [ 6.9033,  1.0000],\n",
      "        [ 9.5070,  2.0000],\n",
      "        [ 7.7383,  0.0000],\n",
      "        [ 7.7109,  2.0000],\n",
      "        [13.0421,  2.0000],\n",
      "        [ 7.0133,  2.0000],\n",
      "        [ 9.3103,  0.0000],\n",
      "        [14.9256,  0.0000],\n",
      "        [ 6.2900,  2.0000],\n",
      "        [11.2351,  3.0000],\n",
      "        [10.4678,  0.0000],\n",
      "        [ 7.2428,  2.0000],\n",
      "        [ 9.8711,  3.0000],\n",
      "        [14.5424,  0.0000],\n",
      "        [ 9.2940,  2.0000],\n",
      "        [10.5560,  3.0000],\n",
      "        [12.0395,  3.0000],\n",
      "        [15.4537,  2.0000],\n",
      "        [20.2722,  0.0000],\n",
      "        [ 5.9504,  0.0000],\n",
      "        [16.6725,  0.0000],\n",
      "        [14.2057,  0.0000],\n",
      "        [ 9.1761,  2.0000],\n",
      "        [12.7677,  2.0000],\n",
      "        [19.7826,  0.0000],\n",
      "        [10.9170,  2.0000],\n",
      "        [ 6.3612,  2.0000],\n",
      "        [ 5.6219,  0.0000],\n",
      "        [10.6514,  2.0000],\n",
      "        [15.7794,  2.0000],\n",
      "        [17.9287,  2.0000],\n",
      "        [ 5.3625,  2.0000],\n",
      "        [11.9715,  2.0000],\n",
      "        [ 9.0749,  0.0000],\n",
      "        [14.9908,  3.0000],\n",
      "        [ 7.8151,  2.0000],\n",
      "        [14.8354,  2.0000],\n",
      "        [ 6.2900,  2.0000],\n",
      "        [ 7.3441,  2.0000],\n",
      "        [10.0441,  0.0000],\n",
      "        [11.1804,  2.0000],\n",
      "        [11.0979,  0.0000],\n",
      "        [ 9.5864,  0.0000],\n",
      "        [ 9.1023,  0.0000],\n",
      "        [11.9438,  2.0000],\n",
      "        [ 9.8985,  0.0000],\n",
      "        [ 9.6192,  2.0000],\n",
      "        [ 9.1756,  0.0000],\n",
      "        [ 6.4522,  0.0000],\n",
      "        [ 8.2099,  2.0000],\n",
      "        [ 9.8629,  0.0000],\n",
      "        [ 7.6207,  2.0000],\n",
      "        [ 5.6548,  0.0000],\n",
      "        [ 8.8033,  2.0000],\n",
      "        [ 8.5570,  2.0000],\n",
      "        [16.2860,  2.0000],\n",
      "        [11.8236,  0.0000],\n",
      "        [ 7.8236,  0.0000],\n",
      "        [ 6.5753,  2.0000],\n",
      "        [ 7.6151,  2.0000],\n",
      "        [13.1675,  0.0000],\n",
      "        [15.7301,  0.0000],\n",
      "        [ 7.7850,  3.0000],\n",
      "        [16.4063,  2.0000],\n",
      "        [ 5.9504,  0.0000],\n",
      "        [14.1096,  2.0000],\n",
      "        [15.0792,  0.0000],\n",
      "        [ 8.7869,  0.0000],\n",
      "        [ 6.9717,  1.0000],\n",
      "        [ 7.3141,  3.0000],\n",
      "        [ 8.9868,  0.0000],\n",
      "        [11.0079,  2.0000],\n",
      "        [ 6.1394,  2.0000],\n",
      "        [ 8.0533,  0.0000]])\n",
      "age tensor(6.2494)\n",
      "sex tensor(0.)\n",
      "No NaN found in age column\n",
      "No NaN found in sex column\n",
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 4: tensor([[14.2960,  3.0000],\n",
      "        [11.5301,  0.0000],\n",
      "        [10.4686,  3.0000],\n",
      "        [11.7276,  3.0000],\n",
      "        [12.9430,  2.0000],\n",
      "        [14.1154,  0.0000],\n",
      "        [ 7.1939,  2.0000],\n",
      "        [15.3579,  0.0000],\n",
      "        [13.4309,  2.0000],\n",
      "        [ 6.5397,  0.0000],\n",
      "        [13.0885,  2.0000],\n",
      "        [12.5411,  0.0000],\n",
      "        [12.8090,  3.0000],\n",
      "        [ 8.5650,  1.0000],\n",
      "        [16.4447,  0.0000],\n",
      "        [ 8.7294,  0.0000],\n",
      "        [ 7.9792,  3.0000],\n",
      "        [10.4215,  0.0000],\n",
      "        [16.1413,  1.0000],\n",
      "        [12.8065,  0.0000],\n",
      "        [17.3104,  2.0000],\n",
      "        [10.4686,  3.0000],\n",
      "        [ 7.1281,  3.0000],\n",
      "        [ 9.5728,  2.0000],\n",
      "        [ 6.5884,  0.0000],\n",
      "        [ 6.5447,  0.0000],\n",
      "        [ 6.2215,  2.0000],\n",
      "        [ 6.5145,  2.0000],\n",
      "        [ 6.3288,  0.0000],\n",
      "        [ 8.4452,  0.0000],\n",
      "        [ 9.1427,  2.0000],\n",
      "        [ 9.9975,  2.0000],\n",
      "        [15.0845,  2.0000],\n",
      "        [14.3613,  2.0000],\n",
      "        [17.9538,  3.0000],\n",
      "        [20.8203,  3.0000],\n",
      "        [18.4822,  0.0000],\n",
      "        [ 7.4398,  0.0000],\n",
      "        [19.7826,  0.0000],\n",
      "        [10.9256,  2.0000],\n",
      "        [ 6.5556,  3.0000],\n",
      "        [15.7307,  2.0000],\n",
      "        [ 9.0333,  0.0000],\n",
      "        [ 8.2667,  3.0000],\n",
      "        [11.3419,  0.0000],\n",
      "        [ 9.9400,  2.0000],\n",
      "        [ 9.6330,  2.0000],\n",
      "        [11.1804,  2.0000],\n",
      "        [ 7.0324,  0.0000],\n",
      "        [ 9.1126,  0.0000],\n",
      "        [ 5.8107,  0.0000],\n",
      "        [11.3665,  0.0000],\n",
      "        [11.9333,  0.0000],\n",
      "        [12.5650,  0.0000],\n",
      "        [ 5.2693,  2.0000],\n",
      "        [12.0751,  2.0000],\n",
      "        [11.5905,  2.0000],\n",
      "        [11.3419,  0.0000],\n",
      "        [10.0026,  3.0000],\n",
      "        [10.5338,  2.0000],\n",
      "        [12.4857,  2.0000],\n",
      "        [ 8.4256,  2.0000],\n",
      "        [12.9901,  3.0000],\n",
      "        [ 7.5719,  2.0000],\n",
      "        [15.9875,  2.0000],\n",
      "        [15.1798,  3.0000],\n",
      "        [ 5.7369,  2.0000],\n",
      "        [ 6.3528,  2.0000],\n",
      "        [14.3672,  0.0000],\n",
      "        [14.2133,  0.0000],\n",
      "        [ 5.9371,  3.0000],\n",
      "        [ 9.0825,  0.0000],\n",
      "        [11.0079,  2.0000],\n",
      "        [ 8.5461,  0.0000],\n",
      "        [ 5.5946,  2.0000],\n",
      "        [12.0395,  3.0000],\n",
      "        [ 7.5116,  2.0000],\n",
      "        [11.9710,  2.0000],\n",
      "        [18.6600,  0.0000],\n",
      "        [ 8.4065,  3.0000],\n",
      "        [16.8362,  2.0000],\n",
      "        [20.9101,  3.0000],\n",
      "        [11.2400,  0.0000],\n",
      "        [13.8437,  0.0000],\n",
      "        [ 9.7183,  0.0000],\n",
      "        [ 9.3349,  2.0000],\n",
      "        [ 8.1599,  2.0000],\n",
      "        [16.1523,  0.0000],\n",
      "        [ 5.4198,  2.0000],\n",
      "        [16.3658,  2.0000],\n",
      "        [ 7.8535,  2.0000],\n",
      "        [16.9512,  0.0000],\n",
      "        [ 8.5734,  2.0000],\n",
      "        [10.2736,  2.0000],\n",
      "        [11.3906,  3.0000],\n",
      "        [11.4673,  2.0000],\n",
      "        [ 9.1866,  0.0000],\n",
      "        [18.8326,  2.0000],\n",
      "        [11.7276,  3.0000],\n",
      "        [ 8.9052,  0.0000],\n",
      "        [11.2400,  0.0000],\n",
      "        [ 8.2206,  0.0000],\n",
      "        [ 9.9341,  1.0000],\n",
      "        [12.1221,  0.0000],\n",
      "        [ 6.3835,  3.0000],\n",
      "        [12.2311,  3.0000],\n",
      "        [ 8.5817,  0.0000],\n",
      "        [11.4673,  2.0000],\n",
      "        [ 9.3016,  2.0000],\n",
      "        [13.5212,  0.0000],\n",
      "        [10.6547,  2.0000],\n",
      "        [11.0927,  2.0000],\n",
      "        [10.8841,  2.0000],\n",
      "        [ 7.5171,  0.0000],\n",
      "        [13.1046,  2.0000],\n",
      "        [12.0341,  2.0000],\n",
      "        [ 7.1743,  0.0000],\n",
      "        [ 7.8177,  0.0000],\n",
      "        [ 6.9750,  0.0000],\n",
      "        [ 7.2729,  0.0000],\n",
      "        [ 6.4110,  0.0000],\n",
      "        [ 6.2189,  0.0000],\n",
      "        [15.2242,  0.0000],\n",
      "        [ 5.9371,  3.0000],\n",
      "        [10.6547,  2.0000],\n",
      "        [11.9141,  3.0000],\n",
      "        [ 6.0031,  3.0000],\n",
      "        [11.4673,  2.0000]])\n",
      "age tensor(14.2960)\n",
      "sex tensor(3.)\n",
      "NaN found in age column\n",
      "No NaN found in sex column\n",
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 5: tensor([[ 9.1899,  1.0000],\n",
      "        [17.4473,  2.0000],\n",
      "        [17.7073,  3.0000],\n",
      "        [15.2242,  0.0000],\n",
      "        [10.1783,  0.0000],\n",
      "        [ 9.5731,  2.0000],\n",
      "        [11.3906,  3.0000],\n",
      "        [18.6600,  0.0000],\n",
      "        [ 7.8753,  3.0000],\n",
      "        [12.4808,  3.0000],\n",
      "        [ 8.3768,  0.0000],\n",
      "        [10.7939,  2.0000],\n",
      "        [12.5411,  0.0000],\n",
      "        [17.3104,  2.0000],\n",
      "        [18.0222,  3.0000],\n",
      "        [10.1043,  2.0000],\n",
      "        [15.0298,  2.0000],\n",
      "        [ 9.8901,  0.0000],\n",
      "        [14.3672,  0.0000],\n",
      "        [ 6.4898,  1.0000],\n",
      "        [ 7.4564,  2.0000],\n",
      "        [ 8.2399,  3.0000],\n",
      "        [11.8752,  3.0000],\n",
      "        [ 9.5672,  0.0000],\n",
      "        [10.0218,  0.0000],\n",
      "        [ 8.2120,  0.0000],\n",
      "        [ 6.4904,  2.0000],\n",
      "        [ 7.7855,  2.0000],\n",
      "        [ 8.4610,  1.0000],\n",
      "        [19.2049,  2.0000],\n",
      "        [14.0250,  0.0000],\n",
      "        [21.4823,  2.0000],\n",
      "        [ 9.7431,  3.0000],\n",
      "        [ 8.0919,  1.0000],\n",
      "        [18.8814,  0.0000],\n",
      "        [12.7820,  3.0000],\n",
      "        [12.8415,  0.0000],\n",
      "        [ 5.7923,  0.0000],\n",
      "        [ 6.4685,  0.0000],\n",
      "        [ 6.5178,  2.0000],\n",
      "        [ 7.7685,  0.0000],\n",
      "        [ 7.6951,  0.0000],\n",
      "        [ 8.3900,  2.0000],\n",
      "        [12.2563,  0.0000],\n",
      "        [17.3482,  0.0000],\n",
      "        [ 7.5906,  2.0000],\n",
      "        [12.9046,  0.0000],\n",
      "        [ 9.3016,  2.0000],\n",
      "        [ 7.6457,  2.0000],\n",
      "        [19.7932,  0.0000],\n",
      "        [ 5.4446,  0.0000],\n",
      "        [10.5035,  0.0000],\n",
      "        [ 8.6664,  0.0000],\n",
      "        [10.9285,  3.0000],\n",
      "        [15.0840,  2.0000],\n",
      "        [ 7.4398,  0.0000],\n",
      "        [ 9.0826,  3.0000],\n",
      "        [15.6157,  0.0000],\n",
      "        [13.4418,  0.0000],\n",
      "        [ 6.5972,  2.0000],\n",
      "        [ 7.0704,  2.0000],\n",
      "        [ 9.0333,  2.0000],\n",
      "        [14.5144,  0.0000],\n",
      "        [17.2610,  2.0000],\n",
      "        [ 9.8766,  3.0000],\n",
      "        [ 9.6493,  3.0000],\n",
      "        [14.2960,  3.0000],\n",
      "        [12.0341,  2.0000],\n",
      "        [10.3557,  0.0000],\n",
      "        [ 5.6525,  2.0000],\n",
      "        [17.9538,  3.0000],\n",
      "        [ 9.6055,  2.0000],\n",
      "        [ 7.7985,  2.0000],\n",
      "        [21.8196,  2.0000],\n",
      "        [ 8.7376,  3.0000],\n",
      "        [12.9977,  0.0000],\n",
      "        [ 8.7404,  3.0000],\n",
      "        [10.0961,  2.0000],\n",
      "        [16.6719,  2.0000],\n",
      "        [14.3536,  3.0000],\n",
      "        [15.1744,  0.0000],\n",
      "        [ 6.9695,  0.0000],\n",
      "        [ 6.2600,  2.0000],\n",
      "        [ 9.7697,  2.0000],\n",
      "        [12.5793,  0.0000],\n",
      "        [19.7932,  0.0000],\n",
      "        [10.3749,  0.0000],\n",
      "        [19.7826,  0.0000],\n",
      "        [ 7.5631,  0.0000],\n",
      "        [ 7.0100,  0.0000],\n",
      "        [ 7.6207,  2.0000],\n",
      "        [13.3022,  0.0000],\n",
      "        [ 5.5562,  2.0000],\n",
      "        [11.0896,  0.0000],\n",
      "        [ 7.6650,  3.0000],\n",
      "        [ 6.3288,  0.0000],\n",
      "        [11.1775,  2.0000],\n",
      "        [ 6.7198,  0.0000],\n",
      "        [ 5.2036,  2.0000],\n",
      "        [12.2536,  0.0000],\n",
      "        [ 5.6251,  0.0000],\n",
      "        [10.7584,  2.0000],\n",
      "        [16.4233,  0.0000],\n",
      "        [18.0222,  3.0000],\n",
      "        [14.3672,  0.0000],\n",
      "        [ 9.6055,  2.0000],\n",
      "        [12.5520,  2.0000],\n",
      "        [11.7602,  2.0000],\n",
      "        [10.8841,  2.0000],\n",
      "        [ 7.0324,  0.0000],\n",
      "        [ 7.0133,  2.0000],\n",
      "        [11.8259,  0.0000],\n",
      "        [11.6896,  2.0000],\n",
      "        [ 6.3612,  2.0000],\n",
      "        [ 7.5110,  0.0000],\n",
      "        [ 9.7561,  2.0000],\n",
      "        [ 8.7404,  3.0000],\n",
      "        [ 7.0214,  2.0000],\n",
      "        [10.1969,  2.0000],\n",
      "        [10.0025,  2.0000],\n",
      "        [18.8954,  0.0000],\n",
      "        [12.2481,  0.0000],\n",
      "        [13.6581,  0.0000],\n",
      "        [ 9.3816,  2.0000],\n",
      "        [ 8.6395,  1.0000],\n",
      "        [ 9.1570,  1.0000],\n",
      "        [ 6.2105,  2.0000],\n",
      "        [11.1420,  2.0000]])\n",
      "age tensor(9.1899)\n",
      "sex tensor(1.)\n",
      "No NaN found in age column\n",
      "No NaN found in sex column\n",
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 6: tensor([[ 9.4363,  2.0000],\n",
      "        [17.4467,  3.0000],\n",
      "        [ 9.2197,  3.0000],\n",
      "        [12.5926,  0.0000],\n",
      "        [ 9.2690,  1.0000],\n",
      "        [10.9859,  2.0000],\n",
      "        [ 8.4009,  2.0000],\n",
      "        [ 7.3714,  0.0000],\n",
      "        [ 8.6582,  0.0000],\n",
      "        [ 8.9052,  0.0000],\n",
      "        [10.5994,  2.0000],\n",
      "        [ 5.6362,  0.0000],\n",
      "        [ 6.1208,  0.0000],\n",
      "        [16.0367,  2.0000],\n",
      "        [ 5.9559,  0.0000],\n",
      "        [10.9887,  0.0000],\n",
      "        [11.1749,  2.0000],\n",
      "        [ 8.2535,  2.0000],\n",
      "        [10.4548,  0.0000],\n",
      "        [ 8.4807,  0.0000],\n",
      "        [10.1235,  3.0000],\n",
      "        [10.5994,  2.0000],\n",
      "        [ 7.7850,  3.0000],\n",
      "        [ 6.2105,  2.0000],\n",
      "        [12.1190,  0.0000],\n",
      "        [ 6.1284,  2.0000],\n",
      "        [ 7.7109,  2.0000],\n",
      "        [10.0825,  2.0000],\n",
      "        [13.0990,  0.0000],\n",
      "        [ 8.4832,  2.0000],\n",
      "        [ 8.3872,  0.0000],\n",
      "        [10.6547,  2.0000],\n",
      "        [10.1887,  2.0000],\n",
      "        [ 9.3373,  0.0000],\n",
      "        [ 8.5817,  0.0000],\n",
      "        [10.5583,  2.0000],\n",
      "        [15.2345,  0.0000],\n",
      "        [ 7.4125,  2.0000],\n",
      "        [ 8.0702,  0.0000],\n",
      "        [12.8531,  1.0000],\n",
      "        [13.8437,  0.0000],\n",
      "        [ 9.9975,  2.0000],\n",
      "        [12.3630,  2.0000],\n",
      "        [10.7361,  0.0000],\n",
      "        [10.2271,  2.0000],\n",
      "        [ 9.5070,  2.0000],\n",
      "        [13.6740,  2.0000],\n",
      "        [10.4383,  3.0000],\n",
      "        [ 8.0532,  2.0000],\n",
      "        [18.3640,  2.0000],\n",
      "        [15.7252,  2.0000],\n",
      "        [ 6.1913,  2.0000],\n",
      "        [15.0325,  2.0000],\n",
      "        [10.7553,  2.0000],\n",
      "        [12.4150,  3.0000],\n",
      "        [11.4756,  0.0000],\n",
      "        [ 8.5110,  0.0000],\n",
      "        [ 9.0497,  2.0000],\n",
      "        [ 6.7067,  2.0000],\n",
      "        [ 8.8859,  3.0000],\n",
      "        [ 6.0988,  2.0000],\n",
      "        [ 8.0888,  3.0000],\n",
      "        [10.7939,  2.0000],\n",
      "        [ 9.5044,  3.0000],\n",
      "        [ 9.5075,  0.0000],\n",
      "        [16.2860,  2.0000],\n",
      "        [ 6.6355,  2.0000],\n",
      "        [ 7.4565,  0.0000],\n",
      "        [ 9.0333,  0.0000],\n",
      "        [12.6013,  0.0000],\n",
      "        [ 7.7547,  2.0000],\n",
      "        [17.4687,  0.0000],\n",
      "        [13.1270,  2.0000],\n",
      "        [ 8.5350,  2.0000],\n",
      "        [10.7642,  0.0000],\n",
      "        [10.7115,  2.0000],\n",
      "        [12.4481,  0.0000],\n",
      "        [ 7.9442,  2.0000],\n",
      "        [13.8518,  2.0000],\n",
      "        [14.4870,  0.0000],\n",
      "        [ 7.2428,  2.0000],\n",
      "        [13.1182,  2.0000],\n",
      "        [ 5.4446,  0.0000],\n",
      "        [ 9.8469,  2.0000],\n",
      "        [12.7820,  3.0000],\n",
      "        [ 7.0133,  2.0000],\n",
      "        [ 6.3809,  3.0000],\n",
      "        [ 7.0133,  2.0000],\n",
      "        [ 9.0640,  0.0000],\n",
      "        [16.3658,  2.0000],\n",
      "        [15.9657,  3.0000],\n",
      "        [ 7.4375,  2.0000],\n",
      "        [ 8.5350,  0.0000],\n",
      "        [ 9.8711,  3.0000],\n",
      "        [ 5.2475,  2.0000],\n",
      "        [13.8470,  2.0000],\n",
      "        [ 8.5570,  2.0000],\n",
      "        [ 9.3182,  0.0000],\n",
      "        [12.5378,  2.0000],\n",
      "        [ 6.6355,  2.0000],\n",
      "        [ 6.3864,  0.0000],\n",
      "        [11.3441,  1.0000],\n",
      "        [ 8.0805,  2.0000],\n",
      "        [ 6.5090,  0.0000],\n",
      "        [10.7718,  2.0000],\n",
      "        [ 6.5397,  0.0000],\n",
      "        [12.4229,  2.0000],\n",
      "        [ 9.4636,  2.0000],\n",
      "        [ 8.4481,  0.0000],\n",
      "        [ 7.1826,  2.0000],\n",
      "        [19.7826,  0.0000],\n",
      "        [13.0934,  2.0000],\n",
      "        [ 7.9409,  0.0000],\n",
      "        [ 8.8778,  0.0000],\n",
      "        [ 9.9038,  0.0000],\n",
      "        [ 8.5734,  2.0000],\n",
      "        [10.5617,  3.0000],\n",
      "        [ 8.5327,  2.0000],\n",
      "        [ 8.2667,  3.0000],\n",
      "        [ 6.2600,  2.0000],\n",
      "        [ 7.1939,  2.0000],\n",
      "        [ 7.5171,  0.0000],\n",
      "        [10.2275,  2.0000],\n",
      "        [ 7.6951,  0.0000],\n",
      "        [ 7.3139,  0.0000],\n",
      "        [ 9.4721,  3.0000],\n",
      "        [16.8614,  3.0000],\n",
      "        [11.0873,  0.0000]])\n",
      "age tensor(9.4363)\n",
      "sex tensor(2.)\n",
      "No NaN found in age column\n",
      "No NaN found in sex column\n",
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 7: tensor([[ 7.9764,  1.0000],\n",
      "        [10.7939,  2.0000],\n",
      "        [ 8.4995,  2.0000],\n",
      "        [ 6.1421,  3.0000],\n",
      "        [10.0086,  0.0000],\n",
      "        [ 9.9346,  0.0000],\n",
      "        [12.6063,  0.0000],\n",
      "        [ 6.0799,  3.0000],\n",
      "        [13.7068,  3.0000],\n",
      "        [ 6.0326,  0.0000],\n",
      "        [ 9.2639,  0.0000],\n",
      "        [10.5617,  3.0000],\n",
      "        [10.4953,  3.0000],\n",
      "        [10.8217,  0.0000],\n",
      "        [15.1388,  0.0000],\n",
      "        [ 5.0552,  0.0000],\n",
      "        [13.8470,  0.0000],\n",
      "        [13.0585,  0.0000],\n",
      "        [12.5793,  0.0000],\n",
      "        [ 8.6806,  0.0000],\n",
      "        [11.1749,  2.0000],\n",
      "        [15.3987,  1.0000],\n",
      "        [ 9.1022,  3.0000],\n",
      "        [ 5.3625,  2.0000],\n",
      "        [ 5.7841,  0.0000],\n",
      "        [14.1072,  2.0000],\n",
      "        [14.1154,  0.0000],\n",
      "        [11.3413,  0.0000],\n",
      "        [ 9.0086,  0.0000],\n",
      "        [12.8090,  3.0000],\n",
      "        [ 5.6219,  0.0000],\n",
      "        [17.4221,  0.0000],\n",
      "        [12.5762,  1.0000],\n",
      "        [14.4520,  3.0000],\n",
      "        [ 6.0874,  1.0000],\n",
      "        [10.0518,  0.0000],\n",
      "        [14.5424,  0.0000],\n",
      "        [10.1235,  3.0000],\n",
      "        [11.0845,  0.0000],\n",
      "        [17.9893,  2.0000],\n",
      "        [ 6.2687,  0.0000],\n",
      "        [10.7718,  2.0000],\n",
      "        [11.2050,  0.0000],\n",
      "        [10.5583,  2.0000],\n",
      "        [16.0367,  2.0000],\n",
      "        [16.6725,  0.0000],\n",
      "        [11.8808,  0.0000],\n",
      "        [14.1509,  2.0000],\n",
      "        [13.0500,  1.0000],\n",
      "        [ 7.0868,  0.0000],\n",
      "        [11.8182,  2.0000],\n",
      "        [ 7.8040,  3.0000],\n",
      "        [19.2049,  2.0000],\n",
      "        [12.4147,  2.0000],\n",
      "        [ 6.1394,  2.0000],\n",
      "        [17.7073,  3.0000],\n",
      "        [15.0298,  2.0000],\n",
      "        [11.8128,  0.0000],\n",
      "        [ 7.0100,  0.0000],\n",
      "        [10.5780,  2.0000],\n",
      "        [ 8.4995,  2.0000],\n",
      "        [17.7074,  3.0000],\n",
      "        [ 9.7073,  2.0000],\n",
      "        [15.7301,  0.0000],\n",
      "        [10.1537,  3.0000],\n",
      "        [13.9423,  2.0000],\n",
      "        [ 8.8476,  0.0000],\n",
      "        [11.9710,  2.0000],\n",
      "        [ 5.6411,  3.0000],\n",
      "        [ 8.1599,  2.0000],\n",
      "        [ 7.7303,  1.0000],\n",
      "        [ 7.3139,  0.0000],\n",
      "        [12.1221,  0.0000],\n",
      "        [ 7.6207,  2.0000],\n",
      "        [20.9101,  3.0000],\n",
      "        [ 7.8319,  2.0000],\n",
      "        [13.4363,  0.0000],\n",
      "        [11.3413,  0.0000],\n",
      "        [ 5.6219,  0.0000],\n",
      "        [ 6.5829,  0.0000],\n",
      "        [ 8.8389,  0.0000],\n",
      "        [16.6719,  2.0000],\n",
      "        [ 9.9702,  0.0000],\n",
      "        [15.5467,  3.0000],\n",
      "        [ 9.9894,  0.0000],\n",
      "        [15.2242,  0.0000],\n",
      "        [10.2709,  0.0000],\n",
      "        [ 5.8465,  0.0000],\n",
      "        [10.9749,  2.0000],\n",
      "        [ 8.7047,  0.0000],\n",
      "        [ 9.1209,  2.0000],\n",
      "        [ 6.2105,  2.0000],\n",
      "        [14.8458,  0.0000],\n",
      "        [ 7.7109,  2.0000],\n",
      "        [ 8.2151,  1.0000],\n",
      "        [10.1235,  3.0000],\n",
      "        [10.2271,  2.0000],\n",
      "        [ 7.6951,  0.0000],\n",
      "        [ 6.4541,  1.0000],\n",
      "        [15.6157,  0.0000],\n",
      "        [ 6.3065,  0.0000],\n",
      "        [ 7.1004,  2.0000],\n",
      "        [ 7.9958,  0.0000],\n",
      "        [ 8.8312,  0.0000],\n",
      "        [ 6.2927,  2.0000],\n",
      "        [ 6.9662,  0.0000],\n",
      "        [ 7.3441,  2.0000],\n",
      "        [ 8.7869,  0.0000],\n",
      "        [ 7.2101,  1.0000],\n",
      "        [13.6581,  0.0000],\n",
      "        [ 9.7348,  0.0000],\n",
      "        [ 8.5350,  0.0000],\n",
      "        [13.9099,  1.0000],\n",
      "        [13.3022,  0.0000],\n",
      "        [ 6.7885,  0.0000],\n",
      "        [ 8.8033,  2.0000],\n",
      "        [ 5.6165,  2.0000],\n",
      "        [14.9613,  0.0000],\n",
      "        [17.7534,  0.0000],\n",
      "        [11.3747,  2.0000],\n",
      "        [ 6.2576,  2.0000],\n",
      "        [ 6.2570,  0.0000],\n",
      "        [16.1386,  2.0000],\n",
      "        [ 5.4446,  0.0000],\n",
      "        [ 9.6006,  0.0000],\n",
      "        [12.2311,  3.0000],\n",
      "        [10.7939,  2.0000],\n",
      "        [ 9.4002,  2.0000]])\n",
      "age tensor(7.9764)\n",
      "sex tensor(1.)\n",
      "NaN found in age column\n",
      "No NaN found in sex column\n",
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 8: tensor([[14.8458,  0.0000],\n",
      "        [ 6.2927,  2.0000],\n",
      "        [10.1783,  0.0000],\n",
      "        [ 5.1894,  2.0000],\n",
      "        [10.1887,  2.0000],\n",
      "        [ 9.8223,  2.0000],\n",
      "        [12.8663,  0.0000],\n",
      "        [ 8.4009,  2.0000],\n",
      "        [ 9.7999,  2.0000],\n",
      "        [13.6740,  2.0000],\n",
      "        [11.8862,  0.0000],\n",
      "        [ 8.0888,  3.0000],\n",
      "        [17.6636,  0.0000],\n",
      "        [15.1553,  3.0000],\n",
      "        [ 6.5857,  2.0000],\n",
      "        [ 7.1059,  0.0000],\n",
      "        [ 8.5350,  2.0000],\n",
      "        [ 8.5986,  0.0000],\n",
      "        [ 8.2284,  3.0000],\n",
      "        [12.4150,  3.0000],\n",
      "        [ 5.1735,  2.0000],\n",
      "        [12.4999,  2.0000],\n",
      "        [ 8.7075,  2.0000],\n",
      "        [11.8236,  0.0000],\n",
      "        [ 8.7928,  0.0000],\n",
      "        [15.0900,  0.0000],\n",
      "        [16.1386,  2.0000],\n",
      "        [12.8993,  2.0000],\n",
      "        [ 7.1032,  2.0000],\n",
      "        [ 6.3065,  0.0000],\n",
      "        [13.1270,  2.0000],\n",
      "        [ 9.7183,  0.0000],\n",
      "        [ 6.0272,  0.0000],\n",
      "        [15.4212,  2.0000],\n",
      "        [ 7.9134,  1.0000],\n",
      "        [11.0210,  1.0000],\n",
      "        [18.3968,  3.0000],\n",
      "        [14.9908,  3.0000],\n",
      "        [ 5.6251,  2.0000],\n",
      "        [ 5.7369,  2.0000],\n",
      "        [12.4857,  0.0000],\n",
      "        [ 6.0874,  1.0000],\n",
      "        [20.9101,  3.0000],\n",
      "        [ 5.8389,  0.0000],\n",
      "        [ 7.4268,  0.0000],\n",
      "        [10.7882,  0.0000],\n",
      "        [10.1477,  2.0000],\n",
      "        [ 5.7731,  2.0000],\n",
      "        [13.6636,  2.0000],\n",
      "        [ 8.9052,  0.0000],\n",
      "        [10.0218,  0.0000],\n",
      "        [20.8418,  2.0000],\n",
      "        [13.8661,  0.0000],\n",
      "        [ 6.4541,  1.0000],\n",
      "        [10.9859,  2.0000],\n",
      "        [ 7.7498,  0.0000],\n",
      "        [10.7939,  2.0000],\n",
      "        [15.2242,  0.0000],\n",
      "        [ 9.3373,  0.0000],\n",
      "        [ 9.6417,  3.0000],\n",
      "        [ 9.6493,  3.0000],\n",
      "        [ 8.0888,  3.0000],\n",
      "        [13.1046,  2.0000],\n",
      "        [17.3022,  3.0000],\n",
      "        [13.1046,  2.0000],\n",
      "        [ 9.9867,  0.0000],\n",
      "        [ 6.5556,  3.0000],\n",
      "        [15.0185,  1.0000],\n",
      "        [11.9086,  0.0000],\n",
      "        [11.5905,  2.0000],\n",
      "        [ 6.0988,  2.0000],\n",
      "        [ 7.8565,  0.0000],\n",
      "        [17.6439,  2.0000],\n",
      "        [ 6.2193,  2.0000],\n",
      "        [19.2077,  2.0000],\n",
      "        [ 6.3939,  1.0000],\n",
      "        [ 8.0915,  3.0000],\n",
      "        [ 6.4439,  2.0000],\n",
      "        [ 6.2927,  2.0000],\n",
      "        [10.4713,  2.0000],\n",
      "        [ 7.7903,  2.0000],\n",
      "        [ 7.7470,  1.0000],\n",
      "        [10.4215,  0.0000],\n",
      "        [ 7.7389,  0.0000],\n",
      "        [11.3989,  2.0000],\n",
      "        [ 5.8328,  2.0000],\n",
      "        [11.7520,  2.0000],\n",
      "        [18.2029,  2.0000],\n",
      "        [10.7882,  0.0000],\n",
      "        [11.0979,  0.0000],\n",
      "        [10.4547,  2.0000],\n",
      "        [ 8.0702,  0.0000],\n",
      "        [10.1645,  2.0000],\n",
      "        [11.8182,  3.0000],\n",
      "        [14.4055,  2.0000],\n",
      "        [20.9982,  2.0000],\n",
      "        [ 9.0935,  0.0000],\n",
      "        [11.9608,  3.0000],\n",
      "        [13.1790,  0.0000],\n",
      "        [12.4481,  0.0000],\n",
      "        [12.0695,  0.0000],\n",
      "        [16.9212,  0.0000],\n",
      "        [12.4754,  2.0000],\n",
      "        [ 8.5602,  2.0000],\n",
      "        [ 8.0477,  0.0000],\n",
      "        [ 6.4597,  0.0000],\n",
      "        [ 6.9033,  1.0000],\n",
      "        [ 7.3141,  3.0000],\n",
      "        [ 5.7123,  2.0000],\n",
      "        [ 8.6254,  0.0000],\n",
      "        [11.7389,  2.0000],\n",
      "        [14.0441,  0.0000],\n",
      "        [ 9.0935,  0.0000],\n",
      "        [13.3127,  0.0000],\n",
      "        [ 8.8587,  0.0000],\n",
      "        [12.2837,  2.0000],\n",
      "        [ 9.0749,  0.0000],\n",
      "        [14.9908,  3.0000],\n",
      "        [ 8.4529,  2.0000],\n",
      "        [16.8614,  3.0000],\n",
      "        [18.3968,  3.0000],\n",
      "        [ 6.4981,  2.0000],\n",
      "        [11.6650,  2.0000],\n",
      "        [19.2077,  2.0000],\n",
      "        [ 9.2639,  0.0000],\n",
      "        [14.4870,  0.0000],\n",
      "        [17.3022,  3.0000],\n",
      "        [ 6.2215,  2.0000]])\n",
      "age tensor(14.8458)\n",
      "sex tensor(0.)\n",
      "No NaN found in age column\n",
      "No NaN found in sex column\n",
      "torch.Size([128, 1, 50])\n",
      "label shape torch.Size([128, 2])\n",
      "Sample 9: tensor([[15.4212,  2.0000],\n",
      "        [ 5.2966,  2.0000],\n",
      "        [ 9.4636,  2.0000],\n",
      "        [ 9.3373,  0.0000],\n",
      "        [14.2133,  0.0000],\n",
      "        [16.0284,  3.0000],\n",
      "        [ 7.4268,  0.0000],\n",
      "        [10.4383,  3.0000],\n",
      "        [ 9.0611,  2.0000],\n",
      "        [15.2682,  3.0000],\n",
      "        [14.4625,  0.0000],\n",
      "        [16.9212,  0.0000],\n",
      "        [11.3413,  0.0000],\n",
      "        [13.3708,  3.0000],\n",
      "        [17.1376,  2.0000],\n",
      "        [ 8.7047,  0.0000],\n",
      "        [14.6405,  0.0000],\n",
      "        [ 7.7935,  0.0000],\n",
      "        [17.1242,  2.0000],\n",
      "        [13.0585,  0.0000],\n",
      "        [ 7.8535,  2.0000],\n",
      "        [ 9.9400,  2.0000],\n",
      "        [ 6.6930,  0.0000],\n",
      "        [ 7.8535,  2.0000],\n",
      "        [21.2167,  2.0000],\n",
      "        [ 5.4691,  0.0000],\n",
      "        [16.4967,  0.0000],\n",
      "        [ 9.6656,  0.0000],\n",
      "        [ 7.1032,  2.0000],\n",
      "        [10.0025,  2.0000],\n",
      "        [21.4823,  2.0000],\n",
      "        [ 6.6930,  0.0000],\n",
      "        [ 7.2428,  2.0000],\n",
      "        [11.8752,  3.0000],\n",
      "        [ 8.4065,  3.0000],\n",
      "        [10.4789,  3.0000],\n",
      "        [12.4807,  3.0000],\n",
      "        [ 5.5787,  2.0000],\n",
      "        [17.7534,  0.0000],\n",
      "        [10.4383,  3.0000],\n",
      "        [ 9.5044,  3.0000],\n",
      "        [11.0927,  2.0000],\n",
      "        [11.1749,  2.0000],\n",
      "        [ 7.9164,  0.0000],\n",
      "        [16.4967,  0.0000],\n",
      "        [12.8663,  0.0000],\n",
      "        [ 8.8253,  2.0000],\n",
      "        [ 7.4125,  2.0000],\n",
      "        [14.9613,  0.0000],\n",
      "        [ 6.2215,  2.0000],\n",
      "        [12.4147,  2.0000],\n",
      "        [18.0222,  3.0000],\n",
      "        [ 9.1626,  0.0000],\n",
      "        [ 6.7885,  0.0000],\n",
      "        [11.5827,  0.0000],\n",
      "        [13.3022,  0.0000],\n",
      "        [ 7.0736,  2.0000],\n",
      "        [11.9438,  2.0000],\n",
      "        [15.0626,  3.0000],\n",
      "        [15.5467,  3.0000],\n",
      "        [17.3482,  0.0000],\n",
      "        [ 7.1772,  2.0000],\n",
      "        [ 9.6192,  2.0000],\n",
      "        [11.6891,  2.0000],\n",
      "        [13.9423,  2.0000],\n",
      "        [ 6.6513,  0.0000],\n",
      "        [12.5000,  0.0000],\n",
      "        [15.4131,  0.0000],\n",
      "        [14.4625,  0.0000],\n",
      "        [ 8.6119,  0.0000],\n",
      "        [15.1420,  0.0000],\n",
      "        [11.3386,  3.0000],\n",
      "        [ 7.6207,  2.0000],\n",
      "        [ 9.6192,  2.0000],\n",
      "        [ 7.6151,  3.0000],\n",
      "        [ 8.3353,  0.0000],\n",
      "        [ 9.4305,  0.0000],\n",
      "        [ 8.0805,  2.0000],\n",
      "        [ 5.6741,  2.0000],\n",
      "        [ 7.0868,  0.0000],\n",
      "        [ 8.0969,  3.0000],\n",
      "        [14.5287,  0.0000],\n",
      "        [11.2291,  2.0000],\n",
      "        [ 6.6191,  0.0000],\n",
      "        [ 5.2966,  2.0000],\n",
      "        [ 7.2186,  3.0000],\n",
      "        [12.0695,  0.0000],\n",
      "        [12.2481,  0.0000],\n",
      "        [10.5506,  0.0000],\n",
      "        [ 8.5327,  2.0000],\n",
      "        [ 7.6650,  3.0000],\n",
      "        [ 6.2193,  2.0000],\n",
      "        [ 6.3864,  0.0000],\n",
      "        [14.1674,  0.0000],\n",
      "        [15.0295,  0.0000],\n",
      "        [ 8.7819,  2.0000],\n",
      "        [ 9.8082,  3.0000],\n",
      "        [ 6.6272,  0.0000],\n",
      "        [ 8.9868,  0.0000],\n",
      "        [19.3499,  3.0000],\n",
      "        [12.5246,  0.0000],\n",
      "        [ 9.2003,  2.0000],\n",
      "        [17.6747,  0.0000],\n",
      "        [10.7361,  0.0000],\n",
      "        [ 7.8593,  2.0000],\n",
      "        [14.1887,  0.0000],\n",
      "        [12.0395,  3.0000],\n",
      "        [ 7.6452,  0.0000],\n",
      "        [12.0784,  2.0000],\n",
      "        [10.3776,  2.0000],\n",
      "        [ 9.0667,  3.0000],\n",
      "        [ 8.2036,  1.0000],\n",
      "        [14.5972,  1.0000],\n",
      "        [19.7826,  0.0000],\n",
      "        [11.9989,  0.0000],\n",
      "        [11.3906,  3.0000],\n",
      "        [11.2050,  0.0000],\n",
      "        [ 6.5145,  2.0000],\n",
      "        [ 6.5447,  0.0000],\n",
      "        [16.9401,  2.0000],\n",
      "        [ 9.2446,  2.0000],\n",
      "        [ 8.2036,  1.0000],\n",
      "        [10.5035,  0.0000],\n",
      "        [ 7.0214,  2.0000],\n",
      "        [15.1420,  0.0000],\n",
      "        [ 9.8223,  2.0000],\n",
      "        [ 7.1311,  0.0000],\n",
      "        [10.8841,  2.0000]])\n",
      "age tensor(15.4212)\n",
      "sex tensor(2.)\n",
      "No NaN found in age column\n",
      "No NaN found in sex column\n"
     ]
    }
   ],
   "source": [
    "for i, (x, labels) in enumerate(train_loader_raw):\n",
    "    if i >= 10:  # Only print first 10\n",
    "        break\n",
    "    print(x.shape)\n",
    "    print(\"label shape\", labels.shape)\n",
    "    print(f\"Sample {i}:\", labels)\n",
    "    print(\"age\", labels[0][0])\n",
    "    print(\"sex\", labels[0][1])\n",
    "    if torch.isnan(labels[:,0].float().unsqueeze(1).to(device, non_blocking=True)).any():\n",
    "        print(\"NaN found in age column\")\n",
    "    else:\n",
    "        print(\"No NaN found in age column\")\n",
    "    if torch.isnan(labels[:,1].long()).any():\n",
    "        print(\"NaN found in sex column\")\n",
    "    else:\n",
    "        print(\"No NaN found in sex column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_loader_raw.dataset)):\n",
    "    if torch.isnan(train_loader_raw.dataset[i][1][0]).any() or train_loader_raw.dataset[i][1][0] is None:\n",
    "        print(f\"NaN or None found at index {i}\")\n",
    "\n",
    "for i in range(len(train_loader_raw.dataset)):\n",
    "    if torch.isnan(train_loader_raw.dataset[i][1][1]).any() or train_loader_raw.dataset[i][1][1] is None:\n",
    "        print(f\"NaN or None found at index {i}\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not get sample batch to determine input shape.\n",
      "Using default/manual input shape: channels=1, sequence_length=50\n"
     ]
    }
   ],
   "source": [
    "if 'x_batch' in locals() and x_batch is not None:\n",
    "    input_channels = x_batch.shape[1]\n",
    "    sequence_length = x_batch.shape[2]\n",
    "    print(f\"Detected input shape: channels={input_channels}, sequence_length={sequence_length}\")\n",
    "else:\n",
    "    print(\"Warning: Could not get sample batch to determine input shape.\")\n",
    "    # Set defaults or exit if necessary\n",
    "    input_channels = 1 # Set manually if needed\n",
    "    sequence_length = 50 # Set manually if needed (MUST MATCH VAE DECODER OUTPUT)\n",
    "    print(f\"Using default/manual input shape: channels={input_channels}, sequence_length={sequence_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists of hyperparameters to test\n",
    "latent_dims = [32, 64]\n",
    "dropout_values = [0.0]  # VAE dropout\n",
    "\n",
    "# New separate dropout values for predictors\n",
    "age_dropout_values = [0.0]\n",
    "site_dropout_values = [0.0, 0.3]\n",
    "\n",
    "# Define lists of weight values to test\n",
    "w_recon_values = [1.0]\n",
    "w_kl_values = [1.0, 0.1]\n",
    "w_age_values = [3.0, 5.0]  # Higher weights to prioritize age prediction\n",
    "w_site_values = [2.0, 3.0]  # Higher weights for stronger adversarial effect\n",
    "\n",
    "# --- Storage for results ---\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# --- Create results directory ---\n",
    "save_directory = \"experiment_results\"\n",
    "import os\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "print(f\"Results will be saved in: {save_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with latent_dim=2, vae_dropout=0.0, pred_dropout=0.0\n",
      "Starting combined training on mps... Monitoring  val_age_mae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samchou/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils/utils.py:598: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n",
      "/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils/utils.py:698: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 | Batch 448/448 | Train Loss: 3.9579"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils/utils.py:791: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: New best model found! val_age_mae: 2.4665. State stored.\n",
      "\n",
      "Epoch 1 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0000\n",
      "  Loss (Train/Val): 4.1578 / 3.4698\n",
      "  Recon Loss (Train/Val): 0.0643 / 0.0163\n",
      "  KL Loss (Train/Val): 6.323521 / 7.916004\n",
      "  Age MAE (Train/Val): 2.9748 / 2.4665\n",
      "  Site Acc (Train/Val): 45.32% / 52.76%\n",
      "------------------------------------------------------------\n",
      "Epoch 2/500 | Batch 448/448 | Train Loss: 3.2685\n",
      "Epoch 2 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0100\n",
      "  Loss (Train/Val): 3.9742 / 3.6171\n",
      "  Recon Loss (Train/Val): 0.0201 / 0.0164\n",
      "  KL Loss (Train/Val): 9.670978 / 11.671460\n",
      "  Age MAE (Train/Val): 2.8428 / 2.5381\n",
      "  Site Acc (Train/Val): 45.88% / 44.95%\n",
      "------------------------------------------------------------\n",
      "Epoch 3/500 | Batch 448/448 | Train Loss: 3.5771\n",
      "Epoch 3 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0200\n",
      "  Loss (Train/Val): 3.9596 / 3.7921\n",
      "  Recon Loss (Train/Val): 0.0180 / 0.0177\n",
      "  KL Loss (Train/Val): 10.444498 / 9.538917\n",
      "  Age MAE (Train/Val): 2.8324 / 2.7466\n",
      "  Site Acc (Train/Val): 45.35% / 47.59%\n",
      "------------------------------------------------------------\n",
      "Epoch 4/500 | Batch 448/448 | Train Loss: 4.0150\n",
      "Epoch 4: New best model found! val_age_mae: 2.4451. State stored.\n",
      "\n",
      "Epoch 4 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0300\n",
      "  Loss (Train/Val): 3.9445 / 3.4970\n",
      "  Recon Loss (Train/Val): 0.0144 / 0.0109\n",
      "  KL Loss (Train/Val): 10.060961 / 11.187494\n",
      "  Age MAE (Train/Val): 2.8223 / 2.4451\n",
      "  Site Acc (Train/Val): 45.52% / 49.28%\n",
      "------------------------------------------------------------\n",
      "Epoch 5/500 | Batch 448/448 | Train Loss: 3.1069\n",
      "Epoch 5 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0400\n",
      "  Loss (Train/Val): 3.9353 / 3.4924\n",
      "  Recon Loss (Train/Val): 0.0138 / 0.0123\n",
      "  KL Loss (Train/Val): 12.152547 / 11.344324\n",
      "  Age MAE (Train/Val): 2.8147 / 2.4546\n",
      "  Site Acc (Train/Val): 45.59% / 49.17%\n",
      "------------------------------------------------------------\n",
      "Epoch 6/500 | Batch 448/448 | Train Loss: 3.0350\n",
      "Epoch 6: New best model found! val_age_mae: 2.4277. State stored.\n",
      "\n",
      "Epoch 6 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0500\n",
      "  Loss (Train/Val): 3.9218 / 3.4547\n",
      "  Recon Loss (Train/Val): 0.0124 / 0.0120\n",
      "  KL Loss (Train/Val): 11.045758 / 10.381998\n",
      "  Age MAE (Train/Val): 2.8057 / 2.4277\n",
      "  Site Acc (Train/Val): 45.71% / 49.64%\n",
      "------------------------------------------------------------\n",
      "Epoch 7/500 | Batch 448/448 | Train Loss: 3.2560\n",
      "Epoch 7 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0600\n",
      "  Loss (Train/Val): 3.9209 / 3.7029\n",
      "  Recon Loss (Train/Val): 0.0119 / 0.0117\n",
      "  KL Loss (Train/Val): 11.995826 / 13.279319\n",
      "  Age MAE (Train/Val): 2.8036 / 2.6804\n",
      "  Site Acc (Train/Val): 45.51% / 49.68%\n",
      "------------------------------------------------------------\n",
      "Epoch 8/500 | Batch 448/448 | Train Loss: 3.1150\n",
      "Epoch 8 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0700\n",
      "  Loss (Train/Val): 3.9153 / 3.5851\n",
      "  Recon Loss (Train/Val): 0.0114 / 0.0112\n",
      "  KL Loss (Train/Val): 13.252288 / 13.965874\n",
      "  Age MAE (Train/Val): 2.7983 / 2.5109\n",
      "  Site Acc (Train/Val): 45.46% / 45.79%\n",
      "------------------------------------------------------------\n",
      "Epoch 9/500 | Batch 448/448 | Train Loss: 3.6614\n",
      "Epoch 9 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0800\n",
      "  Loss (Train/Val): 3.9192 / 3.4781\n",
      "  Recon Loss (Train/Val): 0.0115 / 0.0106\n",
      "  KL Loss (Train/Val): 12.099061 / 10.855524\n",
      "  Age MAE (Train/Val): 2.7983 / 2.4373\n",
      "  Site Acc (Train/Val): 44.98% / 47.71%\n",
      "------------------------------------------------------------\n",
      "Epoch 10/500 | Batch 448/448 | Train Loss: 4.2659\n",
      "Epoch 10 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0900\n",
      "  Loss (Train/Val): 3.9216 / 3.6331\n",
      "  Recon Loss (Train/Val): 0.0113 / 0.0130\n",
      "  KL Loss (Train/Val): 11.519609 / 12.139090\n",
      "  Age MAE (Train/Val): 2.8002 / 2.5485\n",
      "  Site Acc (Train/Val): 45.02% / 46.40%\n",
      "------------------------------------------------------------\n",
      "Epoch 11/500 | Batch 448/448 | Train Loss: 2.5482\n",
      "Epoch 11: New best model found! val_age_mae: 2.4242. State stored.\n",
      "\n",
      "Epoch 11 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1000\n",
      "  Loss (Train/Val): 3.9203 / 3.4462\n",
      "  Recon Loss (Train/Val): 0.0119 / 0.0105\n",
      "  KL Loss (Train/Val): 11.683353 / 11.546429\n",
      "  Age MAE (Train/Val): 2.7991 / 2.4242\n",
      "  Site Acc (Train/Val): 44.84% / 49.54%\n",
      "------------------------------------------------------------\n",
      "Epoch 12/500 | Batch 448/448 | Train Loss: 3.1932\n",
      "Epoch 12 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1100\n",
      "  Loss (Train/Val): 3.9234 / 4.1877\n",
      "  Recon Loss (Train/Val): 0.0118 / 0.0118\n",
      "  KL Loss (Train/Val): 11.347169 / 12.254239\n",
      "  Age MAE (Train/Val): 2.8033 / 3.1355\n",
      "  Site Acc (Train/Val): 44.97% / 46.43%\n",
      "------------------------------------------------------------\n",
      "Epoch 13/500 | Batch 448/448 | Train Loss: 3.8013\n",
      "Epoch 13 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1200\n",
      "  Loss (Train/Val): 3.9214 / 3.4730\n",
      "  Recon Loss (Train/Val): 0.0112 / 0.0105\n",
      "  KL Loss (Train/Val): 11.952690 / 11.992870\n",
      "  Age MAE (Train/Val): 2.7990 / 2.4386\n",
      "  Site Acc (Train/Val): 44.86% / 49.76%\n",
      "------------------------------------------------------------\n",
      "Epoch 14/500 | Batch 448/448 | Train Loss: 2.8979\n",
      "Epoch 14 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1300\n",
      "  Loss (Train/Val): 3.9141 / 3.4663\n",
      "  Recon Loss (Train/Val): 0.0108 / 0.0103\n",
      "  KL Loss (Train/Val): 12.536661 / 11.361830\n",
      "  Age MAE (Train/Val): 2.7951 / 2.4293\n",
      "  Site Acc (Train/Val): 45.25% / 49.32%\n",
      "------------------------------------------------------------\n",
      "Epoch 15/500 | Batch 448/448 | Train Loss: 3.3229\n",
      "Epoch 15 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1400\n",
      "  Loss (Train/Val): 3.9140 / 3.4703\n",
      "  Recon Loss (Train/Val): 0.0108 / 0.0103\n",
      "  KL Loss (Train/Val): 11.956034 / 12.110684\n",
      "  Age MAE (Train/Val): 2.7916 / 2.4333\n",
      "  Site Acc (Train/Val): 44.86% / 48.88%\n",
      "------------------------------------------------------------\n",
      "Epoch 16/500 | Batch 448/448 | Train Loss: 3.3522\n",
      "Epoch 16 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1500\n",
      "  Loss (Train/Val): 3.9187 / 3.4825\n",
      "  Recon Loss (Train/Val): 0.0119 / 0.0116\n",
      "  KL Loss (Train/Val): 10.083154 / 9.446931\n",
      "  Age MAE (Train/Val): 2.7961 / 2.4568\n",
      "  Site Acc (Train/Val): 45.13% / 49.18%\n",
      "------------------------------------------------------------\n",
      "Epoch 17/500 | Batch 448/448 | Train Loss: 4.0760\n",
      "Epoch 17 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1600\n",
      "  Loss (Train/Val): 3.9161 / 3.5022\n",
      "  Recon Loss (Train/Val): 0.0109 / 0.0115\n",
      "  KL Loss (Train/Val): 10.292995 / 11.342745\n",
      "  Age MAE (Train/Val): 2.7927 / 2.4432\n",
      "  Site Acc (Train/Val): 45.07% / 49.64%\n",
      "------------------------------------------------------------\n",
      "Epoch 18/500 | Batch 448/448 | Train Loss: 3.0702\n",
      "Epoch 18 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1700\n",
      "  Loss (Train/Val): 3.9158 / 3.4635\n",
      "  Recon Loss (Train/Val): 0.0111 / 0.0102\n",
      "  KL Loss (Train/Val): 11.374477 / 11.420450\n",
      "  Age MAE (Train/Val): 2.7906 / 2.4271\n",
      "  Site Acc (Train/Val): 44.79% / 49.37%\n",
      "------------------------------------------------------------\n",
      "Epoch 19/500 | Batch 448/448 | Train Loss: 3.8843\n",
      "Epoch 19 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1800\n",
      "  Loss (Train/Val): 3.9164 / 3.4954\n",
      "  Recon Loss (Train/Val): 0.0108 / 0.0103\n",
      "  KL Loss (Train/Val): 10.378661 / 11.144993\n",
      "  Age MAE (Train/Val): 2.7926 / 2.4402\n",
      "  Site Acc (Train/Val): 45.30% / 47.64%\n",
      "------------------------------------------------------------\n",
      "Epoch 20/500 | Batch 370/448 | Train Loss: 3.7194"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m combined_model \u001b[39m=\u001b[39m CombinedVAE_Predictors(vae, age_predictor, site_predictor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m combined_model \u001b[39m=\u001b[39m combined_model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m training_results \u001b[39m=\u001b[39m train_variational_autoencoder_age_site(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     combined_model\u001b[39m=\u001b[39;49mcombined_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     train_data\u001b[39m=\u001b[39;49mtrain_loader_raw,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     val_data\u001b[39m=\u001b[39;49mval_loader_raw,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     max_grad_norm\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     w_recon\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     w_kl\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     w_age\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     w_site\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     kl_annealing_start_epoch\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     kl_annealing_duration\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     kl_annealing_start\u001b[39m=\u001b[39;49m\u001b[39m0.0001\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     grl_alpha_start\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     grl_alpha_end\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     grl_alpha_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m models[latent_dim, dropout, pred_dropout] \u001b[39m=\u001b[39m combined_model\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m results[latent_dim, dropout, pred_dropout] \u001b[39m=\u001b[39m training_results\n",
      "File \u001b[0;32m~/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils/utils.py:732\u001b[0m, in \u001b[0;36mtrain_variational_autoencoder_age_site\u001b[0;34m(combined_model, train_data, val_data, epochs, lr, device, max_grad_norm, w_recon, w_kl, w_age, w_site, kl_annealing_start_epoch, kl_annealing_duration, kl_annealing_start, grl_alpha_start, grl_alpha_end, grl_alpha_epochs, save_prefix, val_metric_to_monitor)\u001b[0m\n\u001b[1;32m    730\u001b[0m scaler\u001b[39m.\u001b[39munscale_(opt)\n\u001b[1;32m    731\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(combined_model\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39mmax_grad_norm)\n\u001b[0;32m--> 732\u001b[0m scaler\u001b[39m.\u001b[39;49mstep(opt)\n\u001b[1;32m    733\u001b[0m scaler\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m    735\u001b[0m \u001b[39m# Accumulate sums (losses are mean per item, scale by batch size)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/amp/grad_scaler.py:380\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Invoke ``unscale_(optimizer)`` followed by parameter update, if gradients are not infs/NaN.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \n\u001b[1;32m    360\u001b[0m \u001b[39m:meth:`step` carries out the following two operations:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39m    Closure use is not currently supported.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enabled:\n\u001b[0;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mclosure\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    383\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    384\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClosure use is not currently supported if GradScaler is enabled.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m\"\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     92\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     adam(\n\u001b[1;32m    224\u001b[0m         params_with_grad,\n\u001b[1;32m    225\u001b[0m         grads,\n\u001b[1;32m    226\u001b[0m         exp_avgs,\n\u001b[1;32m    227\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    228\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    229\u001b[0m         state_steps,\n\u001b[1;32m    230\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    231\u001b[0m         has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[1;32m    232\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    233\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    234\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    235\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    236\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    237\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    238\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    239\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    240\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    242\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    243\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    246\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[39mreturn\u001b[39;00m disabled_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m func(\n\u001b[1;32m    785\u001b[0m     params,\n\u001b[1;32m    786\u001b[0m     grads,\n\u001b[1;32m    787\u001b[0m     exp_avgs,\n\u001b[1;32m    788\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    789\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    790\u001b[0m     state_steps,\n\u001b[1;32m    791\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    792\u001b[0m     has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[1;32m    793\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    794\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    795\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    796\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    797\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    798\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    799\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    800\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    801\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    802\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[1;32m    803\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/adam.py:430\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    428\u001b[0m         denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    429\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[1;32m    432\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n\u001b[1;32m    434\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Main Hyperparameter Loop ---\n",
    "for dropout in dropout_values:\n",
    "    for age_dropout in age_dropout_values:\n",
    "        for site_dropout in site_dropout_values:\n",
    "            for latent_dim in latent_dims:\n",
    "                for w_recon in w_recon_values:\n",
    "                    for w_kl in w_kl_values:\n",
    "                        for w_age in w_age_values:\n",
    "                            for w_site in w_site_values:\n",
    "                                print(\"-\" * 80)\n",
    "                                print(f\"STARTING RUN: LD={latent_dim}, DR_VAE={dropout}, DR_Age={age_dropout}, DR_Site={site_dropout}, wR={w_recon}, wKL={w_kl}, wA={w_age}, wS={w_site}\")\n",
    "                                print(\"-\" * 80)\n",
    "\n",
    "                                # --- Ensure input_channels and sequence_length are defined ---\n",
    "                                if 'sequence_length' not in locals() or 'input_channels' not in locals():\n",
    "                                    print(\"Error: sequence_length or input_channels not defined. Run previous cells.\")\n",
    "                                    break\n",
    "\n",
    "                                # --- Instantiate Models ---\n",
    "                                vae = Conv1DVariationalAutoencoder_fa(latent_dims=latent_dim, dropout=dropout)\n",
    "                                age_predictor = AgePredictorCNN(input_channels=input_channels, \n",
    "                                                              sequence_length=sequence_length, \n",
    "                                                              dropout=age_dropout)\n",
    "                                site_predictor = SitePredictorCNN(num_sites=num_sites, \n",
    "                                                                input_channels=input_channels, \n",
    "                                                                sequence_length=sequence_length, \n",
    "                                                                dropout=site_dropout)\n",
    "\n",
    "                                combined_model = CombinedVAE_Predictors(vae, age_predictor, site_predictor)\n",
    "                                combined_model = combined_model.to(device)\n",
    "\n",
    "                                # --- Define unique prefix for this run's files ---\n",
    "                                run_save_prefix = os.path.join(save_directory, \n",
    "                                    f\"combo_ld{latent_dim}_drV{dropout}_drA{age_dropout}_drS{site_dropout}_wr{w_recon}_wkl{w_kl}_wa{w_age}_ws{w_site}\")\n",
    "\n",
    "                                # --- Train Model ---\n",
    "                                try:\n",
    "                                    training_results = train_variational_autoencoder_age_site(\n",
    "                                        combined_model=combined_model,\n",
    "                                        train_data=train_loader_raw,\n",
    "                                        val_data=val_loader_raw,\n",
    "                                        epochs=500,\n",
    "                                        lr=0.001,\n",
    "                                        device=device,\n",
    "                                        max_grad_norm=1.0,\n",
    "                                        w_recon=w_recon,\n",
    "                                        w_kl=w_kl,\n",
    "                                        w_age=w_age,\n",
    "                                        w_site=w_site,\n",
    "                                        kl_annealing_start_epoch=200,\n",
    "                                        kl_annealing_duration=100,\n",
    "                                        kl_annealing_start=0.0001,\n",
    "                                        grl_alpha_start=0.5,  # Start with stronger reversal\n",
    "                                        grl_alpha_end=1.5,    # Increase max reversal strength\n",
    "                                        grl_alpha_epochs=50,  # Reach max alpha faster\n",
    "                                        save_prefix=run_save_prefix,\n",
    "                                        val_metric_to_monitor=\"val_age_mae\"\n",
    "                                    )\n",
    "                                except Exception as e:\n",
    "                                    print(f\"\\n !!! Training failed for run {run_save_prefix}: {e} !!!\\n\")\n",
    "                                    training_results = None\n",
    "\n",
    "                                # --- Store Results ---\n",
    "                                current_key = (latent_dim, dropout, age_dropout, site_dropout, w_recon, w_kl, w_age, w_site)\n",
    "                                results[current_key] = training_results\n",
    "\n",
    "                                # --- Process and Save Results if training finished ---\n",
    "                                if training_results and training_results.get(\"model_path\"):\n",
    "                                    # Convert metrics to CPU floats\n",
    "                                    keys_to_convert = [\n",
    "                                        \"train_loss_epoch\", \"val_loss_epoch\", \"train_recon_loss_epoch\", \"val_recon_loss_epoch\",\n",
    "                                        \"train_kl_loss_epoch\", \"val_kl_loss_epoch\", \"train_age_loss_epoch\", \"val_age_loss_epoch\",\n",
    "                                        \"train_site_loss_epoch\", \"val_site_loss_epoch\", \"train_age_mae_epoch\", \"val_age_mae_epoch\",\n",
    "                                        \"train_site_acc_epoch\", \"val_site_acc_epoch\", \"current_beta_epoch\",\n",
    "                                        \"current_grl_alpha_epoch\", \"current_lr_epoch\"\n",
    "                                    ]\n",
    "                                    processed_results = {}\n",
    "                                    for key in keys_to_convert:\n",
    "                                        metric_list = training_results.get(key, [])\n",
    "                                        new_list = []\n",
    "                                        if isinstance(metric_list, (list, tuple)):\n",
    "                                            for val in metric_list:\n",
    "                                                if isinstance(val, torch.Tensor):\n",
    "                                                    new_list.append(float(val.cpu().item()))\n",
    "                                                elif isinstance(val, (int, float, np.number)):\n",
    "                                                    new_list.append(float(val))\n",
    "                                                else:\n",
    "                                                    new_list.append(float('nan'))\n",
    "                                        processed_results[key] = new_list\n",
    "\n",
    "                                    # Convert best metrics\n",
    "                                    best_mae_key = \"best_val_age_mae\"\n",
    "                                    best_mae_val = training_results.get(best_mae_key)\n",
    "                                    if isinstance(best_mae_val, torch.Tensor):\n",
    "                                        best_mae = float(best_mae_val.cpu().item())\n",
    "                                    elif isinstance(best_mae_val, (int, float, np.number)):\n",
    "                                        best_mae = float(best_mae_val)\n",
    "                                    else: \n",
    "                                        best_mae = float('nan')\n",
    "\n",
    "                                    # Create DataFrame\n",
    "                                    num_epochs = len(processed_results.get(\"train_loss_epoch\", []))\n",
    "                                    if num_epochs > 0:\n",
    "                                        df_data = {\"epoch\": range(1, num_epochs + 1)}\n",
    "                                        for k in keys_to_convert:\n",
    "                                            col_name = k.replace('_epoch', '')\n",
    "                                            metric_data = processed_results.get(k, [])\n",
    "                                            if len(metric_data) != num_epochs:\n",
    "                                                metric_data = [float('nan')] * num_epochs\n",
    "                                            df_data[col_name] = metric_data\n",
    "\n",
    "                                        df_epochs = pd.DataFrame(df_data)\n",
    "                                        df_epochs.to_csv(f\"{run_save_prefix}_metrics.csv\", index=False)\n",
    "\n",
    "                                        # Save summary metrics CSV\n",
    "                                        df_summary = pd.DataFrame([{\n",
    "                                            best_mae_key: best_mae,\n",
    "                                            \"best_epoch\": training_results.get(\"best_epoch\", float('nan')),\n",
    "                                            \"model_path\": training_results.get(\"model_path\", \"N/A\")\n",
    "                                        }])\n",
    "                                        df_summary.to_csv(f\"{run_save_prefix}_summary.csv\", index=False)\n",
    "\n",
    "                                        print(f\"Finished & Saved Run: {current_key}. Best Val MAE: {best_mae:.4f}\")\n",
    "                                    else:\n",
    "                                        print(f\"Skipping results saving for run {current_key} - No epoch data found.\")\n",
    "                                else:\n",
    "                                    print(f\"Skipping results processing for run {current_key} - Training did not complete or model not saved.\")\n",
    "\n",
    "# Indicate loop completion\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Hyperparameter search loop finished.\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
