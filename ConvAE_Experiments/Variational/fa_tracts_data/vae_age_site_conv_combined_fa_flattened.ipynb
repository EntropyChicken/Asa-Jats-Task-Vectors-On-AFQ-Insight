{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "from afqinsight import AFQDataset\n",
    "from afqinsight.nn.utils import prep_pytorch_data\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.normal import Normal\n",
    "from sklearn.decomposition import PCA\n",
    "import afqinsight.augmentation as aug\n",
    "from afqinsight.nn.pt_models import Conv1DAutoencoder\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Adjust path as needed\n",
    "sys.path.insert(1, '/mmfs1/gscratch/nrdg/samchou/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils')\n",
    "# sys.path.insert(1, '/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils')\n",
    "# Import necessary functions, including the new one\n",
    "from utils import select_device, train_variational_autoencoder_age_site, kl_divergence_loss,prep_fa_flattned_data, GradReverse, prep_fa_flattened_remapped_data\n",
    "from models import Conv1DVariationalAutoencoder_fa, AgePredictorCNN, SitePredictorCNN, CombinedVAE_Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "Using MPS backend on macOS. (Detailed memory info may not be available.)\n"
     ]
    }
   ],
   "source": [
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/samchou/.cache/afq-insight/hbn/subjects.tsv exists.\n",
      "File /Users/samchou/.cache/afq-insight/hbn/nodes.csv exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samchou/src/nrdg/AFQ-Insight/afqinsight/transform.py:144: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  features = interpolated.stack([\"subjectID\", \"tractID\", \"metric\"]).unstack(\n"
     ]
    }
   ],
   "source": [
    "dataset = AFQDataset.from_study('hbn')\n",
    "torch_dataset, train_loader, test_loader, val_loader = prep_pytorch_data(dataset,batch_size=128)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_idx = dataset.target_cols.index('scan_site_id')\n",
    "age_idx = dataset.target_cols.index('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset, all_tracts_train_loader, all_tracts_test_loader, all_tracts_val_loader = prep_fa_flattned_data(dataset, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing initial PyTorch data loaders...\n",
      "Remapping prep: Using age index 0, site index 2 from ['age', 'sex', 'scan_site_id']\n",
      "Using site map: {0.0: 0.0, 1.0: 1.0, 3.0: 2.0, 4.0: 3.0}\n",
      "Creating remapped datasets...\n",
      "Creating final DataLoaders...\n",
      "prep_fa_flattened_remapped_data complete.\n",
      "Initial data loaders prepared.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing initial PyTorch data loaders...\")\n",
    "try:\n",
    "    # Assuming prep_pytorch_data returns torch_dataset, train_loader, test_loader, val_loader\n",
    "    # If it returns datasets, create loaders here.\n",
    "    # Adapt this call based on the actual signature and return values of your prep_pytorch_data\n",
    "    prep_output = prep_fa_flattened_remapped_data(dataset, batch_size=128)\n",
    "    if len(prep_output) == 4:\n",
    "        _, train_loader_raw, test_loader_raw, val_loader_raw = prep_output\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 4 return values from prep_pytorch_data, got {len(prep_output)}\")\n",
    "\n",
    "    print(\"Initial data loaders prepared.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error calling prep_pytorch_data: {e}\")\n",
    "     print(\"Ensure the function exists and returns DataLoaders or required components.\")\n",
    "     sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not get sample batch to determine input shape.\n",
      "Using default/manual input shape: channels=1, sequence_length=50\n"
     ]
    }
   ],
   "source": [
    "if 'x_batch' in locals() and x_batch is not None:\n",
    "    input_channels = x_batch.shape[1]\n",
    "    sequence_length = x_batch.shape[2]\n",
    "    print(f\"Detected input shape: channels={input_channels}, sequence_length={sequence_length}\")\n",
    "else:\n",
    "    print(\"Warning: Could not get sample batch to determine input shape.\")\n",
    "    # Set defaults or exit if necessary\n",
    "    input_channels = 1 # Set manually if needed\n",
    "    sequence_length = 50 # Set manually if needed (MUST MATCH VAE DECODER OUTPUT)\n",
    "    print(f\"Using default/manual input shape: channels={input_channels}, sequence_length={sequence_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists of hyperparameters to test\n",
    "latent_dims = [32, 64]\n",
    "dropout_values = [0.0]  # VAE dropout\n",
    "\n",
    "# New separate dropout values for predictors\n",
    "age_dropout_values = [0.0]\n",
    "site_dropout_values = [0.0, 0.3]\n",
    "\n",
    "# Define lists of weight values to test\n",
    "w_recon_values = [1.0]\n",
    "w_kl_values = [1.0, 0.1]\n",
    "w_age_values = [3.0, 5.0]  # Higher weights to prioritize age prediction\n",
    "w_site_values = [2.0, 3.0]  # Higher weights for stronger adversarial effect\n",
    "\n",
    "# --- Storage for results ---\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# --- Create results directory ---\n",
    "save_directory = \"experiment_results\"\n",
    "import os\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "print(f\"Results will be saved in: {save_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with latent_dim=2, vae_dropout=0.0, pred_dropout=0.0\n",
      "Starting combined training on mps... Monitoring  val_age_mae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samchou/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils/utils.py:598: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n",
      "/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils/utils.py:698: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 | Batch 448/448 | Train Loss: 3.9579"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils/utils.py:791: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: New best model found! val_age_mae: 2.4665. State stored.\n",
      "\n",
      "Epoch 1 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0000\n",
      "  Loss (Train/Val): 4.1578 / 3.4698\n",
      "  Recon Loss (Train/Val): 0.0643 / 0.0163\n",
      "  KL Loss (Train/Val): 6.323521 / 7.916004\n",
      "  Age MAE (Train/Val): 2.9748 / 2.4665\n",
      "  Site Acc (Train/Val): 45.32% / 52.76%\n",
      "------------------------------------------------------------\n",
      "Epoch 2/500 | Batch 448/448 | Train Loss: 3.2685\n",
      "Epoch 2 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0100\n",
      "  Loss (Train/Val): 3.9742 / 3.6171\n",
      "  Recon Loss (Train/Val): 0.0201 / 0.0164\n",
      "  KL Loss (Train/Val): 9.670978 / 11.671460\n",
      "  Age MAE (Train/Val): 2.8428 / 2.5381\n",
      "  Site Acc (Train/Val): 45.88% / 44.95%\n",
      "------------------------------------------------------------\n",
      "Epoch 3/500 | Batch 448/448 | Train Loss: 3.5771\n",
      "Epoch 3 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0200\n",
      "  Loss (Train/Val): 3.9596 / 3.7921\n",
      "  Recon Loss (Train/Val): 0.0180 / 0.0177\n",
      "  KL Loss (Train/Val): 10.444498 / 9.538917\n",
      "  Age MAE (Train/Val): 2.8324 / 2.7466\n",
      "  Site Acc (Train/Val): 45.35% / 47.59%\n",
      "------------------------------------------------------------\n",
      "Epoch 4/500 | Batch 448/448 | Train Loss: 4.0150\n",
      "Epoch 4: New best model found! val_age_mae: 2.4451. State stored.\n",
      "\n",
      "Epoch 4 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0300\n",
      "  Loss (Train/Val): 3.9445 / 3.4970\n",
      "  Recon Loss (Train/Val): 0.0144 / 0.0109\n",
      "  KL Loss (Train/Val): 10.060961 / 11.187494\n",
      "  Age MAE (Train/Val): 2.8223 / 2.4451\n",
      "  Site Acc (Train/Val): 45.52% / 49.28%\n",
      "------------------------------------------------------------\n",
      "Epoch 5/500 | Batch 448/448 | Train Loss: 3.1069\n",
      "Epoch 5 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0400\n",
      "  Loss (Train/Val): 3.9353 / 3.4924\n",
      "  Recon Loss (Train/Val): 0.0138 / 0.0123\n",
      "  KL Loss (Train/Val): 12.152547 / 11.344324\n",
      "  Age MAE (Train/Val): 2.8147 / 2.4546\n",
      "  Site Acc (Train/Val): 45.59% / 49.17%\n",
      "------------------------------------------------------------\n",
      "Epoch 6/500 | Batch 448/448 | Train Loss: 3.0350\n",
      "Epoch 6: New best model found! val_age_mae: 2.4277. State stored.\n",
      "\n",
      "Epoch 6 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0500\n",
      "  Loss (Train/Val): 3.9218 / 3.4547\n",
      "  Recon Loss (Train/Val): 0.0124 / 0.0120\n",
      "  KL Loss (Train/Val): 11.045758 / 10.381998\n",
      "  Age MAE (Train/Val): 2.8057 / 2.4277\n",
      "  Site Acc (Train/Val): 45.71% / 49.64%\n",
      "------------------------------------------------------------\n",
      "Epoch 7/500 | Batch 448/448 | Train Loss: 3.2560\n",
      "Epoch 7 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0600\n",
      "  Loss (Train/Val): 3.9209 / 3.7029\n",
      "  Recon Loss (Train/Val): 0.0119 / 0.0117\n",
      "  KL Loss (Train/Val): 11.995826 / 13.279319\n",
      "  Age MAE (Train/Val): 2.8036 / 2.6804\n",
      "  Site Acc (Train/Val): 45.51% / 49.68%\n",
      "------------------------------------------------------------\n",
      "Epoch 8/500 | Batch 448/448 | Train Loss: 3.1150\n",
      "Epoch 8 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0700\n",
      "  Loss (Train/Val): 3.9153 / 3.5851\n",
      "  Recon Loss (Train/Val): 0.0114 / 0.0112\n",
      "  KL Loss (Train/Val): 13.252288 / 13.965874\n",
      "  Age MAE (Train/Val): 2.7983 / 2.5109\n",
      "  Site Acc (Train/Val): 45.46% / 45.79%\n",
      "------------------------------------------------------------\n",
      "Epoch 9/500 | Batch 448/448 | Train Loss: 3.6614\n",
      "Epoch 9 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0800\n",
      "  Loss (Train/Val): 3.9192 / 3.4781\n",
      "  Recon Loss (Train/Val): 0.0115 / 0.0106\n",
      "  KL Loss (Train/Val): 12.099061 / 10.855524\n",
      "  Age MAE (Train/Val): 2.7983 / 2.4373\n",
      "  Site Acc (Train/Val): 44.98% / 47.71%\n",
      "------------------------------------------------------------\n",
      "Epoch 10/500 | Batch 448/448 | Train Loss: 4.2659\n",
      "Epoch 10 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.0900\n",
      "  Loss (Train/Val): 3.9216 / 3.6331\n",
      "  Recon Loss (Train/Val): 0.0113 / 0.0130\n",
      "  KL Loss (Train/Val): 11.519609 / 12.139090\n",
      "  Age MAE (Train/Val): 2.8002 / 2.5485\n",
      "  Site Acc (Train/Val): 45.02% / 46.40%\n",
      "------------------------------------------------------------\n",
      "Epoch 11/500 | Batch 448/448 | Train Loss: 2.5482\n",
      "Epoch 11: New best model found! val_age_mae: 2.4242. State stored.\n",
      "\n",
      "Epoch 11 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1000\n",
      "  Loss (Train/Val): 3.9203 / 3.4462\n",
      "  Recon Loss (Train/Val): 0.0119 / 0.0105\n",
      "  KL Loss (Train/Val): 11.683353 / 11.546429\n",
      "  Age MAE (Train/Val): 2.7991 / 2.4242\n",
      "  Site Acc (Train/Val): 44.84% / 49.54%\n",
      "------------------------------------------------------------\n",
      "Epoch 12/500 | Batch 448/448 | Train Loss: 3.1932\n",
      "Epoch 12 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1100\n",
      "  Loss (Train/Val): 3.9234 / 4.1877\n",
      "  Recon Loss (Train/Val): 0.0118 / 0.0118\n",
      "  KL Loss (Train/Val): 11.347169 / 12.254239\n",
      "  Age MAE (Train/Val): 2.8033 / 3.1355\n",
      "  Site Acc (Train/Val): 44.97% / 46.43%\n",
      "------------------------------------------------------------\n",
      "Epoch 13/500 | Batch 448/448 | Train Loss: 3.8013\n",
      "Epoch 13 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1200\n",
      "  Loss (Train/Val): 3.9214 / 3.4730\n",
      "  Recon Loss (Train/Val): 0.0112 / 0.0105\n",
      "  KL Loss (Train/Val): 11.952690 / 11.992870\n",
      "  Age MAE (Train/Val): 2.7990 / 2.4386\n",
      "  Site Acc (Train/Val): 44.86% / 49.76%\n",
      "------------------------------------------------------------\n",
      "Epoch 14/500 | Batch 448/448 | Train Loss: 2.8979\n",
      "Epoch 14 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1300\n",
      "  Loss (Train/Val): 3.9141 / 3.4663\n",
      "  Recon Loss (Train/Val): 0.0108 / 0.0103\n",
      "  KL Loss (Train/Val): 12.536661 / 11.361830\n",
      "  Age MAE (Train/Val): 2.7951 / 2.4293\n",
      "  Site Acc (Train/Val): 45.25% / 49.32%\n",
      "------------------------------------------------------------\n",
      "Epoch 15/500 | Batch 448/448 | Train Loss: 3.3229\n",
      "Epoch 15 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1400\n",
      "  Loss (Train/Val): 3.9140 / 3.4703\n",
      "  Recon Loss (Train/Val): 0.0108 / 0.0103\n",
      "  KL Loss (Train/Val): 11.956034 / 12.110684\n",
      "  Age MAE (Train/Val): 2.7916 / 2.4333\n",
      "  Site Acc (Train/Val): 44.86% / 48.88%\n",
      "------------------------------------------------------------\n",
      "Epoch 16/500 | Batch 448/448 | Train Loss: 3.3522\n",
      "Epoch 16 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1500\n",
      "  Loss (Train/Val): 3.9187 / 3.4825\n",
      "  Recon Loss (Train/Val): 0.0119 / 0.0116\n",
      "  KL Loss (Train/Val): 10.083154 / 9.446931\n",
      "  Age MAE (Train/Val): 2.7961 / 2.4568\n",
      "  Site Acc (Train/Val): 45.13% / 49.18%\n",
      "------------------------------------------------------------\n",
      "Epoch 17/500 | Batch 448/448 | Train Loss: 4.0760\n",
      "Epoch 17 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1600\n",
      "  Loss (Train/Val): 3.9161 / 3.5022\n",
      "  Recon Loss (Train/Val): 0.0109 / 0.0115\n",
      "  KL Loss (Train/Val): 10.292995 / 11.342745\n",
      "  Age MAE (Train/Val): 2.7927 / 2.4432\n",
      "  Site Acc (Train/Val): 45.07% / 49.64%\n",
      "------------------------------------------------------------\n",
      "Epoch 18/500 | Batch 448/448 | Train Loss: 3.0702\n",
      "Epoch 18 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1700\n",
      "  Loss (Train/Val): 3.9158 / 3.4635\n",
      "  Recon Loss (Train/Val): 0.0111 / 0.0102\n",
      "  KL Loss (Train/Val): 11.374477 / 11.420450\n",
      "  Age MAE (Train/Val): 2.7906 / 2.4271\n",
      "  Site Acc (Train/Val): 44.79% / 49.37%\n",
      "------------------------------------------------------------\n",
      "Epoch 19/500 | Batch 448/448 | Train Loss: 3.8843\n",
      "Epoch 19 Summary:\n",
      "  LR: 1.0e-03 | Beta: 0.0000 | GRL Alpha: 0.1800\n",
      "  Loss (Train/Val): 3.9164 / 3.4954\n",
      "  Recon Loss (Train/Val): 0.0108 / 0.0103\n",
      "  KL Loss (Train/Val): 10.378661 / 11.144993\n",
      "  Age MAE (Train/Val): 2.7926 / 2.4402\n",
      "  Site Acc (Train/Val): 45.30% / 47.64%\n",
      "------------------------------------------------------------\n",
      "Epoch 20/500 | Batch 370/448 | Train Loss: 3.7194"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m combined_model \u001b[39m=\u001b[39m CombinedVAE_Predictors(vae, age_predictor, site_predictor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m combined_model \u001b[39m=\u001b[39m combined_model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m training_results \u001b[39m=\u001b[39m train_variational_autoencoder_age_site(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     combined_model\u001b[39m=\u001b[39;49mcombined_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     train_data\u001b[39m=\u001b[39;49mtrain_loader_raw,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     val_data\u001b[39m=\u001b[39;49mval_loader_raw,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     max_grad_norm\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     w_recon\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     w_kl\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     w_age\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     w_site\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     kl_annealing_start_epoch\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     kl_annealing_duration\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     kl_annealing_start\u001b[39m=\u001b[39;49m\u001b[39m0.0001\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     grl_alpha_start\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     grl_alpha_end\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     grl_alpha_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m models[latent_dim, dropout, pred_dropout] \u001b[39m=\u001b[39m combined_model\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samchou/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_conv_combined_fa_flattened.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m results[latent_dim, dropout, pred_dropout] \u001b[39m=\u001b[39m training_results\n",
      "File \u001b[0;32m~/AFQ-Insight-Autoencoder-Experiments/AFQ-Insight-Autoencoder-Experiments/Experiment_Utils/utils.py:732\u001b[0m, in \u001b[0;36mtrain_variational_autoencoder_age_site\u001b[0;34m(combined_model, train_data, val_data, epochs, lr, device, max_grad_norm, w_recon, w_kl, w_age, w_site, kl_annealing_start_epoch, kl_annealing_duration, kl_annealing_start, grl_alpha_start, grl_alpha_end, grl_alpha_epochs, save_prefix, val_metric_to_monitor)\u001b[0m\n\u001b[1;32m    730\u001b[0m scaler\u001b[39m.\u001b[39munscale_(opt)\n\u001b[1;32m    731\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(combined_model\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39mmax_grad_norm)\n\u001b[0;32m--> 732\u001b[0m scaler\u001b[39m.\u001b[39;49mstep(opt)\n\u001b[1;32m    733\u001b[0m scaler\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m    735\u001b[0m \u001b[39m# Accumulate sums (losses are mean per item, scale by batch size)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/amp/grad_scaler.py:380\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Invoke ``unscale_(optimizer)`` followed by parameter update, if gradients are not infs/NaN.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \n\u001b[1;32m    360\u001b[0m \u001b[39m:meth:`step` carries out the following two operations:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39m    Closure use is not currently supported.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enabled:\n\u001b[0;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mclosure\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    383\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    384\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClosure use is not currently supported if GradScaler is enabled.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m\"\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     92\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     adam(\n\u001b[1;32m    224\u001b[0m         params_with_grad,\n\u001b[1;32m    225\u001b[0m         grads,\n\u001b[1;32m    226\u001b[0m         exp_avgs,\n\u001b[1;32m    227\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    228\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    229\u001b[0m         state_steps,\n\u001b[1;32m    230\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    231\u001b[0m         has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[1;32m    232\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    233\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    234\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    235\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    236\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    237\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    238\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    239\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    240\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    242\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    243\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    246\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[39mreturn\u001b[39;00m disabled_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m func(\n\u001b[1;32m    785\u001b[0m     params,\n\u001b[1;32m    786\u001b[0m     grads,\n\u001b[1;32m    787\u001b[0m     exp_avgs,\n\u001b[1;32m    788\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    789\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    790\u001b[0m     state_steps,\n\u001b[1;32m    791\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    792\u001b[0m     has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[1;32m    793\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    794\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    795\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    796\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    797\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    798\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    799\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    800\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    801\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    802\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[1;32m    803\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/afq_new/lib/python3.11/site-packages/torch/optim/adam.py:430\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    428\u001b[0m         denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    429\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[1;32m    432\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n\u001b[1;32m    434\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Main Hyperparameter Loop ---\n",
    "for dropout in dropout_values:\n",
    "    for age_dropout in age_dropout_values:\n",
    "        for site_dropout in site_dropout_values:\n",
    "            for latent_dim in latent_dims:\n",
    "                for w_recon in w_recon_values:\n",
    "                    for w_kl in w_kl_values:\n",
    "                        for w_age in w_age_values:\n",
    "                            for w_site in w_site_values:\n",
    "                                print(\"-\" * 80)\n",
    "                                print(f\"STARTING RUN: LD={latent_dim}, DR_VAE={dropout}, DR_Age={age_dropout}, DR_Site={site_dropout}, wR={w_recon}, wKL={w_kl}, wA={w_age}, wS={w_site}\")\n",
    "                                print(\"-\" * 80)\n",
    "\n",
    "                                # --- Ensure input_channels and sequence_length are defined ---\n",
    "                                if 'sequence_length' not in locals() or 'input_channels' not in locals():\n",
    "                                    print(\"Error: sequence_length or input_channels not defined. Run previous cells.\")\n",
    "                                    break\n",
    "\n",
    "                                # --- Instantiate Models ---\n",
    "                                vae = Conv1DVariationalAutoencoder_fa(latent_dims=latent_dim, dropout=dropout)\n",
    "                                age_predictor = AgePredictorCNN(input_channels=input_channels, \n",
    "                                                              sequence_length=sequence_length, \n",
    "                                                              dropout=age_dropout)\n",
    "                                site_predictor = SitePredictorCNN(num_sites=num_sites, \n",
    "                                                                input_channels=input_channels, \n",
    "                                                                sequence_length=sequence_length, \n",
    "                                                                dropout=site_dropout)\n",
    "\n",
    "                                combined_model = CombinedVAE_Predictors(vae, age_predictor, site_predictor)\n",
    "                                combined_model = combined_model.to(device)\n",
    "\n",
    "                                # --- Define unique prefix for this run's files ---\n",
    "                                run_save_prefix = os.path.join(save_directory, \n",
    "                                    f\"combo_ld{latent_dim}_drV{dropout}_drA{age_dropout}_drS{site_dropout}_wr{w_recon}_wkl{w_kl}_wa{w_age}_ws{w_site}\")\n",
    "\n",
    "                                # --- Train Model ---\n",
    "                                try:\n",
    "                                    training_results = train_variational_autoencoder_age_site(\n",
    "                                        combined_model=combined_model,\n",
    "                                        train_data=train_loader_raw,\n",
    "                                        val_data=val_loader_raw,\n",
    "                                        epochs=500,\n",
    "                                        lr=0.001,\n",
    "                                        device=device,\n",
    "                                        max_grad_norm=1.0,\n",
    "                                        w_recon=w_recon,\n",
    "                                        w_kl=w_kl,\n",
    "                                        w_age=w_age,\n",
    "                                        w_site=w_site,\n",
    "                                        kl_annealing_start_epoch=50,\n",
    "                                        kl_annealing_duration=150,\n",
    "                                        kl_annealing_start=0.001,\n",
    "                                        grl_alpha_start=0.0,  # Start with stronger reversal\n",
    "                                        grl_alpha_end=2.5,    # Increase max reversal strength\n",
    "                                        grl_alpha_epochs=200,  # Reach max alpha faster\n",
    "                                        save_prefix=run_save_prefix,\n",
    "                                        val_metric_to_monitor=\"val_age_mae\"\n",
    "                                    )\n",
    "                                except Exception as e:\n",
    "                                    print(f\"\\n !!! Training failed for run {run_save_prefix}: {e} !!!\\n\")\n",
    "                                    training_results = None\n",
    "\n",
    "                                # --- Store Results ---\n",
    "                                current_key = (latent_dim, dropout, age_dropout, site_dropout, w_recon, w_kl, w_age, w_site)\n",
    "                                results[current_key] = training_results\n",
    "\n",
    "                                # --- Process and Save Results if training finished ---\n",
    "                                if training_results and training_results.get(\"model_path\"):\n",
    "                                    # Convert metrics to CPU floats\n",
    "                                    keys_to_convert = [\n",
    "                                        \"train_loss_epoch\", \"val_loss_epoch\", \"train_recon_loss_epoch\", \"val_recon_loss_epoch\",\n",
    "                                        \"train_kl_loss_epoch\", \"val_kl_loss_epoch\", \"train_age_loss_epoch\", \"val_age_loss_epoch\",\n",
    "                                        \"train_site_loss_epoch\", \"val_site_loss_epoch\", \"train_age_mae_epoch\", \"val_age_mae_epoch\",\n",
    "                                        \"train_site_acc_epoch\", \"val_site_acc_epoch\", \"current_beta_epoch\",\n",
    "                                        \"current_grl_alpha_epoch\", \"current_lr_epoch\"\n",
    "                                    ]\n",
    "                                    processed_results = {}\n",
    "                                    for key in keys_to_convert:\n",
    "                                        metric_list = training_results.get(key, [])\n",
    "                                        new_list = []\n",
    "                                        if isinstance(metric_list, (list, tuple)):\n",
    "                                            for val in metric_list:\n",
    "                                                if isinstance(val, torch.Tensor):\n",
    "                                                    new_list.append(float(val.cpu().item()))\n",
    "                                                elif isinstance(val, (int, float, np.number)):\n",
    "                                                    new_list.append(float(val))\n",
    "                                                else:\n",
    "                                                    new_list.append(float('nan'))\n",
    "                                        processed_results[key] = new_list\n",
    "\n",
    "                                    # Convert best metrics\n",
    "                                    best_mae_key = \"best_val_age_mae\"\n",
    "                                    best_mae_val = training_results.get(best_mae_key)\n",
    "                                    if isinstance(best_mae_val, torch.Tensor):\n",
    "                                        best_mae = float(best_mae_val.cpu().item())\n",
    "                                    elif isinstance(best_mae_val, (int, float, np.number)):\n",
    "                                        best_mae = float(best_mae_val)\n",
    "                                    else: \n",
    "                                        best_mae = float('nan')\n",
    "\n",
    "                                    # Create DataFrame\n",
    "                                    num_epochs = len(processed_results.get(\"train_loss_epoch\", []))\n",
    "                                    if num_epochs > 0:\n",
    "                                        df_data = {\"epoch\": range(1, num_epochs + 1)}\n",
    "                                        for k in keys_to_convert:\n",
    "                                            col_name = k.replace('_epoch', '')\n",
    "                                            metric_data = processed_results.get(k, [])\n",
    "                                            if len(metric_data) != num_epochs:\n",
    "                                                metric_data = [float('nan')] * num_epochs\n",
    "                                            df_data[col_name] = metric_data\n",
    "\n",
    "                                        df_epochs = pd.DataFrame(df_data)\n",
    "                                        df_epochs.to_csv(f\"{run_save_prefix}_metrics.csv\", index=False)\n",
    "\n",
    "                                        # Save summary metrics CSV\n",
    "                                        df_summary = pd.DataFrame([{\n",
    "                                            best_mae_key: best_mae,\n",
    "                                            \"best_epoch\": training_results.get(\"best_epoch\", float('nan')),\n",
    "                                            \"model_path\": training_results.get(\"model_path\", \"N/A\")\n",
    "                                        }])\n",
    "                                        df_summary.to_csv(f\"{run_save_prefix}_summary.csv\", index=False)\n",
    "\n",
    "                                        print(f\"Finished & Saved Run: {current_key}. Best Val MAE: {best_mae:.4f}\")\n",
    "                                    else:\n",
    "                                        print(f\"Skipping results saving for run {current_key} - No epoch data found.\")\n",
    "                                else:\n",
    "                                    print(f\"Skipping results processing for run {current_key} - Training did not complete or model not saved.\")\n",
    "\n",
    "# Indicate loop completion\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Hyperparameter search loop finished.\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
