{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samchou/miniconda3/envs/afq_new/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "from afqinsight import AFQDataset\n",
    "from afqinsight.nn.utils import prep_pytorch_data\n",
    "from afqinsight.nn.utils import prep_fa_dataset\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.normal import Normal\n",
    "from sklearn.decomposition import PCA\n",
    "import afqinsight.augmentation as aug\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/samchou/.cache/afq-insight/hbn/subjects.tsv exists.\n",
      "File /Users/samchou/.cache/afq-insight/hbn/nodes.csv exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samchou/miniconda3/envs/afq_new/lib/python3.11/site-packages/afqinsight/transform.py:144: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  features = interpolated.stack([\"subjectID\", \"tractID\", \"metric\"]).unstack(\n"
     ]
    }
   ],
   "source": [
    "dataset = AFQDataset.from_study('hbn')\n",
    "torch_dataset, train_loader, test_loader, val_loader = prep_pytorch_data(dataset,batch_size=64)  \n",
    "gt_shape = torch_dataset[0][1].size()[0]\n",
    "sequence_length = torch_dataset[0][0].size()[0]  # 48\n",
    "in_channels = torch_dataset[0][0].size()[1]  # 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DEncoder_one_tract(nn.Module):\n",
    "    def __init__(self, latent_dims=20, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=5, stride=2, padding=2)  \n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=2)  \n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv4 = nn.Conv1d(64, latent_dims, kernel_size=5, stride=2, padding=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.conv1(x)) \n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)   \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv4(x)\n",
    "        return x\n",
    "    \n",
    "class Conv1DDecoder_one_tract(nn.Module):\n",
    "    def __init__(self, latent_dims=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose1d(latent_dims, 64, kernel_size=5, stride=2, padding=2, output_padding=0)  \n",
    "        self.deconv2 = nn.ConvTranspose1d(64, 32, kernel_size=5, stride=2, padding=2, output_padding=0)  \n",
    "        self.deconv3 = nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=2, output_padding=2)\n",
    "        self.deconv4 = nn.ConvTranspose1d(16, 1, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = F.relu(self.deconv1(x)) \n",
    "        x = F.relu(self.deconv2(x))   \n",
    "        x = F.relu(self.deconv3(x))\n",
    "        x = self.deconv4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        # return x.view(batch_size, -1)\n",
    "\n",
    "class Conv1DAutoencoder_one_tract(nn.Module): \n",
    "    def __init__(self, latent_dims=20, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.encoder = Conv1DEncoder_one_tract(latent_dims, dropout=dropout)\n",
    "        self.decoder = Conv1DDecoder_one_tract(latent_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_prime = self.decoder(z)\n",
    "        return x_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DAutoencoder_one_tract(nn.Module): \n",
    "    def __init__(self, latent_dims=20, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.encoder = Conv1DEncoder_one_tract(latent_dims, dropout=dropout)\n",
    "        self.decoder = Conv1DDecoder_one_tract(latent_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_prime = self.decoder(z)\n",
    "        return x_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_first_tract_dropout_experiment(\n",
    "    self, train_data, val_data, epochs=20, lr=0.001, num_selected_tracts=5, sigma=0.03\n",
    "):\n",
    "    opt = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5, factor=0.5)\n",
    "    train_rmse_per_epoch = []\n",
    "    val_rmse_per_epoch = []\n",
    "    best_val_loss = float('inf')  # Track the best (lowest) validation RMSE overall\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        self.train()\n",
    "        running_loss = 0\n",
    "        running_rmse = 0\n",
    "        items = 0\n",
    "\n",
    "        for x, _ in train_data:  # x shape: (batch_size, 48, 100)\n",
    "            batch_size = x.size(0)\n",
    "            # For simplicity, using only the first tract in training\n",
    "\n",
    "            tract_data = x[:, 0:1, :] #keeps it (batch_size, 1, 100)    \n",
    "\n",
    "            # Apply jitter augmentation\n",
    "            tract_data = tract_data.to(torch.float32).numpy()\n",
    "            tract_data = aug.jitter(tract_data, sigma=sigma)\n",
    "            tract_data = torch.tensor(tract_data, dtype=torch.float32).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            opt.zero_grad()\n",
    "            x_hat = self(tract_data)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = reconstruction_loss(tract_data, x_hat, kl_div=0, reduction=\"sum\")\n",
    "            # Compute RMSE for the batch\n",
    "            batch_rmse = torch.sqrt(F.mse_loss(tract_data, x_hat, reduction=\"mean\"))\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            items += tract_data.size(0)\n",
    "            running_loss += loss.item()\n",
    "            running_rmse += batch_rmse.item() * tract_data.size(0)  # Weighted sum\n",
    "\n",
    "        scheduler.step(running_loss / items)\n",
    "        avg_train_rmse = running_rmse / items\n",
    "        train_rmse_per_epoch.append(avg_train_rmse)\n",
    "\n",
    "        # Validation\n",
    "        self.eval()\n",
    "        val_rmse = 0\n",
    "        val_items = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, _ in val_data:\n",
    "                batch_size = x.size(0)\n",
    "                # For simplicity, using the first tract in validation as well\n",
    "                tract_data = x[:, 0:1, :]\n",
    "\n",
    "                # Apply jitter augmentation\n",
    "                \n",
    "                tract_data = tract_data.to(torch.float32).numpy()\n",
    "                tract_data = aug.jitter(tract_data, sigma=sigma)\n",
    "                tract_data = torch.tensor(tract_data, dtype=torch.float32).to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                x_hat = self(tract_data)\n",
    "\n",
    "                # Compute RMSE for the batch\n",
    "                batch_val_rmse = torch.sqrt(F.mse_loss(tract_data, x_hat, reduction=\"mean\"))\n",
    "\n",
    "                val_items += tract_data.size(0)\n",
    "                val_rmse += batch_val_rmse.item() * tract_data.size(0)\n",
    "\n",
    "        avg_val_rmse = val_rmse / val_items\n",
    "        val_rmse_per_epoch.append(avg_val_rmse)\n",
    "\n",
    "        # Update best validation loss if improved\n",
    "        if avg_val_rmse < best_val_loss:\n",
    "            best_val_loss = avg_val_rmse\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}, Train RMSE: {avg_train_rmse:.4f}, Val RMSE: {avg_val_rmse:.4f}\"\n",
    "        )\n",
    "\n",
    "    return train_rmse_per_epoch, val_rmse_per_epoch, best_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_values = [0, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "train_rmse_results = {}\n",
    "val_rmse_results = {}\n",
    "best_val_results = {}\n",
    "\n",
    "for dropout in dropout_values:\n",
    "    print(f\"\\nTraining with dropout = {dropout}\")\n",
    "    vae_one_tract = Conv1DAutoencoder_one_tract(latent_dims=20, dropout=dropout).to(device)\n",
    "    train_rmse, val_rmse, best_val_loss = train_first_tract_dropout_experiment(\n",
    "        vae_one_tract, train_loader, val_loader, epochs=100, lr=1e-3, num_selected_tracts=8\n",
    "    )\n",
    "    train_rmse_results[dropout] = train_rmse\n",
    "    val_rmse_results[dropout] = val_rmse\n",
    "    best_val_results[dropout] = best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot best validation RMSE for each dropout value\n",
    "plt.figure(figsize=(10, 6))\n",
    "dropout_keys = sorted(best_val_results.keys())\n",
    "best_vals = [best_val_results[d] for d in dropout_keys]\n",
    "plt.plot(dropout_keys, best_vals, marker='o')\n",
    "plt.xlabel(\"Dropout\")\n",
    "plt.ylabel(\"Best Validation RMSE\")\n",
    "plt.title(\"Best Validation RMSE vs. Dropout\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Training RMSE only\n",
    "plt.figure(figsize=(18, 6))\n",
    "for dropout in dropout_values:\n",
    "    plt.plot(\n",
    "        range(1, len(train_rmse_results[dropout]) + 1),\n",
    "        train_rmse_results[dropout],\n",
    "        label=f\"Train RMSE (Dropout = {dropout})\",\n",
    "    )\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Training RMSE for Different Dropout Values\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Validation RMSE only\n",
    "plt.figure(figsize=(18, 6))\n",
    "for dropout in dropout_values:\n",
    "    plt.plot(\n",
    "        range(1, len(val_rmse_results[dropout]) + 1),\n",
    "        val_rmse_results[dropout],\n",
    "        label=f\"Val RMSE (Dropout = {dropout})\",\n",
    "    )\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Validation RMSE for Different Dropout Values\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Both Training and Validation RMSE\n",
    "plt.figure(figsize=(18, 8))\n",
    "for dropout in dropout_values:\n",
    "    plt.plot(\n",
    "        range(1, len(train_rmse_results[dropout]) + 1),\n",
    "        train_rmse_results[dropout],\n",
    "        label=f\"Train RMSE (Dropout = {dropout})\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        range(1, len(val_rmse_results[dropout]) + 1),\n",
    "        val_rmse_results[dropout],\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Val RMSE (Dropout = {dropout})\",\n",
    "    )\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Train vs. Validation RMSE for Different Dropout Values\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afq_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
