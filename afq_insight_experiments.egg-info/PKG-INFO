Metadata-Version: 2.1
Name: afq_insight_experiments
Version: 0.1.0
Summary: Autoencoder experiments for AFQ-Insight neuroimaging data analysis
Home-page: https://github.com/yourusername/AFQ-Insight-Autoencoder-Experiments
Author: Sam Chou
Author-email: sam@thechous.com
Keywords: autoencoder,VAE,afq,neuroimaging,diffusion MRI,brain connectivity
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Medical Science Apps.
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: License :: OSI Approved :: MIT License
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: torch>=2.0.0
Requires-Dist: torchvision>=0.15.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: matplotlib>=3.7.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: seaborn>=0.12.0
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: afqinsight>=0.3.0
Requires-Dist: jupyter>=1.0.0
Requires-Dist: ipywidgets>=8.0.0
Requires-Dist: tqdm>=4.65.0
Requires-Dist: pytest>=7.0.0
Requires-Dist: setuptools>=65.0.0

# AFQ-Insight Autoencoder Experiments

This repository contains comprehensive experiments applying convolutional autoencoders and variational autoencoders to diffusion MRI brain connectivity data from the AFQ-Insight HBN dataset. The experiments focus on learning brain representations for age prediction and site effect removal using adversarial training.

## ğŸ“ Project Structure

```
AFQ-Insight-Autoencoder-Experiments/
â”œâ”€â”€ ConvAE_Experiments/           # Main experimental code
â”‚   â”œâ”€â”€ Non_Variational/          # Standard autoencoder experiments
â”‚   â”‚   â”œâ”€â”€ First_tract_data/     # Single tract (tract 0) experiments
â”‚   â”‚   â””â”€â”€ Fa_tracts_data/       # FA-only tract experiments
â”‚   â””â”€â”€ Variational/              # Variational autoencoder experiments
â”‚       â”œâ”€â”€ all_tracts/           # All 48 tracts with multi-task learning
â”‚       â”œâ”€â”€ fa_tracts_data/       # FA-only VAE experiments
â”‚       â””â”€â”€ first_tract_data/     # Single tract VAE experiments
â”œâ”€â”€ FC_AE_Experiments/            # Fully connected autoencoder experiments
â”œâ”€â”€ evaluating_tracts/            # Individual tract importance analysis
â”œâ”€â”€ Experiment_Utils/             # Core utilities and model definitions
â”‚   â”œâ”€â”€ models.py                 # Autoencoder architectures
â”‚   â”œâ”€â”€ utils.py                  # Data processing and training functions
â”‚   â””â”€â”€ overfit_utils.py          # Overfitting analysis tools
â”œâ”€â”€ batch_scripts/                # HPC batch job scripts
â””â”€â”€ tests/                        # Test files
```

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- CUDA-compatible GPU (recommended)
- 8GB+ RAM
- AFQ-Insight compatible diffusion MRI data

### Setup Instructions

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/AFQ-Insight-Autoencoder-Experiments.git
   cd AFQ-Insight-Autoencoder-Experiments
   ```

2. **Create and activate virtual environment:**
   ```bash
   # Using conda (recommended)
   conda create -n afq_experiments python=3.11
   conda activate afq_experiments
   
   # Or using venv
   python -m venv afq_experiments
   source afq_experiments/bin/activate  # Linux/Mac
   # afq_experiments\Scripts\activate  # Windows
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install the package in development mode:**
   ```bash
   pip install -e .
   ```

## ğŸ“Š Data Requirements

The experiments require AFQ tractometry data compatible with the `afqinsight` package. The data should include:

- **48 brain tracts** with diffusion measurements (FA, MD, etc.)
- **Participant metadata** including age and scanning site
- **Standard AFQ-Insight format** (see [AFQ-Insight documentation](https://yeatmanlab.github.io/AFQ-Insight/))

Expected data structure:
```
your_afq_data/
â”œâ”€â”€ nodes/          # Individual tract node data
â”œâ”€â”€ profiles/       # Tract profile data  
â””â”€â”€ subjects.csv    # Participant metadata (age, site, etc.)
```

## ğŸ”¬ Running Experiments

### Option 1: Interactive Jupyter Notebooks

1. **Start Jupyter:**
   ```bash
   jupyter notebook
   ```

2. **Navigate to experiment folders and run notebooks:**
   - `ConvAE_Experiments/Non_Variational/First_tract_data/conv_combined_experiment.ipynb`
   - `ConvAE_Experiments/Variational/all_tracts/vae_age_site_stages_all.ipynb`
   - `ConvAE_Experiments/Variational/fa_tracts_data/vae_age_site_stages.ipynb`

### Option 2: Python Scripts

1. **Single tract experiments:**
   ```bash
   cd ConvAE_Experiments/Variational/first_tract_data
   python vae_age_site_stages_first_tract.py
   ```

2. **All tracts with multi-task learning:**
   ```bash
   cd ConvAE_Experiments/Variational/all_tracts
   python vae_age_site_stages_all.py
   ```

3. **FA-only experiments:**
   ```bash
   cd ConvAE_Experiments/Variational/fa_tracts_data
   python vae_age_site_stages.py
   ```

### Option 3: HPC Batch Jobs

For large-scale experiments on HPC systems:

```bash
# Submit batch jobs
sbatch batch_scripts/run_notebook_vae_age_site_stages.sbatch
sbatch batch_scripts/run_notebook_vae_age_site_stages_all_tract.sbatch
```

## ğŸ§ª Experiment Types

### 1. Non-Variational Autoencoders
- **Purpose**: Baseline autoencoder performance
- **Location**: `ConvAE_Experiments/Non_Variational/`
- **Key Features**: Standard reconstruction, hyperparameter search

### 2. Variational Autoencoders (VAE)
- **Purpose**: Advanced representation learning with age prediction and site removal
- **Location**: `ConvAE_Experiments/Variational/`
- **Key Features**: 
  - Multi-task learning (reconstruction + age prediction + site removal)
  - Adversarial training for site effect removal
  - Staged training approaches

### 3. Tract Importance Analysis
- **Purpose**: Identify which brain tracts are most predictive of age
- **Location**: `evaluating_tracts/`
- **Usage**:
  ```bash
  cd evaluating_tracts
  python tract_importance_evaluation.py --output-dir results_fa_only
  ```

## ğŸ“ˆ Expected Outputs

### Training Metrics
- **Reconstruction loss** (MSE)
- **Age prediction accuracy** (MAE, RÂ²)
- **Site classification accuracy** (for adversarial training)
- **KL divergence** (for VAE models)

### Result Files
- `training_metrics.csv`: Complete training history
- `*_predictions.csv`: Model predictions on validation data
- `site_confusion_matrix_*.png`: Site classification performance
- `*.pth`: Saved model weights

### Visualization
Results can be visualized using the companion repository:
[AFQ-Insight-Autoencoder-Plotting](https://github.com/SamChou05/AFQ-Insight-Autoencoder-Plotting)

## ğŸ”§ Customization

### Modifying Hyperparameters
Edit the hyperparameter sections in notebooks or scripts:
```python
# Example configuration
latent_dims = [32, 64, 128]
dropout_values = [0.0, 0.1, 0.2]
w_recon = 1.0      # Reconstruction weight
w_kl = 0.001       # KL divergence weight (VAE)
w_age = 15.0       # Age prediction weight
w_site = 5.0       # Site adversarial weight
```

### Adding New Models
1. Define model architecture in `Experiment_Utils/models.py`
2. Add training logic in `Experiment_Utils/utils.py`
3. Create experiment script using existing templates

### Data Preprocessing
Modify data preparation functions in `Experiment_Utils/utils.py`:
- `prep_fa_dataset()`: FA-only data
- `prep_first_tract_data()`: Single tract data
- `prep_fa_flattened_remapped_data()`: Site-remapped data

## ğŸ› Testing

Run tests to verify installation:
```bash
pytest tests/
```

## ğŸ“‹ Requirements

### Core Dependencies
- `torch>=2.0.0`: PyTorch deep learning framework
- `afqinsight>=0.3.0`: AFQ-Insight data handling
- `numpy>=1.24.0`: Numerical computing
- `pandas>=2.0.0`: Data manipulation
- `scikit-learn>=1.3.0`: Machine learning metrics
- `matplotlib>=3.7.0`: Visualization

### Development Dependencies
- `jupyter>=1.0.0`: Interactive notebooks
- `pytest>=7.0.0`: Testing framework

See `requirements.txt` for complete dependency list.

## ğŸ“– Citation

If you use this code in your research, please cite:

```bibtex
@misc{chou2024afqinsight,
  title={AFQ-Insight Autoencoder Experiments},
  author={Chou, Sam},
  year={2024},
  url={https://github.com/yourusername/AFQ-Insight-Autoencoder-Experiments}
}
```

## ğŸ”— Related Projects

- [AFQ-Insight](https://github.com/yeatmanlab/AFQ-Insight): Core AFQ analysis framework
- [AFQ-Insight-Autoencoder-Plotting](https://github.com/SamChou05/AFQ-Insight-Autoencoder-Plotting): Visualization tools
- [pyAFQ](https://github.com/yeatmanlab/pyAFQ): Automated fiber quantification

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the `LICENSE` file for details.

## ğŸ†˜ Support

For issues and questions:
1. Check the [Issues](https://github.com/yourusername/AFQ-Insight-Autoencoder-Experiments/issues) page
2. Review experiment-specific Description.txt files in each folder
3. Contact the UW Neuroinformatics R&D Group

## ğŸ¥ Acknowledgments

- **UW Neuroinformatics R&D Group**: Research support and guidance
- **AFQ-Insight Team**: Core framework development
- **Healthy Brain Network**: Data provision 
